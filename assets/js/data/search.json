[
  
  {
    "title": null,
    "url": "/posts/2025-05-14-%EB%B7%B0%EA%B0%95%EC%A0%9C%EB%A6%AC%ED%94%84%EB%A0%88%EC%8B%9C/",
    "categories": "",
    "tags": "",
    "date": "2025-10-15 22:11:15 +0900",
    "content": "SwiftUI에서 @Binding을 지원하지 않는 뷰의 강제 리프레시  parameters와 ParameterRow가 바인딩(Binding)을 사용하지 않고 있다면, SwiftUI는 내부 값이 바뀌더라도 해당 뷰(HStack)를 자동으로 업데이트하지 않습니다. 따라서 Randomize 버튼을 눌러도 뷰가 갱신되지 않는 문제가 발생합니다.  ✅ 해결 방법: id 값을 바꿔서 뷰 강제 갱신  HStack 전체에 .id(...)를 주어 SwiftUI가 해당 뷰를 다른 것으로 인식하도록 하면 뷰 전체가 강제로 다시 그려집니다.  @State private var refreshID = UUID()   그 다음, HStack에 .id(refreshID)를 적용합니다:  HStack {   ForEach(conductor.voc.parameters.indices, id: \\.self) {     ParameterRow(param: conductor.voc.parameters[$0])   } } .id(refreshID) // &lt;- 이게 핵심   그리고 Randomize 버튼에서 refreshID를 갱신해주면 SwiftUI는 뷰 전체를 새로 렌더링합니다:  Button(\"Randomize\") {   conductor.voc.frequency = AUValue.random(in: 0...2000)   conductor.voc.tonguePosition = AUValue.random(in: 0...1)   conductor.voc.tongueDiameter = AUValue.random(in: 0...1)   conductor.voc.tenseness = AUValue.random(in: 0...1)   conductor.voc.nasality = AUValue.random(in: 0...1)   refreshID = UUID() // 강제 갱신 트리거 }     🔁 대안 (권장): Binding을 지원하도록 구조 수정     VocalTract.parameters가 @Published var 배열이면 @Binding으로 넘길 수 있습니다.   ParameterRow(param: Binding&lt;NodeParameter&gt;)처럼 정의하고, 수정 가능하게 만들 수도 있습니다.   하지만 외부 라이브러리이거나 구조를 못 바꾸는 경우에는 .id(UUID()) 방식이 가장 확실하고 간단한 방법입니다.    ✅ 결론  parameters가 Binding을 지원하지 않더라도 HStack에 .id(refreshID)를 설정하고 UUID()를 변경하는 방식으로 뷰를 강제로 새로 그리게 만들 수 있습니다. "
  },
  
  {
    "title": null,
    "url": "/posts/2025-04-29-Observable-%EB%8F%99%EC%9E%91%EC%9B%90%EB%A6%AC/",
    "categories": "",
    "tags": "",
    "date": "2025-10-15 22:11:15 +0900",
    "content": "Observable 동작 원리 viewModel에서 @State를 붙이지 않아도 코드가 동작하는 이유? @Observable 클래스 AudioKit3DViewModel에서 참조하는  각 클래스 AudioEngine3DConductor, SceneCoordinator에 @Observable을 붙이지 않아도 동작하는 이유?   답변  1. viewModel에서 @State를 붙이지 않아도 코드가 동작하는 이유  @State는 SwiftUI 뷰 내부에서 값 타입(보통 구조체)을 직접 소유하고 변경할 때 사용됩니다. 그러나 viewModel은 클래스(AudioKit3DViewModel) 타입이며, 해당 클래스는 SwiftUI 뷰 외부에서 생성되어 참조됩니다. 이 경우 SwiftUI에서 값의 변경을 감지하려면 @ObservedObject, @StateObject, @EnvironmentObject 등의 속성이 필요합니다.  하지만 해당 코드에서는 @Observable 속성이 붙어 있는 것으로 보입니다.  Swift 5.9 이상 (또는 Xcode 15 이상)에서는 SwiftUI의 Observation 프레임워크를 기반으로 하는 @Observable 프로토콜이 도입되었으며, 이 프로토콜을 채택한 객체는 SwiftUI에서 자동으로 상태를 관찰할 수 있습니다. 이를 통해 @StateObject나 @ObservedObject 없이도 값의 변경이 뷰에 반영됩니다.  다시 말해, viewModel이 @Observable을 따르고 있고, SwiftUI가 이를 알 수 있기 때문에 별도의 속성 래퍼가 필요 없습니다. 단, 이 기능은 Swift의 Observation이 제대로 적용되는 환경(Xcode 15 이상, Swift 5.9 이상, iOS 17 이상 등)에서만 가능합니다.    2. AudioEngine3DConductor, SceneCoordinator에 @Observable을 붙이지 않아도 되는 이유  @Observable은 SwiftUI가 뷰에서 참조할 값이 변경될 때 UI를 자동 갱신하기 위해 사용하는 것입니다.  하지만 AudioEngine3DConductor와 SceneCoordinator는 뷰에서 직접 사용하는 것이 아니라, AudioKit3DViewModel 내부에서 사용됩니다. 그리고 이 클래스들은 값의 변경이 SwiftUI 뷰에 직접적인 영향을 주지 않기 때문에 @Observable을 붙일 필요가 없습니다.  즉, 다음과 같은 구조입니다:     AudioKit3DView는 viewModel: AudioKit3DViewModel을 소유함   AudioKit3DViewModel은 @Observable이라서 값의 변경을 SwiftUI가 감지할 수 있음   viewModel 내부에서 사용하는 conductor, coordinator는 뷰에 직접 바인딩된 값이 아님   따라서 그 내부 클래스에 @Observable을 붙일 필요가 없음   단, 만약 AudioEngine3DConductor나 SceneCoordinator의 속성을 뷰에서 직접 바인딩하거나 관찰해야 할 경우, 그때는 해당 클래스에도 @Observable이나 @Published 등을 적용해야 합니다.    요약                 항목       이유                       viewModel에 @State 없음       @Observable을 통해 SwiftUI가 자동 관찰하므로 별도 속성 래퍼 불필요                 conductor, coordinator에 @Observable 없음       뷰에서 직접 사용하지 않으며 뷰에 상태 영향을 주지 않기 때문          "
  },
  
  {
    "title": null,
    "url": "/posts/2025-06-23-%EB%AF%B8%EB%94%94_%ED%8A%B8%EB%9E%99%EC%A4%91%EA%B0%84_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8%EC%B2%B4%EC%9D%B8%EC%A7%80_%EB%8C%80%EC%9D%91%EB%B2%95/",
    "categories": "",
    "tags": "",
    "date": "2025-10-15 22:11:15 +0900",
    "content": "MIDISampler+AppleSequencer를 이용한 미디 멀티트랙 재생 중 트랙 중간에 프로그램 체인지가 있는 경우 대응 방법  track 2: [   AudioKit.MIDIProgramChangeEvent(time: 0.0, channel: 2, number: 57),   AudioKit.MIDIProgramChangeEvent(time: 64.0, channel: 2, number: 60),   AudioKit.MIDIProgramChangeEvent(time: 119.98697916666667, channel: 2, number: 57) ]   track 2처럼 트랙 중간에 Program Change 메시지로 악기가 바뀌는 경우, AudioKit의 AppleSequencer와 MIDISampler 조합만으로는 정확한 사운드 전환을 구현하기 어렵습니다.  기본적으로 track.setMIDIOutput(sampler.midiIn)으로 연결된 MIDISampler는 트랙 전체를 하나의 악기로만 재생합니다. 중간에 악기를 바꾸는 기능은 직접 처리해주지 않으면 반영되지 않습니다.    ✅ 문제 상황 요약  track 2: [   ProgramChange(channel: 2, number: 57) // 시작 시   ProgramChange(channel: 2, number: 60) // 64초쯤   ProgramChange(channel: 2, number: 57) // 120초쯤 복귀 ]      표준 MIDI에서는 이런 식으로 Program Change 메시지를 트랙 내에 삽입하여 동일 채널에 악기 전환을 수행   AudioKit의 기본 Sequencer 처리 방식에서는 이를 자동 인식하거나 대응하지 않음     🎯 해결 방향  ① Program Change 이벤트를 파싱해서     시점별로 악기(프리셋) 변경 정보를 추출   ② 해당 채널의 MIDI 이벤트를 악기 구간별로 나눠서     구간별 MIDISampler를 생성하거나   하나의 Sampler에 프리셋을 실시간으로 변경 요청 (단, 대부분의 MIDISampler는 실행 중 preset 변경을 안정적으로 지원하지 않음)     ✅ 실현 가능한 접근 방법  ✅ 방법 A: 트랙을 구간별로 분할하여 각각 sampler에 할당     1개 트랙을 Program Change 기준으로 여러 개로 나누고, 구간마다 MIDISampler와 연결 → Mixer에 병합   단점:     구현 복잡도 있음   MIDI 이벤트 재구성이 필요   ✅ 방법 B: ProgramChange 메시지 수신 시 sampler의 preset을 변경  if case let .programChange(channel, number) = event {   if channel == 2 {     try? sampler.loadSoundFont(\"CT8MGM\", preset: number, bank: 0)   } }      MIDI 이벤트를 수신하는 커스텀 MIDIListener 구현 필요   실행 중 preset을 바꾸면 버퍼 끊김이나 글리치 발생 가능      ⚠️ 실행 중 preset 변경은 대부분 권장되지 않음     ✅ 권장 방식 (현실적 대안)  🎯 트랙 중간에 Program Change가 있는 경우:     MIDI 파일을 외부에서 미리 분할하거나   DAW에서 동일 채널에 Program Change를 쓰지 않도록 재구성   또는 AudioKit으로 다룰 경우, 중간 ProgramChange를 무시하고 시작 preset만 사용     ✅ 요약                 상황       설명                       트랙에 ProgramChange가 여러 개 있음       MIDI 채널의 악기가 재생 중에 바뀜                 AudioKit AppleSequencer       한 트랙당 하나의 sampler만 연결됨                 실시간 preset 변경       가능은 하지만 glitch 발생 가능                 현실적인 방법       ProgramChange 기준으로 트랙을 사전 분할 또는 첫 preset만 사용             필요하시면:     해당 트랙을 ProgramChange 기준으로 구간 분할하는 MIDI parser 예제   MIDISampler 여러 개 동적으로 운용하는 구조도 함께 도와드릴 수 있습니다.  "
  },
  
  {
    "title": null,
    "url": "/posts/2025-05-01-kMIDINotPermitted-%EB%AC%B8%EC%A0%9C/",
    "categories": "",
    "tags": "",
    "date": "2025-10-15 22:11:15 +0900",
    "content": "kMIDINotPermitted 문제  요약  iOS 앱에서 Background Modes의 “Audio, AirPlay, and Picture in Picture” 옵션을 활성화하지 않으면 MIDI 권한이 제한되어, MIDISampler나 MIDICallbackInstrument와 같은 실시간 MIDI 관련 기능이 제대로 작동하지 않습니다.    ✅ 오류 메시지 해석  CheckError.swift:CheckError(_:):176:kMIDINotPermitted: Have you enabled the audio background mode in your ios app?      kMIDINotPermitted는 MIDI 권한 부족을 나타냅니다.   “Have you enabled the audio background mode…?”라는 메시지 자체가 해결 방법을 알려주고 있습니다: → 즉, “Background Modes &gt; Audio”를 활성화해야 MIDI 기능이 허용됨을 뜻합니다.     🧠 왜 이런 문제가 발생하는가?  iOS는 에너지 절약과 보안을 이유로, 백그라운드 또는 오디오 처리 관련 기능을 명시적으로 허용하지 않으면 일부 오디오/MIDI 기능을 제한합니다.  특히 다음 경우:     AudioKit의 MIDISampler, AppleSequencer, MIDICallbackInstrument 등은 Core MIDI 또는 AVAudioEngine의 실시간 처리 권한이 필요합니다.   하지만 Info.plist 또는 Build 설정에 Background Modes &gt; Audio가 설정되지 않으면, iOS는 이 앱이 오디오 기반 앱이 아니라고 판단하고, → MIDI 처리를 차단합니다.     ✅ 해결 방법  1. Xcode에서 설정     프로젝트 설정 &gt; Signing &amp; Capabilities 탭   + Capability 버튼 클릭 → Background Modes 추가   Audio, AirPlay, and Picture in Picture 체크 ✅   2. Info.plist에 자동으로 추가되는 키  &lt;key&gt;UIBackgroundModes&lt;/key&gt; &lt;array&gt;   &lt;string&gt;audio&lt;/string&gt; &lt;/array&gt;     📌 정리                 항목       설명                       문제       MIDISampler 사용 시 MIDI 권한 부족으로 드럼 소리가 나지 않음                 원인       Background Modes &gt; Audio 옵션이 꺼져 있어서 iOS가 오디오/MIDI 권한 차단                 해결       Xcode &gt; Signing &amp; Capabilities &gt; Background Modes &gt; Audio 항목 체크                 효과       실시간 MIDI 입력, AudioKit 샘플러 및 시퀀서 정상 동작            "
  },
  
  {
    "title": "AudioKit으로 만드는 다중트랙 미디 재생기 (MultiTrack MIDI Player)",
    "url": "/posts/MultiTrackMIDIPlayer/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-23 17:16:31 +0900",
    "content": "Multitrack MIDI Player  이 코드는 AudioKit을 사용하여 여러 트랙과 악기를 포함한 MIDI 파일을 재생할 수 있는 SwiftUI 기반의 멀티트랙 MIDI 플레이어입니다. 구성은 크게 MultitrackMIDIPlayerConductor(오디오 및 MIDI 처리 로직)와 MultitrackMIDIPlayerView(UI)로 나뉘며, 아래와 같이 작동합니다.    🎼 MultitrackMIDIPlayerConductor: 오디오 및 MIDI 제어 클래스  🔹 주요 프로퍼티  let engine = AudioEngine() let sampler = MIDISampler() let sequencer = AppleSequencer() var samplers: [MIDISampler] = [] var mixer: Mixer!      AudioEngine: 오디오 출력의 핵심 객체   AppleSequencer: MIDI 트랙을 다루기 위한 시퀀서   samplers: 트랙별 악기(MIDISampler) 배열   mixer: 여러 sampler를 하나로 합쳐 출력     🔹 init()  sequencer.loadMIDIFile(\"MIDI Files/Horde3\") setTracks() setMixerOutput()   앱 시작 시 기본 MIDI 파일(Horde3)을 불러오고, 트랙 구성 및 믹서 설정을 실행합니다.    🔹 loadMIDIFile(url:)  sequencer.loadMIDIFile(fromURL: url) samplers.removeAll() setTracks() setMixerOutput()      .fileImporter를 통해 선택한 MIDI 파일을 로드   새로운 MIDI 트랙에 맞게 sampler를 재구성하고 믹서도 다시 설정   ※ engine.output = mixer가 setMixerOutput() 안에서 설정되므로 이 라인 이후 오디오 출력이 재설정됨    🔹 setTracks()  let tracks = sequencer.tracks ... let sampler = MIDISampler() try sampler.loadSoundFont(...) track.setMIDIOutput(sampler.midiIn)   각 트랙에 대해:     channel == 9인지 판단하여 드럼인지 구분   bank 값을 일반(0) 또는 드럼용(128)으로 설정   programChangeEvents에서 preset 번호 추출   해당 사운드폰트 로딩   트랙과 sampler 연결 → track.setMIDIOutput(...)   로그는 conductor.midiLog에 텍스트로 기록됨    🔹 sequencerPlay() / sequencerStop()  sequencer.play() sequencer.stop()   플레이/스톱 버튼에 대응하여 시퀀서를 재생 또는 정지합니다.    🎛 MultitrackMIDIPlayerView: 사용자 인터페이스  🔹 상태 바인딩  @StateObject private var conductor = MultitrackMIDIPlayerConductor() @State private var showFileImporter = false      conductor: 로직을 담당하는 ViewModel   showFileImporter: 파일 가져오기 창 제어용     🔹 UI 구성 요약     MIDI 파일명 표시   [Load MIDI File], [PLAY / STOP] 버튼   MIDI 분석 로그 스크롤 출력   Text(conductor.fileName) ... ScrollView {   Text(conductor.midiLog) }     🔹 파일 가져오기 (.midi)  .fileImporter(isPresented: $showFileImporter, allowedContentTypes: [.midi]) { result in   ...   conductor.loadMIDIFile(url: url) }   유저가 파일을 선택하면 MIDI 파일을 Conductor에 전달하여 새롭게 로드합니다. 보안 스코프 리소스 접근 권한도 자동으로 획득함 (startAccessingSecurityScopedResource())    🔹 오디오 엔진 관리  .onAppear { conductor.start() } .onDisappear { conductor.stop() }   뷰가 등장할 때 AudioKit 엔진 시작, 사라질 때 정지    ✅ 핵심 특징 요약                 기능       구현 방식                       트랙별 악기 설정       programChangeEvents 기반으로 MIDISampler 생성 및 연결                 퍼커션 채널 감지       channel == 9이면 bank: 128로 로딩                 MIDI 분석 출력       로그 텍스트를 ScrollView에 표시                 파일 가져오기       .fileImporter를 통해 .mid 파일 로딩                 실시간 재생 제어       sequencer.play() / sequencer.stop() 호출             📦 확장 아이디어     트랙별 볼륨/음소거 슬라이더 추가   ProgramChange 다중 처리 (중간 악기 변경)  "
  },
  
  {
    "title": "AudioKit의 MIDIPortTest",
    "url": "/posts/MIDIPortTest/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-23 00:42:28 +0900",
    "content": "MIDI Port Test (Virtual MIDI Host 포함)    MIDIPortTestConductor  MIDIPortTestConductor는 AudioKit과 MIDIKit을 이용해 MIDI 포트를 테스트하거나 MIDI 이벤트를 수신/전송할 수 있도록 설계된 MIDI 테스트 도구의 핵심 로직 클래스입니다. 가상 포트를 생성하고, 외부 장치와 통신하며, MIDI 로그를 저장하고, 포트 정보를 조회하는 기능을 포함합니다.    ✅ 주요 목적     가상 MIDI 입/출력 포트 생성 및 관리   외부 MIDI 장치 연결 및 포트 열기/닫기   MIDI 이벤트 실시간 수신 및 로그 기록   특정 포트로 이벤트 전송   테스트용 UI와의 연결을 위한 ObservableObject 구현     ✅ 주요 구성요소 설명  📌 고정 UID 정의  let inputUIDDevelop: Int32 = 1_200_000 let outputUIDDevelop: Int32 = 1_500_000 let inputUIDMain: Int32 = 2_200_000 let outputUIDMain: Int32 = 2_500_000      고정된 UID를 가진 가상 포트를 생성하기 위해 사용됨   UID 기반으로 포트 교체(swap)하거나 구분 가능     📌 @Published 속성  @Published var log = [MIDIEvent]() @Published var outputIsOpen: Bool @Published var outputPortIsSwapped: Bool @Published var inputPortIsSwapped: Bool      UI에서 실시간으로 바뀌는 값을 추적할 수 있도록 상태 노출   MIDI 이벤트 기록(log), 포트 스왑 여부, 출력 포트 오픈 여부 관리     📌 MIDI 초기화  midi.destroyAllVirtualPorts() midi.createVirtualInputPorts(...) midi.createVirtualOutputPorts(...) midi.addListener(self)      기존 포트를 제거하고, UID를 지정한 가상 포트 생성   self를 MIDIListener로 등록하여 수신 처리 가능     📌 로그 버퍼링 및 Timer 처리  private var logBuffer = [MIDIEvent]() private var logTimer: Timer?      MIDI 이벤트를 실시간으로 logBuffer에 임시 저장   0.5초마다 한 번씩 flushLogBuffer()를 호출해 log에 삽입 → UI 성능 저하 방지     📌 포트 설명 캐싱  private var portDescriptionCache: [MIDIUniqueID : PortDescription]      inputPortDescription(forUID:) 함수에서 매번 조회하지 않고 캐싱   초기화 시 백그라운드 스레드에서 inputInfos를 순회해 캐싱해둠     📌 포트 열기 및 닫기  func didSetOutputIsOpen() { ... } func openOutputs() { ... } func start() / stop()      outputIsOpen이 바뀔 때 포트를 열거나 닫음   start()는 input 포트 열기, stop()은 모두 닫기     📌 이벤트 전송  func sendEvent(eventToSend:event, portIDs:[MIDIUniqueID]?)           MIDIEvent 객체를 보고 적절한 AudioKit 전송 함수 호출             .controllerChange → sendControllerMessage       .programChange → sendEvent(...)       .noteOn / .noteOff → 각각 전송                swapVirtualOutputPorts()로 포트 교체 가능        📌 포트 스왑 기능  func swapVirtualInputPort(...) func swapVirtualOutputPorts(...)      개발용 포트와 메인 포트를 교체하여 라우팅 방식 변경 가능   예: 출력 포트 UID가 outputUIDDevelop이면 → inputUIDDevelop로 바꿈     📌 MIDIListener 구현  receivedMIDINoteOn(...) receivedMIDIController(...) ...      MIDIKit이 제공하는 이벤트 콜백   수신된 이벤트를 logBuffer에 추가   로그에 포트 ID 포함 → 어떤 포트에서 들어온 메시지인지 추적 가능     ✅ 요약                 기능       설명                       가상 포트 생성       고정 UID로 input/output 포트 생성                 포트 상태 토글       outputIsOpen으로 열고 닫음                 포트 스왑       개발용/메인 포트를 상황에 따라 교체                 MIDI 이벤트 수신       MIDIListener 프로토콜 구현                 이벤트 로그 기록       logBuffer + 타이머 → @Published log                 포트 정보 조회       UID → 제조사/장치 이름 조회 및 캐싱                 이벤트 전송       noteOn/noteOff/controller/program 등 구분 전송             MIDIPortTestView  MIDIPortTestView는 AudioKit + MIDIKit 기반의 SwiftUI 뷰로, 가상 및 외부 MIDI 포트의 입출력 테스트, CC/노트 전송, 포트 선택 및 실시간 로그 확인 기능을 제공합니다. 앱 또는 MIDI 툴에서 MIDI 포트 동작 상태를 시각적으로 테스트하거나 디버그하는 데 유용한 구성입니다.    ✅ 전체 구조 요약  MIDIPortTestView  ├─ HeaderArea                     ← 포트 개수 및 이름 헤더 표시  ├─ TabView                       ← 포트1/포트2 전환 UI  │   ├─ Port1SelectArea           ← Destination 포트 선택  │   ├─ Port2SelectArea           ← Virtual Output 포트 선택  │   └─ PortEventArea(portID)     ← 선택 포트로 Note/CC 전송 버튼들  ├─ 포트 스왑/출력 여부 Toggle  ├─ LogResetButtonArea            ← 로그 초기화 버튼  ├─ LogHeaderArea                 ← MIDI 로그의 컬럼 헤더  └─ LogDataArea                   ← 수신된 MIDI 로그 목록 표시     🧩 주요 구성 요소 설명  📌 HeaderArea  HeaderCell(...) // 4칸      현재 MIDI 시스템에 등록된 포트 정보(입력/출력/가상 등)의 개수, 이름, UID를 표시     📌 TabView + Port1/2SelectArea  TabView { VStack { Port1SelectArea ... } }      PageTabViewStyle로 구성   첫 페이지: 외부 Destination 포트 선택 + 버튼 전송   두 번째 페이지: Virtual Output 포트 선택 + 전송     📌 PortEventArea(portID:)  MIDIEventButton(eventToSend: .noteOn / .noteOff ...)      하드코딩된 노트 번호([60, 62, 64, 67, 69] 등)로 NoteOn/NoteOff 전송 버튼   ProgramChange(랜덤 악기 변경), CC 1 (Mod Wheel) 전송 버튼 포함   버튼 클릭 시 conductor.sendEvent(...) 호출로 해당 포트에 MIDI 전송     📌 로그 관련 UI  ▸ LogHeaderArea     상태, 채널, 데이터1~2, 포트 UID, 장치명, 제조사명 등 컬럼 헤더 출력   ▸ LogDataArea  ForEach(conductor.log.indices) { i in ... }      실시간 MIDI 이벤트 로그 출력   한 줄당 .LazyHStack으로 7개 항목 출력   conductor.inputPortDescription(forUID:)를 통해 포트 UID → 이름/제조사 변환 (성능 저하 원인)     📌 포트 상태 전환 토글  Toggle(isOn: $conductor.outputIsOpen) { ... } Toggle(isOn: $conductor.inputPortIsSwapped) { ... } Toggle(isOn: $conductor.outputPortIsSwapped) { ... }      outputIsOpen: openOutputs() 실행 여부   inputPortIsSwapped: 가상 입력 포트 UID 스왑 여부   outputPortIsSwapped: 가상 출력 포트 UID 스왑 여부 → conductor.swapVirtualInputPort(...) 등의 포트 경로 제어에 영향     🎛️ 기능 요약                 기능       설명                       포트 선택       외부 포트 및 가상 포트 드롭다운 선택                 MIDI 이벤트 전송       NoteOn/Off, CC, ProgramChange 전송                 포트 스왑       가상 포트 UID를 상황에 따라 교체                 로그 보기       수신된 MIDI 이벤트 로그 실시간 표시                 로그 초기화       버튼으로 로그 지우기             ⚠️ 주의/개선 포인트     LogDataArea에서 inputPortDescription()은 성능 병목 → 캐싱 또는 비동기 평가 필요   포트 수가 많을 경우 Picker나 log 처리 성능 저하 발생 가능   각 포트별 상태나 활성화 여부도 추가 UI로 제공 가능     ✅ 요약  MIDIPortTestView는:     가상/외부 MIDI 포트를 선택하고   테스트용 MIDI 이벤트를 보내며   수신되는 MIDI 로그를 실시간으로 시각화하는 데 최적화된 SwiftUI 뷰입니다.   테스트 도구, 디버깅 뷰, 또는 DAW 플러그인 개발자용 MIDI 유틸리티로 활용할 수 있습니다.   "
  },
  
  {
    "title": "AudioKit의 PolyphonicSTK+MIDIKit",
    "url": "/posts/PolyphonicSTK+MIDIKit/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-22 19:03:37 +0900",
    "content": "Polyphonic STK + MIDIKit  이 코드는 AudioKit과 MIDIKit을 함께 사용하여, 가상 또는 외부 MIDI 장치로부터 들어오는 MIDI 이벤트를 수신하고, RhodesPianoKey(SoundpipeAudioKit) 기반으로 폴리포닉 연주를 가능하게 하는 구조입니다.    ✅ MIDIKit 관련 설명  🔹 MIDIManager 생성  let midiManager = MIDIManager(   clientName: \"CookbookAppMIDIManager\",   model: \"CookbookApp\",   manufacturer: \"BGSMM\" )      MIDIKit의 핵심 객체   CoreMIDI 클라이언트를 만들고, 포트와 연결을 관리함   iOS/macOS의 MIDI 시스템과 연동됨     🔹 MIDI 연결 설정: MIDIConnect()  1. MIDI 서비스 시작  try midiManager.start()      MIDI 시스템 접근을 시작하며, 장치 탐색 및 연결 가능 상태로 전환   2. 입력 연결 설정  try midiManager.addInputConnection(   to: .allOutputs,   tag: \"Listener\",   filter: .owned(),   receiver: .events { ... } )      .allOutputs: 연결 가능한 모든 외부 출력 포트를 수신 대상으로 설정   filter: .owned(): 본 앱이 만든 가상 포트는 수신 대상에서 제외   receiver: .events: 이벤트 수신 핸들러     🔹 이벤트 수신 핸들러  receiver: .events { [weak self] events, timeStamp, source in   Task { @MainActor in     for event in events {       self?.received(midiEvent: event)     }   } }      비동기 클로저이며 백그라운드 스레드에서 호출됨   Task { @MainActor in ... }으로 UI 안전하게 업데이트   self는 weak으로 캡처하여 메모리 누수 방지      @Sendable 제한을 피하기 위해 DispatchQueue.main.async 대신 Task { @MainActor } 사용     🔹 수신된 MIDI 이벤트 처리  private func received(midiEvent: MIDIEvent) { ... }      MIDI 이벤트 타입별로 분기 처리                  타입       처리 내용                       .noteOn       음을 재생 + NotificationCenter로 노트 정보 전달                 .noteOff       해당 음을 멈춤 + NotificationCenter로 노트 정보 전달                 .cc       콘트롤 체인지 정보 콘솔 출력                 .programChange       프로그램 체인지 이벤트 출력                 기타       무시              NotificationCenter.default.post(...)는 외부 UI에 키보드 상태 전파에 사용됨     🎹 AudioKit 관련 (간단 요약)     RhodesPianoKey → 기본 오실레이터   AmplitudeEnvelope으로 각각 음의 게이트 제어   최대 11음까지 동시에 연주 가능   .noteOn, .noteOff로 envs[i].openGate() / closeGate() 처리   출력은 Mixer(envs) → engine.output     🧪 동작 요약     앱 실행 → MIDIManager 시작   가상포트 혹은 실제 MIDI 키보드에서 노트를 누름   .noteOn 수신 → noteOn(pitch:) 호출   RhodesPianoKey 연주 시작   .noteOff 수신 → noteOff(pitch:) → 게이트 닫힘     ✅ 사용 예     외부 MIDI 장치, 가상 MIDI 장치, DAW 등에서 이 앱으로 노트 전송 가능   SwiftUI UI에서 MIDIKItKeyboard로 직접 연주도 가능   모든 이벤트는 콘솔과 UI에 실시간 반영됨    "
  },
  
  {
    "title": "AudioKit의 AmplitudeEnvelope",
    "url": "/posts/AmplitudeEnvelope/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-22 19:03:01 +0900",
    "content": "Amplitude Envelope  AmplitudeEnvelope는 AudioKit에서 소리의 볼륨(진폭, amplitude)을 시간에 따라 제어하는 ADSR 엔벨로프(Envelope Generator) 컴포넌트입니다.  이 컴포넌트는 노트의 시작과 끝을 부드럽게 다듬는 역할을 하며, 특히 노트가 갑자기 시작되거나 끊길 때 생기는 “팝(pop)” 소리나 부자연스러운 연결을 방지합니다.    🎛️ AmplitudeEnvelope란?  let env = AmplitudeEnvelope(osc)      입력 노드(osc, 즉 오실레이터나 샘플러 등)를 감싸서, 소리가 나는 동안 진폭을 부드럽게 변화시켜 줌        ADSR 구조:             Attack: 소리가 시작된 후 최대 볼륨까지 도달하는 데 걸리는 시간       Decay: 최대 볼륨에서 지속 볼륨까지 내려가는 시간       Sustain: 키를 누르고 있는 동안 유지되는 볼륨       Release: 키를 뗀 후 소리가 완전히 사라지는 시간             🔧 주요 메서드  ✅ openGate()     **노트 온(Note On)**을 의미   엔벨로프가 Attack → Decay → Sustain 단계로 이동   실제로는 소리가 커지는 과정이 시작됨   env.openGate()   → noteOn()에서 호출됨    ✅ closeGate()     **노트 오프(Note Off)**를 의미   엔벨로프가 Release 단계로 진입 → 서서히 볼륨이 줄어듦   env.closeGate()   → noteOff()에서 호출됨    🧪 예시  env.attackDuration = 0.2 env.releaseDuration = 0.5      openGate() 시: 0.2초 동안 볼륨이 올라가고 유지됨   closeGate() 시: 0.5초 동안 볼륨이 서서히 줄어듦     🎯 왜 중요한가?     부드러운 노트 연결 갑작스러운 진폭 변화 없이 자연스러운 사운드 생성   음악적 표현력 향상 사운드에 감정, 움직임, 생동감을 부여   기본적인 음색 제어 수단 거의 모든 신시사이저에서 기본적으로 존재함     ✅ 요약                 요소       설명                       AmplitudeEnvelope       진폭(볼륨)을 시간에 따라 제어하는 AudioKit 노드                 openGate()       노트 온 (소리 시작)                 closeGate()       노트 오프 (소리 감쇠 시작)                 주 용도       소리의 자연스러운 시작과 끝, 팝 노이즈 제거, 음악적 표현            "
  },
  
  {
    "title": "AudioKit의 Roland TB303 Filter",
    "url": "/posts/Roland_TB303_Filter/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-22 17:36:28 +0900",
    "content": "Roland TB-303 Filter  RolandTB303Filter는 Roland의 전설적인 베이스 신시사이저 TB-303의 필터 사운드를 모방한 레조넌트 로우패스 필터입니다. TB-303은 1980년대에 등장한 아날로그 신스 베이스 머신으로, **애시드 하우스(acid house)**와 전자 음악 장르에서 매우 유명한 독특한 필터 사운드를 제공합니다.    🎛️ Roland TB-303 Filter란?     **1-pole 혹은 4-pole 저역 통과 필터(Low-Pass Filter)**로 고주파수를 잘라내고 저역만 통과시킵니다.   자극적이고 공격적인 레조넌스 특성으로 유명하며, 레조넌스를 극단적으로 높일 때 오실레이터처럼 자가 발진(self-oscillate) 하는 특성도 있음.   SoundpipeAudioKit에 구현된 RolandTB303Filter는 이 클래식한 아날로그 필터의 **사운드 특성과 비선형 동작(디스토션, 비대칭성)**을 디지털로 복제한 것입니다.     ⚙️ 파라미터 목록 및 효과 설명  1. Cutoff Frequency  | 500.0 | 12.0...20000.0 Hz     역할: 필터가 신호를 감쇄하기 시작하는 주파수   낮은 값: 저음만 통과 (우우우 하는 어두운 톤)   높은 값: 고음도 통과 → 밝고 날카로운 사운드      동적 제어 시 “와우 와우” 같은 자동 필터 스윕 효과 가능     2. Resonance  | 0.5 | 0.0...2.0     역할: 컷오프 주파수 근처의 특정 주파수를 강조(공명)   낮은 값 (0.0~0.3): 부드럽고 무난한 필터   중간 값 (0.5~1.0): TB-303 특유의 콱콱 찌르는 듯한 어택 생김   높은 값 (&gt;1.5): 거의 자체 발진에 가까운 강한 휘파람/휘웅 소리      TB-303 스타일 애시드 사운드의 핵심     3. Distortion  | 2.0 | 0.0...4.0     역할: 필터 후단에 적용되는 비선형 오버드라이브 효과   낮은 값: 깨끗하고 자연스러운 필터   중간 값 (~2.0): 살짝 과장된 빈티지 톤   높은 값 (4.0): 거칠고 찢어지는 음색 → 애시드 사운드 강화      디지털 필터의 지나치게 깔끔한 소리를 거칠게 만들기 위한 파라미터     4. Resonance Asymmetry  | 0.5 | 0.0...1.0     역할: 공명 피크(레조넌스)의 파형 비대칭도 제어   0.0: 완전히 대칭적인 필터 반응   1.0: 비대칭 공명 → 비자연적이고 디스토션된 느낌   0.5: TB-303 특유의 약간 찌그러진 공명 표현 가능      미세 조정용 파라미터로, 전체적인 톤의 “캐릭터”를 정함     🧪 파라미터 조합 예시                 Cutoff       Resonance       Distortion       Asymmetry       결과 사운드                       800       0.8       1.5       0.5       기본적인 TB-303 베이스                 200       1.8       3.0       1.0       극단적 애시드 사운드, 거칠고 공격적                 1000       0.2       0.0       0.0       부드럽고 깨끗한 베이스 필터링                 1500       1.0       4.0       0.3       고역 강조, 디스토션된 리드 사운드             ✅ 요약     RolandTB303Filter는 TB-303 베이스 신스의 핵심 요소인 레조넌트 로우패스 필터를 재현한 것   Cutoff + Resonance의 조합이 사운드 캐릭터의 중심   Distortion은 날카로운 빈티지 톤을 더함   Resonance Asymmetry는 필터의 비선형성을 미세하게 조절함     필요하시면 SwiftUI UI 슬라이더와 함께 실시간 제어 가능한 데모 코드도 제공해 드릴 수 있습니다. "
  },
  
  {
    "title": "AudioKit의 DunneSynth",
    "url": "/posts/DunneSynth/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-22 15:58:34 +0900",
    "content": "Dunne Synth  DunneSynthConductor는 AudioKit의 Synth (정확히는 DunneAudioKit의 Dunne Synthesizer)를 제어하는 오디오 신스 컨덕터 클래스입니다. SwiftUI 기반의 UI와 연동하여 신스의 파라미터 조정, 노트 재생, 피크 리미팅, 팝 제거 등 다양한 오디오 처리 제어를 담당합니다.    ✅ 클래스 개요  class DunneSynthConductor: ObservableObject, HasAudioEngine      ObservableObject이므로 SwiftUI 뷰와 상태 바인딩 가능   HasAudioEngine 프로토콜을 통해 engine 및 노드 연결 보장   내부에서 Synth 객체를 사용하여 가상 악기를 구현     ✅ 주요 구성 요소  🔹 let engine = AudioEngine()     AudioKit의 핵심 오디오 처리 엔진   🔹 var instrument = Synth()     DunneAudioKit의 폴리포닉 신스   매핑된 파라미터들을 실시간으로 제어 가능     ✅ noteOn / noteOff  func noteOn(pitch: Pitch, point _: CGPoint)  instrument.play(noteNumber: ..., velocity: 100, channel: 0)      전달된 Pitch를 MIDI note로 변환하여 재생 시작   func noteOff(pitch: Pitch)  instrument.stop(noteNumber: ..., channel: 0)      해당 음 높이의 노트를 정지시킴     ✅ 초기화: init()  🔸 1. engine.output = PeakLimiter(...)     출력단에 PeakLimiter 삽입 → 소리의 과도한 피크 방지   attackTime = 0.001: 피크 감지 후 빠르게 제한   decayTime = 0.001: 제한 해제도 즉시   preGain = 0: 입력 게인을 증폭하지 않음   🔸 2. 팝 노이즈 제거 설정  instrument.releaseDuration = 0.01 instrument.filterReleaseDuration = 10.0 instrument.filterStrength = 40.0      releaseDuration이 너무 짧으면 소리가 갑자기 끊기면서 팝(Pop) 노이즈 발생   filterReleaseDuration을 길게 설정해 필터 계열 소리가 부드럽게 사라지도록 함   filterStrength는 필터 적용 정도 조절     🧪 파라미터 목록  🎛 일반 음성 파라미터                 파라미터       기본값       범위       설명                       Master Volume       1.0       0.0...1.0       전체 출력 볼륨                 Pitch Bend       0.0       -24.0...24.0       실시간 피치 변조 (세미톤 단위)                 Vibrato Depth       0.0       0.0...12.0       비브라토 강도                 Filter Cutoff       1.0       0.0...1.0       필터 컷오프 주파수 (정규화)                 Filter Strength       40.0       0.0...100.0       필터 효과의 강도                 Filter Resonance       0.0       -20.0...20.0       공명(Resonance) 강도             🎛 앰플리튜드 ADSR (Amplitude Envelope)                 파라미터       기본값       범위       설명                       Attack Duration       0.0       0.0...10.0       노트 시작 시 볼륨이 증가하는 시간                 Decay Duration       0.0       0.0...10.0       최대 볼륨에서 지속 볼륨까지 줄어드는 시간                 Sustain Level       1.0       0.0...1.0       키를 누르고 있을 때 유지되는 볼륨                 Release Duration       0.01       0.0...10.0       노트 종료 후 소리가 사라지는 시간             🎛 필터 ADSR (Filter Envelope)                 파라미터       기본값       범위       설명                       Filter Attack Duration       0.0       0.0...10.0       필터가 작동을 시작하는 데 걸리는 시간                 Filter Decay Duration       0.0       0.0...10.0       필터가 최대 효과에서 사라지는 시간                 Filter Sustain Level       1.0       0.0...1.0       필터 효과의 유지 비율                 Filter Release Duration       10.0       0.0...10.0       필터 효과가 사라지는 시간             ✅ 콘솔 출력  instrument.parameters.forEach {   print(\"\\($0.def.name) | \\($0.value) | \\($0.range)\") }      모든 파라미터 이름, 현재값, 범위를 디버깅용으로 출력   UI 연결 확인이나 슬라이더 구성 시 유용함     ✅ 요약  DunneSynthConductor는:     AudioKit의 Dunne 신스를 제어하고   소리의 피크와 팝 노이즈를 제어하며   다양한 신스 파라미터들을 외부 UI와 연결할 수 있게 준비된 컨트롤러입니다.      SwiftUI와 함께 사용할 때 매우 직관적인 신디사이저 앱이나 교육용 악기 UI를 구성하는 데 적합합니다.  "
  },
  
  {
    "title": "AudioKit의 InputDeviceDemo+ChannelRouting",
    "url": "/posts/InputDeviceDemo+ChannelRouting/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-22 15:36:36 +0900",
    "content": "Input Device Demo  이 SwiftUI + AudioKit 코드의 목적은 입력 장치(마이크)를 선택하고 오디오 입력을 시작/정지하는 UI를 제공하는 것입니다. 즉, 여러 마이크 장치가 연결된 환경에서 사용자가 원하는 입력을 선택하고, 마이크 버튼을 눌러 오디오 입력을 켜거나 끌 수 있게 합니다.     Channel/Device Routing 예제와 거의 동일     🔧 클래스: InputDeviceDemoConductor  ✅ 역할: 오디오 입력 장치 관리 + AudioKit 엔진 제어  주요 속성                 변수       설명                       engine       AudioKit의 AudioEngine 인스턴스                 mic       현재 연결된 오디오 입력 노드 (engine.input)                 mixer       입력을 오디오 엔진의 출력으로 연결하기 위한 믹서 노드                 inputDevices       AVAudioSession에서 얻은 사용 가능한 오디오 입력 장치 목록                 inputDeviceList       Picker에 표시할 장치 이름 목록 (portName 배열)           init()     오디오 입력 노드가 있을 경우 mic에 할당하고 Mixer(input)으로 연결   입력 장치 목록(inputDevices)을 불러와 portName을 inputDeviceList에 저장   engine.output = mixer를 통해 믹서를 엔진의 출력으로 설정   switchInput(number:)     선택된 입력 장치를 setPreferredInput(...)으로 변경   변경 전에는 stop() 호출로 엔진을 멈춤     🖼️ View: InputDeviceDemoView  ✅ 역할: UI를 통해 입력 장치 선택 및 오디오 입력 시작/정지  주요 상태 변수                 변수       설명                       isPlaying       오디오 입력이 현재 켜져 있는지 여부                 inputDevice       현재 선택된 입력 장치의 인덱스 (Picker에서 선택됨)             ✅ 뷰 구조 설명  📍 안내 텍스트  Text(\"Please plug in headphones\") Text(\"to avoid a feedback loop.\") Text(\"Then, select a device to start!\")      피드백(하울링)을 피하기 위해 이어폰 사용을 권장     🎛 입력 장치 선택 Picker  Picker(\"Input Device\", selection: $inputDevice) {   ForEach(conductor.inputDeviceList.indices, id: \\.self) { i in     Text(conductor.inputDeviceList[i])       .tag(i)   } }      conductor.inputDeviceList에 저장된 장치 이름을 기반으로 Picker 구성   선택이 변경되면 .onChange(of: inputDevice)를 통해 switchInput(...) 호출     🎤 마이크 on/off 버튼  Button {   isPlaying ? conductor.stop() : conductor.start()   isPlaying.toggle() }      클릭 시 마이크 입력이 시작되거나 종료   버튼의 아이콘은 isPlaying 상태에 따라 \"mic.circle\" 또는 \"mic.circle.fill\"로 바뀜   .resizable() + .frame(...)으로 크기와 정렬 지정     📤 종료 시 동작  .onDisappear {   conductor.stop() }      뷰가 사라질 때 자동으로 오디오 입력 종료     ✅ 전체 동작 요약                 상황       동작                       앱 시작       AudioKit 엔진 초기화 + 사용 가능한 입력 장치 목록 확보                 장치 선택       선택된 장치로 입력 전환 (switchInput)                 버튼 클릭       오디오 입력 시작/정지 (start() / stop())                 뷰 종료       입력 강제 종료             ✅ 확장 가능성     입력 장치별 채널 수 확인   입력을 파일로 녹음   출력 장치 설정도 추가 가능     이 코드는 AudioKit을 활용한 기초 오디오 입출력 제어 구조를 익히기에 적절한 예제입니다. "
  },
  
  {
    "title": "AudioKit의 BaseTapForSpeechRecognition",
    "url": "/posts/BaseTapForSpeechRecognition/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-21 22:06:46 +0900",
    "content": "Base Tap for Speech Recognition  현재 코드에서의 SpeechRecognitionTap과 BaseTapForSpeechRecognitionConductor는 AudioKit과 Speech Framework를 연결하여 실시간으로 마이크 입력을 받아 음성 인식 결과를 텍스트로 출력하는 역할을 수행합니다. 변경된 코드 기준으로 두 클래스의 구성과 동작을 자세히 설명드리겠습니다.    ✅ SpeechRecognitionTap: 마이크 오디오 버퍼를 음성 인식기로 전달  class SpeechRecognitionTap: BaseTap   BaseTap은 AudioKit에서 입력을 분석하기 위한 탭(Tap)을 구현할 때 사용하는 기본 클래스입니다. SpeechRecognitionTap은 이를 상속받아 Apple의 Speech 프레임워크와 연결하는 데 초점을 둡니다.  🔧 주요 프로퍼티                 프로퍼티       설명                       recognitionRequest       오디오 버퍼를 지속적으로 전달받는 객체 (SFSpeechAudioBufferRecognitionRequest)                 analyzer       언어별 음성 인식기 (SFSpeechRecognizer)                 reconitionTask       실제 인식 작업을 수행하는 비동기 작업 (SFSpeechRecognitionTask)           🔨 메서드 설명  setupRecognition(locale:)  func setupRecognition(locale: Locale)      선택한 언어(Locale)에 맞는 SFSpeechRecognizer 인스턴스를 생성   실시간 스트리밍 인식을 위한 SFSpeechAudioBufferRecognitionRequest 초기화   recognitionRequest.shouldReportPartialResults = true 설정으로 중간 결과도 실시간 전달 가능   stopRecognition()  func stopRecognition()      음성 인식 세션을 종료하고 관련 객체를 초기화하여 해제   doHandleTapBlock(buffer:at:)  override func doHandleTapBlock(buffer: AVAudioPCMBuffer, at time: AVAudioTime)      AudioKit에서 자동으로 호출되는 메서드   마이크 입력 버퍼를 recognitionRequest에 전달하여 음성 인식기가 실시간으로 처리하게 함     ✅ BaseTapForSpeechRecognitionConductor: 음성 인식과 오디오 경로를 통합 관리  class BaseTapForSpeechRecognitionConductor: ObservableObject, HasAudioEngine   🔧 주요 프로퍼티                 프로퍼티       설명                       textString       인식된 텍스트 결과                 languageCode       선택된 언어 코드 (en-US, ko-KR, ja-JP)                 srTap       SpeechRecognitionTap 인스턴스                 engine, mic, outputMixer, silencer       AudioKit의 오디오 라우팅 구성 요소                 recognitionTask       음성 인식 작업 참조용           🔨 주요 로직  init()     오디오 엔진과 마이크 입력 초기화   AudioKit의 output = silencer로 출력 경로 설정 (실제 소리는 꺼둔 상태)   srTap.start()로 마이크 데이터 수집 시작   setLanguage(code:)를 호출하여 기본 언어로 음성 인식 시작   setLanguage(code:)  func setLanguage(code: String)      현재 음성 인식 세션을 중단 (stopRecognition, stop)   오디오 엔진을 재시작   새로운 언어로 SFSpeechRecognizer를 초기화하고 recognitionRequest를 설정   recognitionTask를 새로 만들어 textString에 실시간 결과를 반영      핵심: 언어가 바뀔 때 engine, tap, recognizer를 모두 재시작해서 새로운 인식 환경을 구성     🧠 흐름 요약     뷰가 나타남 → init()에서 오디오 및 인식기 설정   사용자가 언어를 선택 → languageCode.didSet → setLanguage(...)   마이크 입력 → doHandleTapBlock → recognitionRequest.append(...)   Apple 음성 인식기에서 처리된 결과가 textString에 실시간 업데이트됨   뷰는 ScrollView를 통해 자동 스크롤하며 결과를 출력     📌 정리                 클래스       역할       핵심 기능                       SpeechRecognitionTap       오디오 → SpeechFramework 전달       마이크 입력 버퍼를 recognitionRequest에 지속 전달                 BaseTapForSpeechRecognitionConductor       오디오 엔진 + 언어 변경 + 인식기 관리       언어 변경 시 자동 재설정, 실시간 결과 처리            "
  },
  
  {
    "title": "Tables",
    "url": "/posts/Tables/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-21 20:11:40 +0900",
    "content": "Tables  이 코드는 AudioKit의 Table 객체들을 생성하고 시각화하는 SwiftUI 뷰입니다. 특히 생성자(init())에서는 다양한 방식으로 **파형 테이블(Table)**을 생성하여 오실레이터 등에서 사용할 수 있도록 준비합니다. 이 Table들은 사인파, 정사각파, 사용자 정의 파형 등의 루프 가능한 단일 사이클 웨이브폼입니다.    ✅ 클래스 개요: TableConductor  이 클래스는 ObservableObject로, UI에서 이 객체의 @Published 값을 관찰할 수 있도록 구성되어 있습니다.  class TableConductor: ObservableObject   📌 속성 목록                 속성 이름       역할                       square       정사각형 파형 테이블 (Square Wave)                 triangle       삼각형 파형 테이블 (Triangle Wave)                 sine       사인파 테이블 (Sine Wave)                 sineHarmonic       하모닉(배음) 기반의 사인파                 fileTable       오디오 파일 기반 파형                 custom       사용자 정의 파형 (난수 + 인덱스 기반)             🧠 생성자 설명: init()  🔹 1. 기본 파형 테이블 생성  square = .init(.square, count: 128) triangle = .init(.triangle, count: 128) sine = .init(.sine, count: 256)      .init(_:count:)는 해당 파형 유형의 테이블을 지정된 크기만큼 생성   count는 테이블 길이 (샘플 수), 2의 제곱수로 설정하는 것이 일반적 (FFT 등 성능에 영향)     🔹 2. 오디오 파일 기반 파형 생성  let url = GlobalSource.piano.url! let file = try! AVAudioFile(forReading: url) fileTable = .init(file: file)!      .sfz 또는 .wav 등의 오디오 파일을 읽어 들여 파형 테이블로 변환   fileTable은 실제 음성 데이터를 기반으로 한 루프 테이블이 됨   주의:    파일 로딩은 오래 걸릴 수 있으므로 생성자에서 직접 하지 말고 task 등을 통해 비동기적으로 실행     🔹 3. 하모닉 오버톤 기반 테이블 생성  let harmonicOvertoneAmplitudes: [Float] = [   0.0, 0.0, 0.016, 0.301 ] sineHarmonic = .init(.harmonic(harmonicOvertoneAmplitudes), phase: 0.75)      AudioKit.TableType.harmonic(_)은 **기본파 + 배음(amplitudes)**으로 구성된 파형 생성   harmonicOvertoneAmplitudes[n]은 (n+1)번째 고조파의 세기   phase: 0.75는 위상 오프셋으로, 시작 지점을 오른쪽으로 75%만큼 이동   예: 배음 = [0.0, 0.0, 0.016, 0.301] → 기본파 없음, 3번째와 4번째 고조파만 있는 파형    🔹 4. 사용자 정의 파형 생성  custom = Table(.sine, count: 256) for i in custom.indices {   custom[i] += Float.random(in: -0.5...0.5) + Float(i) / 2048.0 }      먼저 사인파 테이블을 생성한 뒤, 각 샘플에 무작위 값 + 인덱스 기반 값을 더함   이는 잡음 성분이 섞인 사인파 또는 변형된 파형을 만들기 위한 목적   예:     Float.random(in: -0.5...0.5) → 랜덤 노이즈   Float(i) / 2048.0 → 위치에 따라 증가하는 값     🖼️ 테이블 시각화 뷰 (TableDataView)  struct TableDataView: UIViewRepresentable      AudioKit에서 제공하는 TableView를 UIKit 기반으로 감싸 SwiftUI에서 사용 가능하게 함   table을 주입받아 makeUIView에서 그려줌     📱 SwiftUI 구성 (TableRecipeView)  VStack {   Text(\"Square\")   TableDataView(table: conductor.square)   ... }      각 Table을 Text와 함께 나열하여 시각적으로 비교 가능     ✅ 요약                 생성 방식       설명                       .init(.sine, count: N)       기본형 파형 생성                 .init(file:)       오디오 파일 기반 파형                 .init(.harmonic, phase:)       배음 기반 사용자 정의 파형                 .init + 인덱스 수식       완전 커스텀 파형            "
  },
  
  {
    "title": "CallbackMIDIInstrument",
    "url": "/posts/CallbackMIDIInstrument/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-21 17:59:52 +0900",
    "content": "Callback MIDI Instrument  이 코드는 AudioKit + SwiftUI를 이용해 MIDI 시퀀서 이벤트를 감지하고 사운드폰트로 소리를 재생하며, 동시에 이벤트 로그를 실시간으로 출력하는 학습용 인터랙티브 도구입니다. 핵심 개념은 다음 세 가지입니다:     MIDICallbackInstrument: MIDI 이벤트를 실시간으로 감지하여 로그 출력   MIDISampler: MIDI 노트를 실제로 재생   AppleSequencer: 시간에 따라 MIDI 노트를 자동으로 발생시키는 시퀀서     📦 클래스 구성: CallbackInstrumentConductor  🔧 주요 변수                 변수       설명                       engine       AudioKit 오디오 엔진                 sequencer       AppleSequencer, 박자/템포 기반으로 노트를 자동 재생                 callbacker       MIDI 이벤트를 감지하기 위한 콜백 인스트루먼트                 sampler       사운드폰트 기반으로 소리를 출력하는 샘플러                 tempo       템포 (BPM)                 division       한 마디 내 노트 수 (박자 세분화)                 text       MIDI 이벤트 발생 로그             🔁 초기화 흐름  init() {   setCallback()                             // 콜백 설정   try sampler.loadSoundFont(...)           // 사운드폰트 로드   _ = sequencer.newTrack()                 // 클릭 트랙 (이벤트 감지)   _ = sequencer.newTrack(\"sound\")          // 사운드 트랙 (소리 출력)   createClickTrack()                       // 노트 생성   sequencer.setTempo(...)                  // 템포 설정   engine.output = sampler                  // 출력 설정 }     🧱 createClickTrack(): 실제 트랙 생성     division 만큼 루프를 돌면서 노트를 삽입   clickTrack: callbacker에게 MIDI를 보내 이벤트 로그를 남김   soundTrack: sampler에게 MIDI를 보내 실제 소리 재생   clickTrack.setMIDIOutput(callbacker.midiIn) soundTrack.setMIDIOutput(sampler.midiIn)   노트는 아래 두 지점에 생성됩니다:     첫 박자 시작 (firstPosition)   중간 박자 위치 (secondPosition)     🎯 setCallback(): 콜백 로직  self.callbacker = MIDICallbackInstrument { ... }           .noteOn 발생 시:             현재 시퀀서 시간 (self.sequencer.currentPosition.seconds)과 노트 번호를 로그에 추가             🖥️ SwiftUI 뷰: CallbackInstrumentView  주요 UI 구성:                 UI 요소       설명                       Play, Pause, Rewind       시퀀서 제어                 CookbookKnob       템포 조절                 Slider       division 조절                 ScrollView + Text       콜백 로그 출력 (자동 스크롤 포함)           특징:     division을 변경하면 시퀀서를 멈추고 트랙을 재구성   로그는 아래처럼 출력됨:   Start Note 60 at 0.0000 Start Note 61 at 0.5000 ...      스크롤은 .scrollTo(\"logBottom\")으로 항상 아래로 유지됨     🧪 Preview  #Preview {   CallbackInstrumentView() }   Xcode의 canvas에서 인터랙티브 미리보기 지원    ✅ 요약                 기능       구현 방식                       MIDI 노트 생성       AppleSequencer로 자동 반복 생성                 소리 재생       MIDISampler + 사운드폰트                 이벤트 감지       MIDICallbackInstrument                 로그 출력       SwiftUI Text + ScrollView             🔧 확장 아이디어     각 노트에 따라 다른 소리/색상 출력   외부 MIDI 입력과 연동   division이나 템포 변경 시 실시간 반영   .noteOff도 감지해 note duration 분석  "
  },
  
  {
    "title": "AudioKit의 Waveform",
    "url": "/posts/Waveform/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-20 20:10:19 +0900",
    "content": "Waveform  이 코드는 SwiftUI와 AudioKit, WaveformKit을 활용하여 오디오 파형을 시각화하고, 사용자가 드래그로 재생 범위(start ~ length)를 지정할 수 있는 인터랙티브한 Waveform 플레이어입니다. 각 구성요소에 대해 역할과 동작 방식을 중심으로 자세히 설명드리겠습니다.    ✅ 1. WaveformConductor  class WaveformConductor: ObservableObject, ProcessesPlayerInput   🔹 역할     오디오 재생을 담당하는 AudioKit 기반 오디오 컨트롤러   AudioPlayer, SampleBuffer를 설정하고 제공   UI와 바인딩될 수 있도록 @Published를 통해 samples 공개   🔹 내부 구성     AudioEngine을 통해 오디오 재생 환경 설정   player는 AudioPlayer, .buffer에 Cookbook.sourceBuffer(source: .piano) 를 설정해 .piano 샘플을 사용   player.isLooping = true → 오디오 무한 반복        createSampleBuffer():             AudioBuffer를 Float 배열로 변환해 시각화를 위한 SampleBuffer 생성             ✅ 2. WaveformView  struct WaveformView: View   🔹 역할     파형 시각화 및 드래그 UI 포함   start와 length를 조절해서 재생 범위 지정   실제 오디오 재생은 conductor를 통해 수행됨   🔹 구성 상태 변수                 변수       설명                       conductor       오디오 재생 관리                 start       선택된 구간의 시작 위치 (0.0 ~ 1.0)                 length       선택된 구간의 길이 (0.0 ~ 1.0)                 formatter       숫자 표시용 포맷터             🔸 내부 뷰 구성  ① 파라미터 표시  Text(\"start: \\(start), length: \\(length), end: \\(start + length)\")      현재 재생 범위 (0.0 ~ 1.0 단위) 표시   ② PlayerControlsII  PlayerControlsII(conductor: conductor, source: .piano) { conductor.createSampleBuffer() }      AudioKit Cookbook에서 제공하는 제어용 컨트롤 뷰   .piano 소스를 재생하며, 리셋 버튼 누르면 createSampleBuffer() 호출   ③ Waveform 파형 시각화 1 (큰 화면)  ZStack {   Waveform(samples: conductor.samples)   MinimapView(start: $start, length: $length) }      파형 위에 투명한 사각형(MinimapView)을 덮어 드래그 영역 지정 가능   ④ Waveform 파형 시각화 2 (선택 영역만 강조)  Waveform(   samples: conductor.samples,   start: Int(start * sampleRangeLength),   length: Int(length * sampleRangeLength) )      위에서 선택된 start ~ length 범위만 강조해서 보여줌   ⑤ 라이프사이클  .onAppear(perform: conductor.start) .onDisappear(perform: conductor.stop)      뷰가 등장하면 오디오 재생 시작, 사라지면 정지     ✅ 3. MinimapView  🔹 역할     사용자가 드래그로 재생 범위를 선택할 수 있도록 하는 뷰        두 개의 RoundedRectangle이 있고:             하나는 선택된 영역       하나는 우측 경계 조절 핸들             🔸 주요 상태                 변수       설명                       @Binding var start       시작 위치 (WaveformView에서 바인딩)                 @Binding var length       길이                 @GestureState       드래그 시작 시 기준값 저장용 상태 변수             🔸 내부 구성  GeometryReader { geometry in   RoundedRectangle(...)    // 선택 영역   RoundedRectangle(...)    // 우측 조절 핸들 }   드래그 동작 처리  각 사각형에 .gesture(dragGesture(...))를 추가하여 아래와 같이 처리합니다:  func dragGesture(of mode: DragMode, geometryProxy geometry: GeometryProxy) -&gt; some Gesture                  DragMode       동작                       .selectedArea       사각형 전체를 좌우로 이동 (start 변경)                 .handle       우측만 드래그 → length 조절           드래그 비율 계산:  drag.translation.width / geometry.size.width   clamped(to:)로 start + length ≤ 1.0 제약 유지    🔎 실제 파형 재생 제어는?  현재 WaveformView에서 .onAppear(perform: conductor.start)로 전체 오디오가 루프 재생되며, 선택된 구간만 재생하도록 확장하려면 player.play(from:to:) 메서드로 start와 length 기반 구간 재생을 구현해야 합니다 (이전 답변 참고).    ✅ 전체 흐름 요약  AudioPlayer.loadBuffer(.piano)         ↓ SampleBuffer 생성 → WaveformView에 연결         ↓ Waveform 시각화 + 드래그 제스처로 start/length 조절         ↓ 하단에 선택된 영역 Waveform 강조 표시         ↓ (.onAppear 시 전체 루프 재생)    "
  },
  
  {
    "title": "AudioKit의 SynthesisToolkit(STK)",
    "url": "/posts/SynthesisToolkit(STK)/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-20 16:05:35 +0900",
    "content": "Synthesis Toolkit (STK)  이 코드는 AudioKit, STKAudioKit, SwiftUI를 활용하여 구현된 셰이커(Shaker) 기반 메트로놈 데모 앱입니다. 사용자는 템포, 박자, 음색, 벨로시티 등을 조절할 수 있으며, 시각적인 피드백도 함께 제공합니다. 아래는 구조를 전체적으로 설명한 뒤, 구성 요소별로 자세하게 해석해드립니다.    🧭 전체 개요     STKView: 사용자 인터페이스를 담당하는 SwiftUI 뷰   ShakerConductor: AudioKit 엔진을 설정하고 Sequencer 및 Shaker를 관리하는 오디오 컨트롤러   **SynthesisToolkitView.swift**는 STKAudioKit 기반의 샘플 기반 악기인 Shaker를 사용한 오디오 타이머/메트로놈 구현입니다.     🎼 오디오 구성 (ShakerConductor)  class ShakerConductor: ObservableObject, HasAudioEngine   구성 요소:                 속성       설명                       shaker       STKAudioKit의 셰이커 악기                 callbackInstrument       비트 타이밍마다 호출되는 콜백 악기                 reverb       셰이커에 적용할 리버브                 sequencer       시퀀서 – 박자 및 타이밍 제어                 data       사용자 설정 상태 (isPlaying, tempo, currentBeat 등)           핵심 동작:     data가 바뀔 때마다 didSet에서 시퀀서 재시작 + 템포 반영 + 시퀀스 갱신   updateSequences()에서 박자에 따라 셰이커 노트 시퀀스를 생성   track.sequence.add(...) // 각 박에 음표 추가      callbackInstrument는 UI 업데이트용으로 박마다 콜백을 호출     🧱 SwiftUI 레이아웃 구성 (STKView)  🌐 Orientation-aware Layout  let isLandscape = geometry.size.width &gt; geometry.size.height      화면 비율을 기준으로 가로/세로 모드를 판별   각 모드에 맞는 HStack/VStack 레이아웃을 다르게 설정     ▶️ PlayButtonArea     “Start”/”Stop” 토글 버튼   GeometryReader를 통해 버튼을 가운데에 배치   .position(x: geometry.size.width / 2, y: geometry.size.height / 2)     🎚 TempoSliderArea  Slider(value: $conductor.data.tempo, in: 60.0...240.0)      60~240 BPM 범위 내에서 템포 조절 가능   텍스트로 현재 템포 표시     🎵 BeatSelectArea          두 개의 Stepper UI:             Downbeat (첫 박자에 나올 음색)       Other beats (나머지 박자의 음색)           conductor.data.downbeatNoteNumber += 1      MIDI 노트 번호를 기반으로 ShakerType과 매핑된 음색을 설정함     🔊 VelocityArea  Slider(value: $conductor.data.beatNoteVelocity, in: 0...127)      셰이커의 볼륨 (벨로시티) 조절     🧮 BeatCounterArea     현재 박자 수(timeSignatureTop)만큼 버튼이 생성   현재 박자는 data.currentBeat와 비교해 색상 강조   마지막 “+” 버튼을 눌러 박자 수 증가 가능   GeoCircleButton(...) { conductor.data.timeSignatureTop += 1 }     🟠 GeoCircleButton  GeometryReader { geometry in   let fontSize = size * 0.5      원형 버튼 안에 텍스트가 동적으로 크기 조절됨   .aspectRatio(1, .fit)로 정사각형 → 원 형태 유지     🔬 updateSequences()  track.sequence.add(noteNumber: data.downbeatNoteNumber, ...)      첫 번째 트랙에 메트로놈 셰이커 노트를 추가   두 번째 트랙(콜백 트랙)은 beat마다 CallbackInstrument 콜백 호출   currentBeat 값을 실시간으로 업데이트하여 UI와 동기화     📈 FFTView  FFTView(conductor.reverb)      AudioKitUI의 실시간 주파수 스펙트럼 뷰   reverb로 출력된 오디오를 시각화     🧪 Preview  #Preview {   STKView() }      Xcode canvas에서 실시간 인터랙션 테스트 가능     ✅ 요약                 구성 요소       역할                       ShakerConductor       오디오 엔진, 시퀀서, 셰이커 구성                 STKView       SwiftUI 기반 UI                 .onAppear/.onDisappear       오디오 엔진 시작/종료                 updateSequences()       박자에 따라 음 시퀀스 자동 구성                 GeoCircleButton       박자 표시용 원형 버튼 (터치 가능)                 CallbackInstrument       시퀀서와 UI를 연결하는 핵심 콜백                 FFTView       실시간 시각화            "
  },
  
  {
    "title": "AudioKit의 Keyboard",
    "url": "/posts/Keyboard/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-19 18:13:54 +0900",
    "content": "Keyboard  이 코드는 SwiftUI와 AudioKit Keyboard, Tonic를 활용한 다양한 형태의 가상 키보드 데모 뷰입니다. 사용자는 탭을 전환하며 여러 형태의 키보드를 체험할 수 있고, 실제로 MIDI note를 발생시켜 사운드를 출력할 수 있습니다.    📦 주요 구조  struct KeyboardView: View   🧠 역할 요약     여러 형태의 가상 키보드를 탭(Tab) 기반 UI로 제공   키보드 레이아웃 및 터치 인터랙션을 정의   사용자가 눌렀을 때 InstrumentSFZConductor가 해당 음을 재생     🧭 탭 구성 (TabView)                 탭 이름       기능 설명                       세로 피아노       .verticalIsomorphic / .verticalPiano 키보드 2종 비교                 범위 조절       하단 키보드의 시작~끝 음을 사용자가 조절 가능                 스케일       루트와 스케일에 따라 .isomorphic 키보드 변화                 기타       기타 스타일 키보드 + 커스텀 .isomorphic 키보드             🎹 주요 키보드 레이아웃 종류          .verticalIsomorphic             동일 간격으로 쌓이는 음표 배열       이론적으로 한 방향은 루트, 다른 방향은 음정 간격 유지                .verticalPiano             실제 피아노처럼 흰 건반/검은 건반을 위아래로 배열       비율 조정은 KeyboardSpacingInfo에서 설정                .piano             일반적인 수평 피아노 키보드                .isomorphic             루트/스케일을 기준으로 격자형 배열을 생성 (색다른 시각적 피드백 가능)                .guitar             기타처럼 줄과 프렛을 시각적으로 표현한 키보드             🎚 음정 범위 조절 (범위 조절 탭)     Stepper를 통해 lowNote, highNote를 변경 가능   이 값에 따라 .piano(...) 키보드의 표시 범위가 변경됨     🧩 스케일 변경 (스케일 탭)     root: 기준 음 (NoteClass)   scale: 스케일 종류 (Scale.allCases)   사용자가 스케일이나 루트를 변경하면 .isomorphic 키보드에 반영됨   changeRoot(isIncrement:) 함수로 루트 이동 (C → C# → D ...)     🎨 기타 탭 - 커스텀 키보드 UI  Keyboard(layout: .guitar(), noteOn: ..., noteOff: ...) { pitch, isActivated in   KeyboardKey(...) }      각 키마다 눌렸을 때 색상 및 텍스트를 커스터마이징   PitchColor.newtonian 배열을 사용하여 음정에 따라 색상 구분     🎵 음 재생 처리  InstrumentSFZConductor는 .noteOn, .noteOff를 구현한 오디오 컨트롤러입니다.  추가로:  private extension InstrumentSFZConductor {   func noteOnWithVerticalVelocity(pitch: Pitch, point: CGPoint) { ... } }      Y 좌표(수직 위치)에 따라 Velocity 값을 조절해, 터치 위치에 따른 강약 조절도 가능하게 함     🧰 기타 구조  KeyboardSpacingInfo     .verticalPiano에 쓰이는 간격 정의 정보   흰 건반/검은 건반의 상대 위치와 폭을 수학적으로 정의함   VNodeOutputView     AudioKitUI에서 시각적으로 오디오 출력을 보여주는 뷰 (옵션)     ✅ 전체 흐름 요약     KeyboardView는 다양한 종류의 키보드 UI를 TabView로 제공   각 키보드는 noteOn, noteOff 클로저로 연결되어 실제 음을 재생   사용자는 피아노, 기타, 이소모픽 스케일, 범위조절 등 다양한 상호작용을 할 수 있음   배경색은 다크모드 여부에 따라 동적으로 변경됨     🧪 테스트하려면  #Preview {   KeyboardView() }      SwiftUI 프리뷰에서 직접 인터랙션 테스트 가능     PitchColor.newtonian  PitchColor.newtonian은 AudioKit의 Tonic 라이브러리에서 제공하는 음 높이에 대응하는 색상 배열입니다. 즉, **각 음(pitch class)**에 대해 특정 색을 할당하여 시각적으로 표현할 수 있게 하는 컬러 팔레트 중 하나입니다.    🎨 의미 요약     PitchColor: 음(노트)에 색상을 대응시키기 위한 구조체 또는 열거형   .newtonian: 그중 하나의 색상 배열 (총 12개 — 12 반음에 해당)     📦 실제 정의 예 (간략화 예시)  PitchColor.newtonian = [   Color.red,       // C   Color.orange,    // C#   Color.yellow,    // D   Color.green,     // D#   Color.cyan,      // E   Color.blue,      // F   Color.indigo,    // F#   Color.purple,    // G   Color.pink,      // G#   Color.gray,      // A   Color.black,     // A#   Color.white      // B ]   즉, pitch.pitchClass가 0~11일 때:  Color(PitchColor.newtonian[Int(pitch.pitchClass)])   이 코드는 C부터 B까지 각 음에 대해 정해진 색상을 가져와 키보드 등에서 사용할 수 있게 합니다.    💡 “newtonian” 이름 유래?     이름은 아마도 아이작 뉴턴(Isaac Newton)이 주장했던 음과 색의 대응 이론에서 온 것으로 보입니다.   뉴턴은 7음계(CDEFGAB)와 무지개의 7색(R-O-Y-G-B-I-V)을 대응시킨 바 있습니다.     ✅ 사용 예  let color = PitchColor.newtonian[pitch.pitchClass]      pitch.pitchClass는 0(C), 1(C#), …, 11(B) 중 하나   해당 색상은 키보드의 pressedColor 또는 시각적 강조에 사용     🎯 정리                 요소       의미                       PitchColor       음에 대응하는 색상 팔레트 모음                 .newtonian       C~B 12음에 대한 고정 색상 배열                 용도       키보드 시각화, 스케일 색상 강조 등             Keyboard Spacing 관련 정보  이 코드는 AudioKit Keyboard 라이브러리와 AudioKit Tonic를 사용하여, SwiftUI에서 **세로형 피아노 키보드(Vertical Piano Layout)**를 커스터마이즈한 예제입니다.    🎯 목적 요약     Keyboard(...)를 통해 SwiftUI 내에 가상 피아노 키보드 뷰를 생성   .verticalPiano(...) 레이아웃을 적용하여 세로방향 키보드 구성   음 이름(Letter)별 여백 비율과 흑건(검은 건반) 너비를 직접 지정해서 피아노 키 간격을 커스터마이즈     📦 핵심 구성 요소  1. evenSpacingInitialSpacerRatio  let evenSpacingInitialSpacerRatio: [Letter: CGFloat] = [   .C: 0.0,   .D: 2.0 / 12.0,   .E: 4.0 / 12.0,   .F: 0.0 / 12.0,   .G: 1.0 / 12.0,   .A: 3.0 / 12.0,   .B: 5.0 / 12.0 ]      각 흰 건반(Letter) 앞에 얼마나 여백을 둘지를 비율로 나타냄   주로 검은 건반과의 상대적인 위치 보정에 사용됨   예: D는 앞에 2/12 만큼 띄워짐 → C# 위치 확보용     2. evenSpacingSpacerRatio  let evenSpacingSpacerRatio: [Letter: CGFloat] = [   .C: 7.0 / 12.0,   .D: 7.0 / 12.0,   ... ]      각 흰 건반의 자기 자신 이후에 생길 “스페이서” 길이 비율   기본적으로 일정한 간격(7/12) 유지   실제로는 전체 키 간격 = 앞쪽 initialSpacer + 자기 폭 + 뒤쪽 spacer     3. evenSpacingRelativeBlackKeyWidth  let evenSpacingRelativeBlackKeyWidth: CGFloat = 7.0 / 12.0      검은 건반의 상대 너비 비율   1.0은 흰 건반과 동일한 폭, 0.58 정도가 일반적 현실 비율   여기선 꽤 넓은 검은 건반으로 설정됨     🎹 Keyboard(layout: .verticalPiano(...))  Keyboard(   layout: .verticalPiano(     pitchRange: Pitch(48)...Pitch(77),     initialSpacerRatio: evenSpacingInitialSpacerRatio,     spacerRatio: evenSpacingSpacerRatio,     relativeBlackKeyWidth: evenSpacingRelativeBlackKeyWidth   ) )      .verticalPiano(...): AudioKit Keyboard 라이브러리에서 제공하는 세로방향 건반 레이아웃   pitchRange: C3 (MIDI 48) ~ F6 (MIDI 77) 범위의 키 표시   initialSpacerRatio, spacerRatio: 키 간격 및 여백 설정   relativeBlackKeyWidth: 검은 건반의 너비 조절     🔍 실제 결과     화면에 C3~F6 범위의 세로 피아노 키보드가 표시됨   각 키는 지정된 간격대로 배치됨 (즉, 실제 피아노 비율이 아님 → evenSpacing)   디자인 시 균일 간격/비대칭 조정에 유용     ✅ 정리                 항목       설명                       Keyboard(layout:)       AudioKit의 가상 키보드 SwiftUI 뷰                 .verticalPiano(...)       세로 방향 건반 배치                 initialSpacerRatio       각 키 앞에 얼마나 띄울지 비율 설정                 spacerRatio       각 키 뒤에 얼마나 띄울지 비율 설정                 relativeBlackKeyWidth       검은 건반의 상대적인 폭 (1.0 = 흰 건반과 동일)                 Pitch(48)...Pitch(77)       MIDI 기준 C3~F6 범위의 키 표시            "
  },
  
  {
    "title": "AudioKit의 Flow",
    "url": "/posts/Flow/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-19 16:03:22 +0900",
    "content": "Flow  이 코드는 SwiftUI와 Flow 라이브러리를 이용해 모듈형 오디오 또는 비주얼 그래프 편집기 인터페이스를 구현한 예제입니다. 사용자는 “Simple” 또는 “Random” 패치 구성을 선택하여 그래프 형태로 노드(Node)와 와이어(Wire)를 시각적으로 다룰 수 있습니다.    🧠 핵심 클래스: FlowConductor  ObservableObject를 채택한 뷰 모델로서, FlowView에서 사용됩니다.  🔸 주요 프로퍼티     patch: Patch: 현재 그래프 구조 (노드 + 와이어 집합)   selection: Set&lt;NodeIndex&gt;: 사용자가 현재 선택한 노드들   segIndex: Int: “Simple” 또는 “Random” 구성을 고르는 Segment Picker의 선택 인덱스   🔸 init()     뷰가 처음 생성될 때 simplePatch()를 호출해 기본 구성의 패치를 설정     🔧 simplePatch() 함수  간단한 오디오/비주얼 흐름 예제를 구성합니다:          노드 생성             generator, processor, mixer, output 총 6개 노드를 생성       generator와 processor 각각 두 개씩 → 총 6개 노드       각 노드는 이름, 입력/출력 포트, 색상 정보를 가짐                와이어 연결             Wire(from: OutputID, to: InputID) 형태로 노드 간 연결       각 와이어는 출력 포트 → 입력 포트를 의미           예:      Wire(from: OutputID(0, 0), to: InputID(1, 0))           → 첫 번째 generator(노드 0)의 출력이 첫 번째 processor(노드 1)의 입력으로 연결됨           배치 레이아웃 설정             마지막 노드(출력 노드, 인덱스 5)를 기준 위치 (800, 50)에 고정       recursiveLayout을 통해 나머지 노드들이 자동 배치됨                **self.patch = patch**로 최종 구성 반영        🔀 randomPatch() 함수     무작위 노드 50개와 와이어 50개를 생성하여 복잡한 그래프 구성 예제를 제공   각 노드는 랜덤한 위치 및 색상   각 와이어는 랜덤하게 다른 노드와 연결됨   이 함수는 segIndex가 1일 때 실행됩니다.    🖼️ FlowView: SwiftUI View  구조:  VStack {   Picker(...)        // \"Simple\" 또는 \"Random\" 선택   NodeEditor(...)    // Flow 라이브러리의 메인 편집기 뷰 }      .onAppear: 화면이 나타날 때 가로모드 강제 전환   .onDisappear: 뷰가 사라질 때 방향 제한 해제   Picker(\"Select the Patch\", selection: $conductor.segIndex)     사용자가 선택한 값(segIndex)에 따라 simplePatch() 또는 randomPatch()가 자동 호출됨     🧭 NodeEditor(...)     Flow 라이브러리의 메인 UI로, 노드와 와이어를 시각적으로 편집할 수 있게 하는 컴포넌트   $conductor.patch, $conductor.selection과 바인딩되어 실시간 편집 가능     🧪 기타     #Preview: SwiftUI Preview용 코드   forceOrientation(...): 가로모드로 화면 강제 전환 (별도 구현되어야 함)     ✅ 요약                 구성 요소       역할                       FlowConductor       노드 및 연결 정보를 관리하는 뷰 모델                 simplePatch()       미리 정의된 간단한 노드 구성 설정                 randomPatch()       50개의 랜덤 노드 및 연결 구성                 NodeEditor       노드 기반 UI를 표시하고 편집 가능하게 하는 뷰                 segIndex       SegmentPicker로 사용자가 선택한 구성 판단                 .onAppear       뷰 진입 시 가로모드 강제             Simple Patch 동작 해석  Flow 라이브러리에서 Wire는 두 노드를 연결하는 선을 의미합니다. 실제로는 한 노드의 출력 포트(OutputID)가 다른 노드의 입력 포트(InputID)로 연결되는 구조입니다.  let wires = Set([   Wire(from: OutputID(0, 0), to: InputID(1, 0)), // gen 1 -&gt; proc 1   Wire(from: OutputID(1, 0), to: InputID(4, 0)), // proc 1 -&gt; mixer   Wire(from: OutputID(2, 0), to: InputID(3, 0)), // gen 2 -&gt; proc 2   Wire(from: OutputID(3, 0), to: InputID(4, 1)), // proc 2 -&gt; mixer   Wire(from: OutputID(4, 0), to: InputID(5, 0)), // mixer -&gt; output ])   이제 이걸 기반으로 Wire 간의 동작 흐름을 실제 예제로 해석해보겠습니다.    🎯 노드 구성 요약 (nodes 배열 순서)                 인덱스       노드 이름       타입       입력       출력                       0       generator       source       없음       out                 1       processor       effect       in       out                 2       generator       source       없음       out                 3       processor       effect       in       out                 4       mixer       utility       in1, in2       out                 5       output       sink       in       없음             🔗 Wire 흐름 예제 해석  1. Wire(from: OutputID(0, 0), to: InputID(1, 0))     generator 1 → processor 1   generator 1의 첫 번째 출력(\"out\") → processor 1의 첫 번째 입력(\"in\")   ▶️ 첫 번째 오디오 소스가 이펙터로 들어감     2. Wire(from: OutputID(1, 0), to: InputID(4, 0))     processor 1 → mixer (in1)   processor 1 출력 → mixer의 첫 번째 입력(\"in1\")   ▶️ 이펙트 처리된 소리가 믹서로 들어감     3. Wire(from: OutputID(2, 0), to: InputID(3, 0))     generator 2 → processor 2   두 번째 소스 → 두 번째 이펙터     4. Wire(from: OutputID(3, 0), to: InputID(4, 1))     processor 2 → mixer (in2)   ▶️ 이펙트 처리된 두 번째 소리가 믹서로 들어감     5. Wire(from: OutputID(4, 0), to: InputID(5, 0))     mixer → output   믹서의 결과가 최종 출력 노드로 이동     📊 시각적 흐름 요약 (왼쪽 → 오른쪽)  gen1 → proc1 ┐              ├→ mixer → output gen2 → proc2 ┘      두 개의 소스 → 각자 이펙트 처리 → 믹서로 병합 → 최종 출력   이 구조는 이중 채널 처리, 병렬 이펙팅 후 믹싱 등의 오디오 워크플로우와 유사합니다     🧩 실제 활용 시 예시 (AudioKit 연결 예)                 노드       연결 대상 (AudioKit)                       generator       Oscillator() 또는 Player()                 processor       LowPassFilter, Reverb 등                 mixer       Mixer()                 output       engine.output = ...             ✅ 정리                 Wire 구성       의미                       OutputID(a, x)       a번 노드의 x번째 출력 포트                 InputID(b, y)       b번 노드의 y번째 입력 포트                 Wire(from: ..., to: ...)       a번 노드 → b번 노드 간 연결선           이 구조는 실제 오디오 시그널 플로우(신호 흐름)를 시각화하거나, 실시간 처리 체인을 구성할 때 매우 직관적입니다.   "
  },
  
  {
    "title": "AudioKit의 Playlist",
    "url": "/posts/Playlist/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-18 20:12:40 +0900",
    "content": "Playlist  이 코드는 AudioKit과 SwiftUI를 사용해 만든 간단한 오디오 플레이리스트 앱입니다. 사용자가 폴더를 선택하면 그 안에 있는 오디오 파일 목록이 표시되고, 클릭 시 선택한 파일을 재생하거나 중지할 수 있습니다.    🧠 주요 클래스: PlaylistConductor  ▶ 역할     오디오 재생 관리 (AudioEngine, AudioPlayer)   폴더에서 오디오 파일 불러오기   현재 재생 중인 파일 상태 추적     📌 내부 구조 설명  struct AudioFile: Identifiable, Hashable      개별 오디오 파일을 표현   id는 고유 식별자   url: 파일 경로   name: 파일 이름 (확장자 없이)     let player = AudioPlayer()      AudioKit의 단순 재생기   .play(), .stop(), .load(url:)로 파일 제어     @Published var loadedFile: AudioFile?      현재 재생 중인 파일   SwiftUI에서 상태 변화 감지를 위해 사용     🎧 togglePlayback(of:)     파일이 재생 중이면 중지하고 loadedFile = nil   다른 파일이 선택되면 현재 재생 중지 후 새 파일 재생   아무 것도 안 재생 중이면 바로 재생     🎼 loadStartPlayback(of:)     AVAudioFile을 로드하고 재생 시작   loadedFile에 현재 재생 중 파일 저장     📂 getAudioFiles(in:)     주어진 폴더 경로에서 지원하는 오디오 파일 확장자만 필터링하여 리스트 생성     ✅ playbackCompletionHandler     현재 파일이 끝나면 loadedFile = nil → UI에서 상태 변경 반영 가능     🖼️ 뷰 구조: PlaylistView  ▶ 주요 기능     폴더 열기 버튼   재생 상태에 따라 파형 표시 또는 설명 텍스트 표시   오디오 파일 리스트 렌더링 및 버튼 클릭 처리     💡 주요 UI 요소  ZStack { if isPlaying ... }     재생 중이면 NodeRollingView로 파형 표시   아니면 안내 문구 표시   .transition(.opacity) + .animation(...)으로 자연스럽게 페이드 전환     Button(\"Select Playlist Folder\")     폴더 선택을 트리거   .fileImporter에서 폴더 선택 → 보안 권한 확보 후 파일 목록 읽기     List { ForEach(conductor.audioFiles ...) }     오디오 파일 이름 목록   클릭 시 togglePlayback() 호출   현재 재생 중인 항목에는 \"play.fill\" 아이콘 표시     ✅ 전체 앱 흐름 요약     앱 실행 후 [Select Playlist Folder] 버튼 클릭   폴더 선택 → 오디오 파일 목록 생성   리스트에서 오디오 파일 클릭 → 재생   같은 파일 재클릭 → 정지   다른 파일 클릭 → 현재 정지 후 새 파일 재생   파일 재생 완료 시 자동으로 정지 상태로 전환     🧩 사용 기술 요약                 기술       설명                       AudioKit       오디오 재생 기능 구현                 AudioPlayer       단일 오디오 파일 재생                 SwiftUI       UI 구성 및 상태 관리                 @Published       상태 변경 UI 반영                 transition(.opacity)       재생 상태 변화에 따른 페이드 효과                 fileImporter       보안 폴더 접근 UI 지원             필요하시면 다음도 설명드릴 수 있습니다:     NodeRollingView가 실제로 어떤 시각화를 렌더링하는지   재생 중 자동으로 스크롤되는 리스트 구현 방법   여러 파일을 큐처럼 연속 재생하는 기능 추가 방법  "
  },
  
  {
    "title": "AudioKit의 MultiSegmentPlayer",
    "url": "/posts/MultiSegmentPlayer/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-18 19:11:56 +0900",
    "content": "MultiSegment Player  이 코드는 AudioKit을 기반으로 여러 오디오 파일을 연속 재생하며, 실시간 RMS 기반 시각화와 플레이헤드를 포함한 타임라인 UI를 보여주는 멀티 세그먼트 오디오 플레이어 구현입니다.  MultiSegmentPlayerConductor는 오디오 제어 로직을 담당하고, MultiSegmentPlayerView는 이를 화면에 표시합니다.    🧠 전체 구조 개요     ✅ MultiSegmentPlayerConductor: 오디오 재생, 시간 추적, RMS 설정, 세그먼트 생성, 오디오 세션 구성 등 핵심 로직   ✅ MultiSegmentPlayerView: 시각적 UI (파형, 플레이헤드, 버튼 등)   ✅ RMS: 소리의 실제 감지 크기를 표현하는 지표 (RMS = Root Mean Square)     🔷 MultiSegmentPlayerConductor 클래스  1. 오디오 구성 요소     engine: AudioKit의 오디오 엔진   player: 세그먼트 기반의 오디오 플레이어 (여러 오디오 파일 재생 가능)   2. 시간 관련 변수     timer: 0.05초 주기로 checkTime() 호출   timePrevious: 이전 시간 저장 (현재 시간과 비교해 delta time 계산)   timestamp: 재생 시간 누적값 (@Published로 UI와 바인딩됨)   endTime: 전체 오디오 길이   3. RMS 시각화 제어  RMS (Root Mean Square) RMS (Root Mean Square)는 신호의 전반적인 에너지 크기(=지속적인 평균적인 세기)를 나타내는 통계적 측정값입니다. 오디오에서는 “소리의 실제 감지되는 볼륨 크기”에 가까운 값으로 간주됩니다.    오디오 파형은 시간에 따라 위아래로 진동하는 파형인데, 단순 평균(mean)은 0이 되기 때문에 사용이 어렵습니다.   대신, 각 샘플의 제곱 → 평균 → 제곱근을 구해 전체적인 크기를 양수로 계산하는 것이 RMS입니다.   RMS는 Peak보다 낮지만 실제 듣는 소리의 크기와 유사합니다.   변수 설명    rmsFramePerSecond: 1초에 몇 개의 RMS 샘플을 만들지 결정 → 높을수록 부드러운 파형   pixelsPerRMS: RMS 하나당 몇 픽셀 차지할지 → 시각화의 밀도 제어   4. 재생 상태 (isPlaying)     true: 시간 초기화 후 player.playSegments() 호출 → 세그먼트 순차 재생 시작   false: player.stop() → 재생 중지     5. 주요 함수     currentUptimeSeconds(): 시스템 부팅 이후 경과 시간(초 단위) 계산   checkTime(): 매 프레임마다 시간 흐름 계산하여 timestamp 업데이트   createSegments(): 여러 오디오 파일을 시간차를 두고 연속 배치   setEndTime(): 마지막 세그먼트의 끝 시간을 기준으로 총 길이 설정   setAudioSessionCategoriesWithOptions(): 오디오 세션 설정 (스피커, 블루투스 등)   startAudioEngine(): AudioKit 엔진 시작   setTimer(): 타이머 시작     🔶 MultiSegmentPlayerView 구조체  구성 요소     TrackView: RMS 기반 파형을 그리는 커스텀 뷰   Rectangle(): 플레이헤드 (현재 재생 위치를 나타내는 빨간 선)   PlayPauseButton: 재생/일시정지 버튼 (아이콘 변경)   currentTimeText: 현재 시간과 총 시간 표시 (\"2.4 of 4.7\" 형식)   핵심 연산 프로퍼티  var currentPlayPosition: CGFloat {   let pixelsPerSecond = conductor.pixelsPerRMS * conductor.rmsFramePerSecond   return conductor.timestamp * pixelsPerSecond - playheadWidth }      timestamp를 픽셀 단위 위치로 환산 → 플레이헤드를 왼쪽으로 이동시킴   playheadWidth만큼 왼쪽으로 보정해서 중앙 정렬     🔧 실행 흐름 요약     onAppear 시 conductor.start() → 오디오 엔진 시작   Play 누르면 isPlaying = true → player.playSegments() 실행 + timestamp 시작   Timer가 checkTime()을 주기적으로 호출 → timestamp 증가   timestamp 값에 따라 플레이헤드 위치 및 시간 텍스트 실시간 갱신   RMS 파형은 TrackView에서 표시됨 (코드 미포함)     🎯 이 코드가 하는 일     다수의 오디오 파일을 시간차를 두고 이어붙여 순차 재생   RMS 기반 시각화 구현을 위한 값 설정   재생 시간에 따라 플레이헤드를 이동   SwiftUI UI와 오디오 재생이 실시간으로 연동    "
  },
  
  {
    "title": "AudioKit의 PhaseDistortionOscillator",
    "url": "/posts/PhaseDistortionOscillator/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-16 18:19:04 +0900",
    "content": "Phase Distortion Oscillator  PhaseDistortionOscillator는 이름 그대로 **위상 왜곡(Phase Distortion)**을 통해 기본 파형을 변형하여 더 복잡하고 독특한 음색을 생성하는 오실레이터입니다. 이는 전통적인 웨이브셰이핑(waveshaping)과는 달리, 파형의 위상 자체를 비선형적으로 조절함으로써 음색의 질감을 변화시킵니다.  이 오실레이터는 Casio CZ 시리즈 신디사이저에서 유래된 위상 왜곡 방식과 유사하며, 단순한 사인파를 다양한 복잡한 파형처럼 들리게 만들 수 있습니다.    🔊 PhaseDistortionOscillator란?     기본 파형(주로 사인파)을 위상 왜곡하여 새로운 음색을 만드는 신디사이저 기법   단일 오실레이터만으로도 복잡한 하모닉 구조의 사운드를 만들 수 있음   모듈레이션 없이도 독특한 전자음, 퍼커시브 사운드, 디지털 캐릭터 음색 구현 가능     🎛 파라미터 설명  1. Frequency | 440.0 | 0.0…20000.0     소리의 기본 피치(주파수)   440Hz는 A4, 값이 높을수록 고음     2. Amplitude | 0.25 | 0.0…10.0     출력 볼륨   일반적으로 0.0 ~ 1.0 사이 사용 (10은 매우 큼)     3. Phase distortion | 0.0 | -1.0…1.0     위상 왜곡의 강도 및 방향을 조절하는 핵심 파라미터   0.0: 왜곡 없음 → 순수한 기본파   양수로 갈수록: 파형의 전반부를 압축하고 후반부를 확장 → 밝고 날카로운 톤   음수로 갈수록: 파형의 후반부를 압축하고 전반부를 확장 → 어둡고 둔탁한 톤   ±1.0에 가까울수록 더 극적인 왜곡 효과, 금속성 또는 디지털 캐릭터 강조     4. Frequency offset | 0.0 | -1000.0…1000.0     기본 주파수에 더하거나 빼는 미세 조정   비브라토 느낌이나 피치 흔들림 등에 활용 가능     5. Detuning multiplier | 1.0 | 0.9…1.11     주파수에 비율을 곱해 미세하게 음정을 조정   1.0 기준으로 ± 방향으로 디튠 → 두 개 이상의 오실레이터와 섞으면 코러스, 유니즌, 풍성한 사운드 가능     🎧 음향적 특징 요약     phaseDistortion만 조절해도 단순한 사인파를 구형파, 톱니파 같은 복잡한 음색으로 변형 가능   다른 변조기(LFO, ADSR 등) 없이도 사운드 캐릭터에 큰 변화를 줄 수 있음   위상 왜곡 특유의 날카로움, 디지털스러움, 퍼커시브한 성질로 베이스, 리드, 효과음에 활용하기 좋음     🧠 언제 사용하면 좋은가?     단일 오실레이터로 풍부하고 캐릭터 있는 음색을 만들고 싶을 때   아날로그보다 디지털 느낌이 필요한 레트로 게임음, 베이스, 벨, 퍼커션 사운드 만들 때   phaseDistortion을 LFO로 모듈레이션하면 움직이는 음색도 쉽게 구현 가능    "
  },
  
  {
    "title": "AudioKit의 PWM(Pulse_Width_Modulation)Oscillator",
    "url": "/posts/PWM(Pulse_Width_Modulation)Oscillator/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-16 18:19:04 +0900",
    "content": "PWM (Pulse Width Modulation) Oscillator  PWMOscillator는 **Pulse Width Modulation (펄스 폭 변조)**을 지원하는 오실레이터로, 기본적으로 **구형파(square wave)**를 생성하며, **펄스 폭(pulse width)**을 조절하여 음색의 질감을 변화시킬 수 있는 신디사이저 도구입니다.  이 오실레이터는 단순한 사각파보다 훨씬 더 풍부하고 움직임 있는 음색을 만들어낼 수 있어, 베이스, 리드, 효과음에 자주 사용됩니다.    🔊 PWM (Pulse Width Modulation) Oscillator란?     펄스파(구형파)의 “폭”을 시간적으로 조절하여 음색을 변화시키는 방식   펄스 폭이 바뀜에 따라 하모닉(배음) 구조가 달라지므로 음색도 바뀜   일정한 속도로 펄스폭이 변화하면 “움직이는” 사운드, 즉 애니메이션된 음색을 만들 수 있음     🎛 파라미터 설명  1. Frequency | 440.0 | 0.0…20000.0     소리의 기본 피치   예: 440Hz는 A4음   값이 높을수록 고음, 낮을수록 저음     2. Amplitude | 0.25 | 0.0…10.0     소리의 크기 (볼륨)   보통 0.0 ~ 1.0 사이에서 사용 (10은 매우 큼)     3. Pulse Width | 0.5 | 0.0…1.0     한 주기 내에서 펄스(신호)가 얼마나 길게 유지되는지를 비율로 표현   0.5: 정확히 50% → 일반적인 구형파 (대칭 구조)   0.0 또는 1.0: 펄스가 거의 존재하지 않음 → 소리 거의 사라짐   값을 움직이면 배음 구조가 바뀌며 얇거나 날카롭고, 때론 코러스 같은 움직이는 느낌을 줄 수 있음   LFO와 연동하면 “PWM 사운드 특유의 웅웅거리는 질감” 구현 가능     4. Frequency offset | 0.0 | -1000.0…1000.0     기본 주파수에 ± 값으로 미세 조정   피치를 약간 흔들거나 튜닝 보정 용도로 사용     5. Frequency detuning multiplier | 1.0 | 0.9…1.11     주파수에 곱해지는 비율   약간만 차이를 주면 풍부하고 넓은 사운드 (코러스/유니즌) 생성 가능     🎧 음향적 특징 요약     pulseWidth 조절만으로도 다양한 캐릭터의 사각파 음색 생성 가능   모듈레이션(LFO 등)을 통해 pulseWidth를 자동으로 변화시키면, 클래식 아날로그 신디사이저의 PWM 사운드 재현 가능   정적인 구형파보다 훨씬 동적이고 풍부한 소리     🧠 언제 사용하면 좋은가?     베이스: 무게감 있고 존재감 있는 저음   리드: 고음역에서 밝고 강한 존재감을 가진 톤   애니메이션된 음색: 움직이는 텍스처나 드론 사운드     🔁 확장 아이디어     pulseWidth를 LFO로 실시간 모듈레이션하면 PWM 특유의 웅웅거리는 질감 구현 가능   detuning과 함께 사용하면 코러스 또는 유니즌 풍성함   여러 PWMOscillator를 쌓아서 Super PWM Lead, Fat PWM Bass 같은 고급 사운드 구현 가능     필요하시면 SwiftUI UI에서 pulseWidth를 LFO나 슬라이더와 연동해 실시간으로 조절하는 예제도 제공해 드릴 수 있습니다. "
  },
  
  {
    "title": "AudioKit의 Oscillator",
    "url": "/posts/Oscillator/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-16 18:19:04 +0900",
    "content": "Oscillator  이 Oscillator는 가장 기본적인 오디오 신호 생성기(진동기)로, 사인파, 톱니파, 구형파, 삼각파 등 기본 파형을 생성하며 주파수와 진폭을 제어할 수 있습니다. 주로 톤 테스트, 신스 기본 파형, 이펙트 기초 등을 구현할 때 사용됩니다.    🔊 기본 Oscillator란?     복잡한 모듈 없이 단순한 주기적인 파형을 생성하는 기초 오실레이터        파형의 종류는 설정 가능하며, 각 파형은 고유한 음색 특성을 가짐:             사인파: 순수한 음색, 고조파 없음       톱니파: 강한 고조파 포함 → 거칠고 밝은 소리       구형파: 홀수 배 고조파 → 전자음, 게임 사운드에 적합       삼각파: 약한 고조파 → 부드러운 음색             🎛 파라미터 설명  1. Frequency | 440.0 | 0.0…20000.0     생성할 음의 주파수 (Hz)   440Hz는 A4 (기준음)   값이 커질수록 소리가 더 높아짐   가청 범위는 약 20Hz ~ 20,000Hz     2. Amplitude | 0.25 | 0.0…10.0     출력되는 소리의 볼륨 (진폭)   일반적으로 0.0 ~ 1.0 사이를 사용 (10은 매우 큼)   0.0은 무음, 1.0은 꽤 큰 음량     3. Frequency offset | 0.0 | -1000.0…1000.0     설정된 주파수에 더하거나 빼는 정수 단위의 조정값   예: 기본 주파수가 440Hz이고 offset이 +50이면 실제 주파수는 490Hz   빠르게 변조하면 비브라토 또는 불안정한 느낌 연출 가능     4. Frequency detuning multiplier | 1.0 | 0.9…1.11     주파수에 곱해지는 비율 값   1.0보다 작으면 플랫(flat), 크면 샤프(sharp)한 소리   offset보다 미세하게 조정할 수 있어 디튠, 코러스, 두께감 추가에 유용     🎧 활용 예시     단일 테스트 톤 (예: 440Hz 사인파)   기초 신디사이저 소리 제작   offset과 detune을 함께 사용하여 풍부한 유니즌 느낌, 또는 드론 사운드 구현   주파수와 진폭을 LFO, ADSR 등과 연동해 모듈레이션 효과 추가 가능     ✅ 요약                 파라미터       역할       값 변화 시 효과                       Frequency       음높이       값이 클수록 고음                 Amplitude       소리 크기       1.0 이상이면 클리핑 주의                 Frequency offset       피치 보정       ± 값으로 미세 튜닝                 Frequency detuning multiplier       디튠       1.0 기준 ± 소리의 흔들림/풍성함             Oscillator는 단순하지만 모든 신디사이저의 기반이 되는 기초 진동기로, 다른 필터나 이펙터와 조합하면 무궁무진한 사운드 디자인이 가능합니다. "
  },
  
  {
    "title": "AudioKit의 MorphingOscillator",
    "url": "/posts/MorphingOscillator/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-16 18:19:04 +0900",
    "content": "Morphing Oscillator  MorphingOscillator는 **여러 파형 사이를 부드럽게 연결하며 변형(morph)**할 수 있는 오실레이터입니다. 기본적으로 사인파, 삼각파, 구형파, 톱니파 등 서로 다른 파형들을 연속적으로 섞어가며 새로운 음색을 생성할 수 있습니다. 이는 일반적인 오실레이터보다 훨씬 유기적이고 복합적인 소리 디자인이 가능합니다.    🔊 Morphing Oscillator란?     여러 개의 기본 파형을 하나의 연속된 스펙트럼으로 다룰 수 있는 오실레이터   Index 파라미터를 조절해 파형 간의 중간 단계나 혼합된 음색을 생성   음색 모듈레이션, 애니메이션, 또는 동적인 음색 변화에 매우 유용     🎛 파라미터 설명 (이름 | 기본값 | 범위)  1. Frequency | 440.0 | 0.0…22050.0     소리의 기본 **피치(높낮이)**를 결정하는 주파수   값이 높을수록 고음, 낮을수록 저음   440Hz는 표준 A음 (A4), 880Hz는 한 옥타브 위     2. Amplitude | 0.25 | 0.0…1.0     소리의 **크기 (볼륨)**을 조절   0이면 무음, 1이면 최대 출력   일반적으로 0.2~0.5 사이가 적당한 청감 레벨     3. Index | 0.0 | 0.0…3.0     파형을 섞는 위치를 결정하는 가장 중요한 파라미터        보통 4개의 파형이 배열되어 있고, 인덱스는 0~3까지의 실수로 해당 파형을 혼합             예: 0.0 → 첫 번째 파형 (예: 사인파)       1.5 → 두 번째와 세 번째 파형 중간 혼합       3.0 → 네 번째 파형           값을 애니메이션처럼 변화시키면 파형이 유기적으로 변형되어 리드, 패드, 베이스 등에 특색 있는 모션 효과를 줄 수 있음     4. Detuning Offset | 0.0 | -1000.0…1000.0     기본 주파수에 정수 단위로 더하거나 빼서 피치를 미세 조정   예: +5면 피치가 약간 높아짐 (샤프), -5면 약간 낮아짐 (플랫)   여러 오실레이터와 함께 쓸 경우 불협화음 또는 풍부한 유니즌 느낌을 만듦     5. Detuning Multiplier | 1.0 | 0.9…1.11     주파수에 곱셈으로 작용하는 상대적 미세 조정값   1.0이면 변화 없음, 1.02면 약간 높은 피치   Offset과 함께 사용하면 더 입체적인 피치 모듈레이션 가능     🎧 음향적 특징 요약     일반 오실레이터보다 훨씬 유연하고 풍부한 음색 조절이 가능   Index를 시간에 따라 변조하면 리드 사운드에 생동감, 패드에 입체감 부여 가능   Detuning 파라미터는 여러 오실레이터와 섞을 때 코러스 효과나 아날로그 신디 특유의 따뜻함을 더할 수 있음     🧠 언제 사용하면 좋은가?     다양한 음색의 모핑 리드, 패드, 신스 베이스를 만들고 싶을 때   키보드 누를 때마다 음색이 바뀌거나, 터치의 위치/속도에 따라 파형이 달라지도록 만들고 싶을 때   단조로운 사인파/톱니파보다 더 감각적이고 동적인 사운드 디자인을 하고 싶을 때    "
  },
  
  {
    "title": "AudioKit의 FMOscillator",
    "url": "/posts/FMOscillator/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-16 18:19:04 +0900",
    "content": "FM Oscillator  이 코드는 AudioKit의 FMOscillator를 사용하여 FM 신디사이시스(Frequency Modulation Synthesis) 기반의 소리를 생성하고 제어하는 구조입니다.    🎧 FM 신디사이시스란?     FM(Frequency Modulation) 신디사이시스는 한 오실레이터의 주파수를 다른 오실레이터로 변조하여 복잡하고 풍부한 음색을 만드는 기법입니다.   기본적인 진동기(carrier)에 또 다른 진동기(modulator)를 적용하여, 맑고 금속성, 벨소리 같은 사운드, 혹은 혼잡하고 거친 질감을 만들 수 있습니다.     🔊 FMOscillator의 음향 요소  이 오실레이터는 총 5가지 주요 파라미터로 음색을 제어할 수 있습니다:  1. Base Frequency     사운드의 기본 피치를 결정합니다.   예: 440Hz는 표준 A음.   이 값이 낮으면 저음, 높으면 고음.   2. Carrier Multiplier     기본 주파수(Base Frequency)에 곱해져 실제로 들리는 주파수를 결정합니다.   1.0이면 그대로, 2.0이면 한 옥타브 위, 0.5면 한 옥타브 아래.   음악적으로 **음높이의 성격(멜로디성)**에 영향을 줍니다.   3. Modulating Multiplier     변조 신호의 주파수를 결정합니다.   이 값이 클수록 변조 속도가 빨라지고, 음색이 복잡해짐.   소리의 질감이나 색깔, 스펙트럼 폭에 큰 영향을 줌.   4. Modulation Index     변조의 강도를 조절합니다.   값이 높을수록 사운드가 더 거칠고 풍부하며 금속성으로 변함.   낮은 값은 순한 파형(예: 거의 사인파), 높은 값은 지글거리는 느낌(예: 벨, 피리, 퍼커션)   5. Amplitude     최종 출력 음량을 조절합니다.   값이 클수록 볼륨이 큼.     🎛 Presets (음향 성격)  각 프리셋은 특정한 음색을 만들어냅니다:     “Stun Ray”: 아주 높은 carrier multiplier로 매우 고음역의 날카로운 전자음   “Fog Horn”: 저주파 + 약한 변조로 느리고 깊은 혼소리   “Buzzer”: 강한 변조로 거칠고 전기적 질감   “Spiral”: 저주파 + 높은 carrier multiplier → 초저음 위에 고조파 강조, 묘한 공간감   “Wobble”: 저주파 + 느린 변조 → 느릿하고 파도처럼 흔들리는 소리     🎮 인터랙션 구조     사용자가 Preset 버튼을 누르면 각 설정이 적용되고, 소리가 즉시 재생됩니다.   “Random” 버튼은 랜덤 파라미터로 실험적인 음색을 생성 → 새로운 사운드 실험 가능   Parameter 슬라이더를 통해 실시간으로 음색 조절 → 라이브 퍼포먼스나 소리 디자인에 적합     🧠 왜 유용한가?     FM 사운드는 단순한 필터나 진동기만으로 만들 수 없는 복합적이고 다이내믹한 음색을 생성할 수 있습니다.   영화 효과음, 게임 효과음, 전자 음악에서 많이 사용됨.   AudioKit의 FMOscillator는 이를 매우 직관적으로 실험하고 학습할 수 있게 해주는 도구입니다.    "
  },
  
  {
    "title": "AudioKit의 DynamicOscillator",
    "url": "/posts/DynamicOscillator/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-16 18:18:13 +0900",
    "content": "Dynamic Oscillator  DynamicOscillator는 오디오 신호를 생성하는 진동기(oscillator) 중 하나로, 실시간으로 다양한 음색과 음높이를 변화시킬 수 있도록 설계된 동적(Dynamic) 오실레이터입니다.  신디사이저에서 가장 기본적인 소리 생성 장치가 오실레이터이며, 이 소리는 사인파, 톱니파, 구형파 같은 기본 파형으로 시작하여, 다양한 방식으로 변형되어 악기의 소리를 만들어냅니다.    🎧 Dynamic Oscillator란?     **“Dynamic”**이라는 이름처럼, 이 오실레이터는 주파수, 진폭, 디튜닝 등 다양한 파라미터를 실시간으로 조절할 수 있는 구조를 가집니다.   따라서 모노톤 비프음부터 악기처럼 유연하게 변화하는 음색까지 생성이 가능합니다.   사용자가 건반을 누르거나 슬라이더를 움직이는 등 UI 인터랙션에 따라 소리가 즉각적으로 변하는 상황에 적합합니다.     🔊 생성되는 소리의 기본 구성  DynamicOscillator는 다음과 같은 구성 요소를 기반으로 소리를 생성하고 제어합니다:  1. Frequency (주파수)     소리의 높낮이를 결정합니다.   440Hz는 콘서트 A음 (A4), 값이 높을수록 고음, 낮을수록 저음.   건반을 누르거나 노트를 지정하면 이 값이 변함.   2. Amplitude (진폭)     **소리의 크기 (볼륨)**입니다.   0.0이면 무음, 1.0이면 최대.   일반적으로 0.2~0.5 수준이면 충분한 음량.   3. Frequency Offset     기존 주파수에 더하거나 빼는 상대적 주파수 조정값입니다.   예를 들어 440Hz에 +50 offset을 주면 490Hz가 됨.   슬라이딩 피치, 불안정한 음색, 피치 흔들림 효과에 활용.   4. Frequency Detuning Multiplier     주파수를 곱셈 비율로 미세하게 조정합니다.   1.0은 원래 주파수, 0.99는 미세하게 낮음 → 다른 오실레이터와 섞으면 풍부한 음색, 합성 보코더, 코러스 효과 등을 만듦.   신디사이저에서는 여러 오실레이터를 살짝 detune하여 풍부한 소리를 만드는 것이 핵심.     🎹 DynamicOscillator가 중요한 이유     전통적인 고정 음색 오실레이터와 달리, DynamicOscillator는 시간 흐름에 따라 유연하게 음색과 피치를 변화시킬 수 있습니다.   예를 들어, 실시간으로 피치를 올리거나, 진폭을 점점 키우거나, 위상이나 파형을 바꾸는 등 다양한 실시간 퍼포먼스 효과를 구현할 수 있습니다.   특히, iPad/터치 기반 UI에서 슬라이더나 XY패드 등을 통해 소리를 직접 만지고 조절하는 방식의 인터페이스에 잘 어울립니다.     🧠 종합 요약     DynamicOscillator는 오디오 합성에서 기본 파형을 실시간으로 유연하게 제어할 수 있는 오실레이터   피치(Frequency), 음량(Amplitude), 미세 조정(Detune) 같은 주요 파라미터를 실시간으로 조작   디지털 신디사이저의 핵심 구성 요소 중 하나   사용자의 동작에 따라 빠르고 자연스럽게 반응할 수 있는 구조로 설계됨    "
  },
  
  {
    "title": "ADSR(Attack, Decay, Sustain, Release)란 무엇인가?",
    "url": "/posts/ADSR/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-16 18:17:27 +0900",
    "content": "ADSR  ADSR은 음향에서 **소리의 시간적 변화(Envelope)**를 모델링하기 위한 네 가지 기본 단계를 나타냅니다. 이는 특히 신디사이저, 샘플러, 효과기에서 음의 길이와 강약 변화를 제어하는 데 사용됩니다.    🔤 ADSR: 네 가지 단계                 약어       의미       설명                       A       Attack       건반을 누른 순간부터 최대 볼륨까지 도달하는 데 걸리는 시간                 D       Decay       Attack 이후, 소리가 최대치에서 **지속 볼륨(Sustain)**까지 줄어드는 시간                 S       Sustain       키를 누르고 있는 동안 유지되는 지속적인 볼륨 (시간이 아닌 레벨)                 R       Release       키를 뗀 후, 소리가 완전히 사라질 때까지 걸리는 시간             🎧 각 단계의 실제 효과  🟢 Attack (어택)     작을수록: 소리가 바로 나옴 (펀치감, 퍼커션류에 적합)   클수록: 소리가 점점 커지며 시작 (스트링, 패드 사운드에 적합)   🟠 Decay (디케이)     최대 볼륨에서 Sustain 레벨까지 떨어지는 시간   드럼처럼 빠르게 죽는 소리는 짧은 Decay, 피아노처럼 감쇠되는 소리는 중간 Decay 사용   🔵 Sustain (서스테인)     소리를 누르고 있는 동안 유지되는 볼륨 수준   0에 가까울수록 짧게 끝나는 느낌 / 1에 가까우면 지속됨   🔴 Release (릴리즈)     키를 놓은 뒤 소리가 사라지는 데 걸리는 시간   짧을수록 갑자기 꺼지는 느낌 / 길수록 여운이 남음 (리버브처럼)     🧠 ADSR은 왜 중요한가?     음색 컨트롤의 핵심 요소입니다.        같은 악기 소스도 ADSR 설정에 따라 전혀 다른 감성을 가질 수 있습니다.             빠른 Attack + 짧은 Release → 드럼       느린 Attack + 긴 Release → 스트링 패드           신디사이저에서는 필터나 볼륨 뿐만 아니라 피치, 모듈레이션 등 다양한 파라미터에 ADSR을 연결할 수 있습니다.     📊 시각적 예 (타임라인 흐름)  볼륨 │       /‾‾‾‾‾‾‾‾‾ │      /         \\ │     /           \\ │    /             \\__________ │                            \\ │                             \\________ │________________________________________ 시간      ↑A    ↑D             ←S→     ↑R     🎯 요약     ADSR은 소리의 생성과 사라짐을 시간적으로 컨트롤하는 4단계   악기의 캐릭터, 감정, 반응성을 정하는 중요한 요소   Attack/Decay/Release는 시간, Sustain은 볼륨 레벨  "
  },
  
  {
    "title": "AudioKit에서 필터(Filter)의 노드목록",
    "url": "/posts/%ED%95%84%ED%84%B0(Filter)_%EB%85%B8%EB%93%9C%EB%AA%A9%EB%A1%9D/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-15 23:38:56 +0900",
    "content": "Filter의 Node 목록    🔵 AudioKit 필터  🎛 HighPassFilter     기능: 지정된 컷오프 주파수 이하의 저역을 제거하고 고역을 통과시킴.        Cutoff Frequency             필터가 작동을 시작하는 기준 주파수       값이 높을수록 더 많은 저역이 제거됨                Resonance             컷오프 근처의 주파수를 강조하는 정도       값이 높을수록 해당 경계가 날카롭고 뚜렷하게 들림             🎛 HighShelfFilter     기능: 특정 주파수 이상 대역을 증폭 또는 감쇠 (고역 쉘프 필터)        Cut Off Frequency             고역 증감이 시작되는 지점                Gain             해당 대역을 얼마나 키울지 또는 줄일지       양수: 고역 강조 / 음수: 고역 약화             🎛 LowPassFilter     기능: 컷오프 주파수 이상을 제거하고 저역을 통과시킴        Cutoff Frequency             고역 차단 시작 지점       값이 낮을수록 더 많은 고역이 제거됨                Resonance             컷오프 주파수 부근을 얼마나 강조할지       값이 클수록 더 뾰족한 음색을 생성             🎛 LowShelfFilter     기능: 특정 주파수 이하의 저역을 증폭 또는 감쇠        Cutoff Frequency             저역 증감이 시작되는 기준 주파수                Gain             양수일 경우 저음 강화 / 음수일 경우 저음 감소             🔷 SoundpipeAudioKit 필터  🎛 BandPassButterworthFilter     기능: 특정 대역만 통과시키고 그 외는 차단 (부드러운 버터워스 특성)        Center Frequency             통과시킬 중심 주파수                Bandwidth             통과 대역폭 (넓을수록 많은 대역 허용)             🎛 BandRejectButterworthFilter     기능: 특정 대역만 제거하고 그 외는 통과 (노치 필터)        Center Frequency             제거 대상 중심 주파수                Bandwidth             제거 대역폭 (값이 클수록 넓은 영역이 제거됨)             🎛 EqualizerFilter     기능: 특정 대역만 조정 가능한 기본 이퀄라이저        Center Frequency             조절할 중심 주파수                Bandwidth             영향을 주는 대역폭 범위                Gain             해당 대역을 증폭(+)/감쇠(-) 정도             🎛 FormantFilter     기능: 인간 목소리의 공명 구조(포먼트)를 모방해 로봇 보이스나 보컬 이펙트에 활용        Center Frequency             포먼트 중심 주파수                Attack Duration             필터 적용 시 올라가는 속도 (빠를수록 즉각적 반응)                Decay Duration             효과가 사라지는 속도 (느릴수록 잔향 느낌)             🎛 HighPassButterworthFilter     기능: 저역을 부드럽게 제거하는 고역 필터        Cutoff Frequency             저역 차단 시작 지점 (값이 높을수록 더 많은 저역 제거)             🎛 HighShelfParametricEqualizerFilter     기능: 고역대 쉘프 필터에 정밀 제어를 더한 필터        Corner Frequency             고역 증감이 시작되는 주파수                Gain             고역을 얼마나 증폭하거나 감쇠할지                Q             변화가 일어나는 영역의 폭 (값이 작을수록 완만)             🎛 KorgLowPassFilter     기능: Korg 스타일의 필터로, 아날로그 특성 및 왜곡 포함        Filter Cutoff             고역 차단 시작점                Resonance             컷오프 부근 강조 정도                Saturation             왜곡량 조절 (값이 높을수록 따뜻하고 거친 소리)             🎛 LowPassButterworthFilter     기능: 부드럽게 고역을 제거하는 저역 필터        Cutoff Frequency             고역 차단 시작 지점             🎛 LowShelfParametricEqualizerFilter     기능: 저역대 쉘프 필터 + Q 제어 추가        Corner Frequency             저역 증감이 시작되는 주파수                Gain             저역 증폭/감쇠 정도                Q             변화 범위의 폭             🎛 ModalResonanceFilter     기능: 특정 주파수를 공명시켜 금속/현악 느낌을 부여        Resonant Frequency             공명 중심 주파수                Quality Factor             공명의 날카로움 (값이 높을수록 뾰족하고 긴 울림)             🎛 MoogLadder     기능: Moog 신시사이저의 Ladder 필터 모델링, 따뜻한 아날로그 느낌        Cutoff Frequency             고역 차단 지점                Resonance             컷오프 근처 강조 (값이 높을수록 더 신디사이저 느낌)             🎛 PeakingParametricEqualizerFilter     기능: 특정 대역만 강조하거나 감쇠 (중심 대역 이퀄라이저)        Center Frequency             조절할 중심 주파수                Gain             해당 대역 증폭/감쇠 정도                Q             영향받는 대역의 넓이             🎛 ResonantFilter     기능: 특정 주파수를 공명시키고 나머지는 억제        Frequency             공명 주파수                Bandwidth             공명 폭 (넓을수록 효과가 부드러움)             🎛 ThreePoleLowpassFilter     기능: 3단계 구조의 저역 필터, 왜곡 포함        Distortion             추가적인 음색 변형                Cutoff Frequency             고역 차단 시작점                Resonance             공명 강조 정도             🎛 ToneComplementFilter     기능: ToneFilter의 보완적 역할을 하는 필터        Half-Power Point             주파수 응답이 절반으로 줄어드는 기준 지점             🎛 ToneFilter     기능: 고역/저역에 일정한 감쇠 효과를 줘서 톤 정리        Half-Power Point             필터가 가장 많이 작용하는 중심 지점            "
  },
  
  {
    "title": "음향에서 필터(Filter)란?",
    "url": "/posts/%ED%95%84%ED%84%B0(Filter)/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-15 23:38:13 +0900",
    "content": "필터 (Filter)  음향에서의 **필터(Filter)**란, 오디오 신호에서 특정 주파수 성분을 통과시키거나 제거하는 처리기법입니다. 필터는 디지털 또는 아날로그 방식 모두로 구현될 수 있으며, 오디오에서 매우 중요한 역할을 합니다. 예를 들어, 원하는 음색을 만들거나, 잡음을 제거하거나, 공간감이나 특정 질감을 추가하는 데 사용됩니다.    📘 필터의 기본 개념  1. 주파수(Frequency)     소리는 다양한 주파수의 조합으로 이루어집니다.   예: 저음(20250Hz), 중음(2504kHz), 고음(4kHz~20kHz)   2. 필터의 주요 기능     특정 **주파수 대역을 통과(Pass)하거나 제거(Cut)**합니다.   3. 필터의 기본 분류                 필터 종류       기능 설명                       Low-Pass Filter       특정 주파수보다 낮은 주파수만 통과, 고주파 제거                 High-Pass Filter       특정 주파수보다 높은 주파수만 통과, 저주파 제거                 Band-Pass Filter       특정 대역만 통과하고 나머지 제거                 Band-Reject Filter (Notch)       특정 대역만 제거하고 나머지 통과                 Shelf Filter       특정 주파수 이상/이하를 점진적으로 증감 (boost/cut)                 Parametric EQ       중심 주파수, 폭(Q), 증감량(gain)을 조절해 특정 주파수 대역 조절                 Formant Filter       사람 목소리의 공명 주파수를 강조 – 보컬/로봇 보이스 등                 Resonant Filter       특정 주파수를 강조하여 공명 효과 유도             🔍 공통적으로 학습해야 할 핵심 개념  각 필터 종류는 구현 방식이나 특성은 다르지만, 다음의 공통 요소를 갖고 있어 이를 먼저 이해하는 것이 중요합니다:  1. Cutoff Frequency (컷오프 주파수)     필터가 작용하기 시작하는 기준 주파수   대부분의 필터가 이 파라미터를 가짐   2. Resonance / Q (품질 계수)     필터 가장자리에 얼마나 강하게 강조 또는 감쇠할지   값이 높을수록 특정 주파수에서 공명(peaking) 효과가 큼   3. Gain (이득)     해당 대역을 얼마나 증폭하거나 줄일 것인지 (특히 EQ에서)   4. Bandwidth (대역폭)     중심 주파수를 기준으로 얼마나 넓은 영역을 처리할지     📚 예시를 통한 필터별 비교                 필터명       주요 파라미터       설명                       BandPassButterworthFilter       centerFrequency, bandwidth       중심 대역만 통과 (버터워스 방식으로 급격하게 차단)                 BandRejectButterworthFilter       centerFrequency, bandwidth       중심 대역만 제거                 EqualizerFilter       gain, centerFrequency       기본 EQ, 단일 대역 증감                 FormantFilter       frequency, attackDuration       음성 성대 필터 특성 모방                 HighPassFilter, LowPassFilter       cutoffFrequency, resonance       단순 고역/저역 필터                 HighShelfFilter, LowShelfFilter       gain, cutoffFrequency       특정 주파수 이상/이하 전 대역 증감                 MoogLadder       cutoffFrequency, resonance       아날로그 신디사이저의 따뜻한 느낌 재현                 PeakingParametricEqualizerFilter       centerFrequency, gain, Q       중심 주파수를 중심으로 양방향 증감 가능             ✅ 실습 또는 학습 팁          Dry/Wet Mix로 차이 들어보기             필터 전/후의 차이를 듣는 것이 가장 중요합니다.       DryWetMixer로 비교하면 훨씬 이해가 빠릅니다.                하나씩 파라미터를 조절해보기             Frequency, Gain, Q를 바꿔가며 효과 확인                시각적 분석도 활용             FFTPlot, NodeOutputPlot 같은 시각 도구로 필터 효과 확인                실제 음악에 적용해보기             드럼, 보컬, 신디 등 다양한 소스에 필터를 걸어 청감 실험             🎯 요약                 핵심 키워드       설명                       필터(Filter)       특정 주파수 성분을 제거/강조하는 처리 도구                 주파수(Frequency)       음향의 기본 구성 요소, 필터의 기준                 Cutoff / Center Frequency       필터가 작용하는 지점                 Q / Resonance       얼마나 날카롭고 강조되는지                 Gain       특정 주파수 대역을 얼마나 키우거나 줄일지            "
  },
  
  {
    "title": "AudioKit의 ZitaReverb",
    "url": "/posts/ZitaReverb/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-15 20:00:13 +0900",
    "content": "Zita Reverb  ZitaReverbConductor 클래스는 SoundpipeAudioKit의 ZitaReverb 효과를 적용하는 컨덕터로, 다채로운 리버브 제어 기능을 제공하는 고급 리버브입니다. Zita 리버브는 Zita-Rev1를 기반으로 만들어졌으며, 스튜디오 품질의 고해상도 리버브를 모델링한 것입니다.    🎧 ZitaReverb란?     다중 대역(Multiband) 리버브로, 저역과 중역의 잔향 길이를 독립적으로 제어할 수 있습니다.   Pre-delay, 크로스오버, 댐핑, 2밴드 EQ, Dry/Wet 등 다양한 파라미터를 제공해 실제 공간처럼 정밀한 잔향 조정이 가능합니다.   자연스럽고 부드러운 공간감을 연출하며, 악기와 보컬 모두에 적합합니다.     🎛 파라미터 설명                 파라미터 이름       기본값       범위       설명                       PreDelay       60.0       10.0...100.0       원음이 나오고 리버브가 시작되기 전 지연 시간 (ms). 공간의 크기를 암시                 Crossover frequency       200.0       50.0...1000.0       저역/중역을 구분하는 주파수 (Hz)                 Low release time       3.0       1.0...8.0       저역의 잔향 유지 시간 (초)                 Mid Release Time       2.0       1.0...8.0       중역의 잔향 유지 시간 (초)                 Damping Frequency       6000.0       1500.0...47040.0       리버브의 고역 감쇠 시작 주파수 (Hz). 낮을수록 고음이 빨리 죽음                 EQ Frequency 1       315.0       40.0...2500.0       첫 번째 EQ 대역의 중심 주파수 (Hz)                 EQ Level 1       0.0       -15.0...15.0       EQ1의 증/감폭 (dB)                 EQ Frequency 2       1000.0       160.0...1000.0       두 번째 EQ 대역의 중심 주파수 (Hz)                 EQ Level 2       0.0       -15.0...15.0       EQ2의 증/감폭 (dB)                 Dry Wet Mix       1.0       0.0...1.0       원음과 리버브 신호의 비율. 1.0이면 리버브 100%, 0.0이면 원음 100%             🔊 음향적 특징                 항목       설명                       🎚️ 다이내믹 제어       저역과 중역의 잔향을 독립적으로 설정                 🎛️ EQ 내장       리버브 후 신호의 특정 주파수 보정 가능                 🌌 공간감 표현       PreDelay와 Damping 설정으로 작은 방부터 대형 홀까지 표현 가능                 🎵 자연스러움       댐핑과 리버브 시간의 조합으로 매끄러운 잔향             ✅ 요약                 요소       설명                       💡 리버브 종류       고급 멀티밴드 리버브 (Zita 기반)                 🛠️ 주요 조절 요소       프리딜레이, 주파수 크로스오버, 댐핑, 리버브 시간, 2밴드 EQ                 🎧 음향적 용도       보컬, 기타, 신스 등 거의 모든 소스에 적합                 🎯 강점       매우 자연스럽고 조절 가능한 공간감 구현             🎼 사용 예     보컬의 앞뒤 공간감을 주고 싶을 때   드럼 룸 사운드를 시뮬레이션할 때   신디사이저 패드에 깊이를 더할 때   EQ로 특정 대역만 잔향을 주거나 제거할 때     ZitaReverb는 단순한 효과가 아니라, 실제 음향 공간의 거동을 디지털로 구현한 정밀한 리버브 처리기입니다. 🎧 고급 믹싱/마스터링에서 현장감 있는 공간 설계가 필요한 상황에 특히 유용합니다. "
  },
  
  {
    "title": "AudioKit의 FlatFrequencyResponseReverb",
    "url": "/posts/FlatFrequencyResponseReverb/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-15 20:00:13 +0900",
    "content": "Flat Frequency Response Reverb  FlatFrequencyResponseReverbConductor 클래스는 SoundpipeAudioKit의 FlatFrequencyResponseReverb 이펙트를 활용하여 플랫한(고르게 균형 잡힌) 리버브를 적용하는 컨덕터입니다. 이 리버브는 주파수 대역 전반에 걸쳐 고르게 반응하며, 특정 음역을 강조하거나 억제하지 않는 것이 특징입니다.    🧠 Flat Frequency Response Reverb란?     일반적인 리버브는 공간 특성이나 구조에 따라 특정 주파수(고음, 중음, 저음)가 강조될 수 있습니다.   반면 Flat Frequency Response Reverb는 모든 주파수 대역에 대해 동일한 반사 특성을 갖는 리버브입니다.        즉, 주파수 응답(frequency response) 곡선이 평탄(flat) 하도록 설계되어 있어,             원본 음색의 밸런스를 그대로 유지한 채,       공간감(잔향)만 추가하고자 할 때 유용합니다.             🎛 파라미터 설명                 파라미터 이름       기본값       범위       설명                       Reverb Duration       0.5       0.0 ~ 10.0       리버브 잔향이 유지되는 시간 (초). 커질수록 더 길게 퍼지는 느낌.              0.0은 이론상 리버브가 없는 상태지만, 실제 구현에 따라 최소값보다 더 작은 값은 비정상 동작을 유발할 수 있으므로 주의 필요.     🔊 음향적 특성                 항목       설명                       ✅ 주파수 반응       고음, 저음 구분 없이 균일하게 리버브가 걸림                 ✅ 음색 변화 없음       원래 음의 특성을 보존함                 ✅ 투명한 공간감       인공적인 컬러레이션(coloration) 없음                 ✅ 용도       마스터 버스에 리버브를 걸거나, 자연스러운 방 리버브 표현 시 적합             🧩 코드 구조  super.init(source: .drums) { input in   FlatFrequencyResponseReverb(input) }      .drums 오디오 샘플에 이 리버브를 적용.   BasicEffectConductor를 상속받아 DryWetMixer 포함.   전체 AudioEngine의 출력에 연결.     ✅ 요약                 항목       설명                       🎧 효과       주파수에 따른 변화 없이 평탄한 리버브                 🎛 주요 파라미터       Reverb Duration (잔향 길이)                 💡 적합 대상       마스터링 단계, 원음 보존이 중요한 믹싱                 🧪 특징       컬러레이션이 적고 자연스러운 리버브 효과             🎶 사용 예     보컬에 걸어도 음색을 해치지 않고 잔향만 추가 가능   어쿠스틱 악기 녹음 후 자연스러운 룸 사운드를 시뮬레이션할 때   전역 리버브(전체 믹스에 공통으로 적용하는 리버브)로 이상적     이 리버브는 사운드의 성격을 바꾸지 않고 순수한 공간감을 추가하려는 사용자에게 매우 적합합니다. "
  },
  
  {
    "title": "AudioKit의 CostelloReverb",
    "url": "/posts/CostelloReverb/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-15 20:00:13 +0900",
    "content": "Costello Reverb  CostelloReverbConductor 클래스는 SoundpipeAudioKit의 CostelloReverb 이펙트를 적용하는 Swift 오디오 처리 클래스입니다. 아래에 기능, 파라미터, 사용 의도 등을 자세히 설명드리겠습니다.    🧠 클래스 개요  class CostelloReverbConductor: BasicEffectConductor&lt;CostelloReverb&gt;      BasicEffectConductor&lt;CostelloReverb&gt;를 상속하여 오디오 효과를 처리   오디오 소스는 .drums   내부에서 CostelloReverb를 생성하여 오디오에 적용     🔊 CostelloReverb란?     **CostelloReverb**는 SoundpipeAudioKit에 포함된 간단하고 빠른 디지털 리버브입니다.   Jon Costello가 만든 리버브 알고리즘을 기반으로 하며, 가볍고 CPU 사용량이 적은 것이 특징입니다.   Feedback 기반 딜레이 네트워크를 사용하여 잔향을 생성합니다.     🎚️ 파라미터 설명                 파라미터 이름       기본값       범위       설명                       Feedback       0.6       0.0 ~ 1.0       리버브의 잔향 지속 시간. 높을수록 더 길고 깊은 리버브가 생성됨. 1.0에 가까울수록 무한 반복처럼 들릴 수 있음.                 Cutoff Frequency       4000.0       12.0 ~ 20000.0 Hz       로우패스 필터 커트오프 주파수. 리버브에 포함되는 고주파수의 양을 조절. 낮을수록 어두운 소리, 높을수록 밝고 샤프한 잔향.                 Balance       1.0       0.0 ~ 1.0       드라이(원본)와 웻(이펙트) 신호의 믹스 비율. 0.0은 원본만, 1.0은 리버브 신호만 출력됨.             🔁 처리 흐름     .drums 샘플 로딩   CostelloReverb 인스턴스 생성   입력 신호에 리버브 적용   드라이/웻 믹스를 balance로 조정   오디오 출력     🧪 실용적 사용 예     타악기, 드럼 루프에 짧고 퍼지는 리버브 효과를 주고 싶을 때   리소스가 제한된 모바일 환경에서 효율적으로 리버브를 쓰고 싶을 때   잔향이 길지만 비교적 고역이 잘 제어된 리버브를 만들고 싶을 때     ✅ 요약                 항목       설명                       🎧 효과       빠르고 간단한 디지털 리버브                 🧠 기반       Costello 알고리즘                 ⚙️ 주요 파라미터       Feedback, Cutoff Frequency, Balance                 💡 특성       CPU 부담 적고, 어두운 성향의 잔향 생성 가능           즉, CostelloReverb는 실시간성이 필요한 상황에서 빠르고 안정적인 리버브를 제공하기 위해 만들어진 이펙트입니다. "
  },
  
  {
    "title": "AudioKit의 CombFilterReverb",
    "url": "/posts/CombFilterReverb/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-15 20:00:13 +0900",
    "content": "Comb Filter Reverb  CombFilterReverbConductor 클래스는 SoundpipeAudioKit의 CombFilterReverb 이펙트를 사용하는 오디오 처리 클래스입니다. 이 클래스의 목적은 콤 필터 기반의 리버브를 드럼 소스에 적용하는 것입니다. 아래에 이 클래스와 파라미터에 대해 자세히 설명합니다.    🧠 Comb Filter Reverb란?     Comb Filter Reverb는 피드백 딜레이를 기반으로 한 매우 간단한 리버브 효과입니다.   이름처럼 주파수 응답이 빗살(Comb) 모양으로 생깁니다.   이는 특정 주파수 성분을 강조하거나 약화시키는 공명 패턴을 만들어 리버브처럼 들리게 합니다.   일반적인 리버브보다 알고리즘이 단순하고 CPU 사용량이 적음.     🎛 파라미터 설명                 파라미터 이름       기본값       범위       설명                       Reverb Duration       1.0       0.0 ~ 10.0       잔향이 유지되는 시간 (초). 값이 클수록 리버브가 오래 지속됩니다.              ⚠️ 주의: 0.0으로 설정하면 내부적으로 문제가 발생할 수 있어 앱이 멈추거나 오작동할 수 있습니다. 최소값은 0.001 이상을 권장합니다.     🧩 사용 방식  super.init(source: .drums) { input in   CombFilterReverb(input) }      .drums 오디오 파일을 불러와 CombFilterReverb에 연결   BasicEffectConductor를 상속하여 DryWetMixer를 통한 드라이/웻 믹싱 처리   AudioEngine에 연결해 출력     🔊 리버브 특성     잔향은 정확하고 반복적인 에코처럼 들릴 수 있습니다.   Feedback 기반이기 때문에 특정 주파수가 반복적으로 강조됩니다.   실내 공간감보다는 딜레이와 공명 효과에 가까운 리버브입니다.     ✅ 요약                 항목       설명                       🎧 사용 효과       간단한 반사음 효과, 에코처럼 반복되는 리버브                 🎛 주요 조절 항목       Reverb Duration (잔향 지속 시간)                 ⚠️ 주의       0.0으로 설정 시 오류 발생 가능                 💡 적합 대상       드럼, 신스, 실험적인 사운드 디자인             이 효과는 자연스러운 리버브보다는 약간 기계적이고 반복적인 공간감을 만들어내고 싶을 때 유용합니다. Reverb Duration 값을 적절히 조절해 과도한 공명이 생기지 않도록 주의해야 합니다. "
  },
  
  {
    "title": "AudioKit의 ChowningReverb",
    "url": "/posts/ChowningReverb/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-15 20:00:13 +0900",
    "content": "Chowning Reverb  ChowningReverbConductor 클래스는 AudioKit의 ChowningReverb 리버브 효과를 적용하고 제어하는 SwiftUI 기반 오디오 컨덕터 클래스입니다. 구조와 작동 방식을 자세히 설명하겠습니다.    🧠 1. 클래스의 역할  class ChowningReverbConductor: BasicEffectConductor&lt;ChowningReverb&gt;   이 클래스는 BasicEffectConductor의 제네릭 서브클래스로, &lt;ChowningReverb&gt; 타입을 사용합니다. 즉:     ChowningReverb 효과를 오디오 신호에 적용하고   UI에서 제어 가능하도록 상태를 바인딩하며   기본 오디오 소스로 .drums를 사용합니다.     🎛️ 2. ChowningReverb란?  ChowningReverb는 **존 초우닝(John Chowning)**이 설계한 초기 디지털 리버브 알고리즘을 기반으로 만들어진 리버브입니다.     **FAUST 및 CLM (Common Lisp Music)**에서 유래한 고전적인 알고리즘 기반 리버브   알고리즘 리버브의 초기 형태로, 빠르고 가벼운 잔향 처리 가능   복잡한 리버브보다 CPU 부담이 적음      참고: John Chowning은 FM 합성을 발명한 인물로, 디지털 사운드 신디시스 분야의 선구자입니다.     🎚️ 3. 파라미터 설명  Balance | 1.0 | 0.0...1.0           Balance: 리버브의 드라이/웻 믹스 정도를 제어합니다.             0.0 → 원본 소리만 들림 (Dry)       1.0 → 리버브 처리된 소리만 들림 (Wet)       0.5 → 두 신호가 반반 섞임           이 값은 내부적으로 DryWetMixer와 유사하게 작동합니다.    ⚙️ 4. 코드 흐름 요약  super.init(source: .drums) { input in   ChowningReverb(input) }      .drums 샘플을 불러와 플레이어로 재생   ChowningReverb 이펙트를 플레이어에 연결   오디오 신호에 리버브를 적용한 뒤 출력     ✅ 요약                 항목       설명                       🎧 효과       디지털 리버브 (Chowning 알고리즘 기반)                 ⚙️ 파라미터       balance (드라이/웻 믹스 비율)                 📦 모듈       SoundpipeAudioKit                 🔄 용도       빠르고 간단한 잔향 효과, CPU 사용량 적음           이 리버브는 리소스가 제한된 환경이나 간단한 앰비언스 처리를 원할 때 적합합니다. "
  },
  
  {
    "title": "AudioKit의 TanhDistortion",
    "url": "/posts/TanhDistortion/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-14 14:54:09 +0900",
    "content": "Tanh Distortion  이 코드는 AudioKit의 TanhDistortion을 이용한 오디오 왜곡 효과를 적용하는 Swift 클래스입니다. 이름 그대로 tanh() (쌍곡 탄젠트) 함수를 활용한 디스토션 알고리즘으로, 부드럽지만 강한 왜곡을 줄 수 있습니다.    🔧 클래스 설명: TanhDistortionConductor  ✅ 상속     BasicEffectConductor&lt;TanhDistortion&gt;: 커스텀 효과를 공통적으로 다루는 기본 클래스에서 상속.   &lt;TanhDistortion&gt; 제네릭을 통해 AudioKit의 디스토션 노드를 지정.     🎛 파라미터 설명                 파라미터 명칭       기본값       범위       설명                       Pregain       2.0       0.0...10.0       입력 신호에 곱해지는 값. 클수록 강한 디스토션 발생                 Postgain       0.5       0.0...10.0       디스토션 후의 볼륨 조절. 출력 크기를 조정                 Positive Shape Parameter       0.0       -10.0...10.0       양수 영역의 왜곡 곡률 조정                 Negative Shape Parameter       0.0       -10.0...10.0       음수 영역의 왜곡 곡률 조정             🎧 TanhDistortion이란?     수학 함수 tanh(x)를 통해 입력을 부드럽게 압축 → 클리핑 없이 부드러운 디스토션 제공   사인파처럼 완만하게 왜곡되어 하드 클리핑보다 더 음악적인 결과를 냄   양/음수 각각의 비선형성 조절 가능 → 다양한 톤 설계 가능     tanh(x)는 쌍곡 탄젠트 함수(hyperbolic tangent function) 로, 수학적 정의는 다음과 같습니다:    📐 정의  $$ \tanh(x) = \frac{\\sinh(x)}{ "
  },
  
  {
    "title": "AudioKit의 RingModulator",
    "url": "/posts/RingModulator/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-14 14:39:14 +0900",
    "content": "Ring Modulator  **링 모듈레이션(Ring Modulation)**은 두 개의 오디오 신호를 곱해서 새로운 소리를 만들어내는 전자음향 효과입니다. 주로 기존 소리를 극적으로 변형하고 싶을 때 사용되며, 다음과 같은 특징이 있습니다:    🔧 어떻게 작동하나요?          입력 신호(Input Signal): 예를 들어, 마이크나 악기 소리.           변조 신호(Modulator): 보통은 정현파(sine wave) 같은 단순한 신호.           이 둘을 곱셈(multiplication) 연산하면, 다음 주파수가 생성됨:  \\[ext{출력} = \text{입력 주파수} \\pm \text{변조 주파수}\\]           이 결과로 새로운 주파수만 남고, 원래의 음은 사라집니다.        🎧 어떤 소리가 나나요?          원래 음색이 완전히 바뀌며, 보통은 다음과 같이 표현됩니다:             금속성, 기계음, 외계 생명체 같은 느낌       로봇 보이스나 음성 변조 효과       SF 영화나 실험 음악에서 많이 사용됨             🎵 예시                 원본       변조 주파수       출력 소리                       보컬       400Hz       로봇 보이스                 신스       30Hz (저주파)       느리게 흔들리는 진동                 드럼       1000Hz       거친 전자 드럼 느낌             🎯 왜 “링(Ring)”이라고 부르나요?  초기 하드웨어 회로에서 4개의 다이오드가 “링” 형태로 배열된 회로를 사용했기 때문에 이런 이름이 붙었습니다. 수학적으로는 단순히 곱셈이지만, 이 용어가 지금까지도 남아 있습니다.    Ring Modulator Conductor  이 코드는 RingModulator(링 모듈레이터) 이펙트를 적용하는 RingModulatorConductor 클래스를 정의한 것으로, 기본 음원(.drums)에 대해 링 모듈레이션 효과를 부여합니다. 아래는 코드 및 파라미터의 작동 원리, 음향적 효과를 중심으로 상세 설명입니다.    🧠 Ring Modulator란?  **링 모듈레이터(Ring Modulator)**는 다음과 같은 방식으로 작동합니다:     입력 신호(Input)와 **하나 또는 두 개의 정현파(Modulator)**를 곱함.   그 결과는 입력 주파수 ± 변조 주파수 형태로 변형됨 → 원래 음의 고조파나 피치가 사라지고 금속성, 로봇 같은 소리가 만들어짐.   기본 주파수의 흔적이 제거되기 때문에 톤이 불안정하거나 비조화적인 느낌을 줌.     🔧 파라미터 설명                 파라미터 이름       기본값       범위       설명                       Ring Mod Freq1       2486       0.5…8000.0       첫 번째 변조 주파수입니다. 이 값이 높을수록 더 날카롭고 높은 음색을 냅니다.                 Ring Mod Freq2       4655       0.5…8000.0       두 번째 변조 주파수입니다. Freq1과 결합해 복잡한 위상 간섭 및 비정상적인 조화음을 생성합니다.                 Ring Mod Balance       56       0.0…100.0       두 변조 주파수의 비율을 조정합니다. 0이면 Freq1만, 100이면 Freq2만, 중간값은 둘의 혼합입니다.                 Final Mix       100       0.0…100.0       드라이/웻 믹스. 100이면 이펙트만 들리고, 0이면 원본 소리만 들립니다.             🎧 사운드 예시 및 활용     로봇 보이스, 외계 생명체 음성   전자 타악기에서 금속성 또는 불규칙한 음색 연출   드럼, 베이스라인, 보컬에 적용하면 독특하고 SF적 텍스처를 만들어냄     💡 코드 설명 요약  effect.ringModFreq1 = 2486 effect.ringModFreq2 = 4655 effect.ringModBalance = 56 effect.finalMix = 100      Freq1과 Freq2의 값을 다르게 설정하여 복잡한 모듈레이션 음색을 생성   Balance는 두 변조파를 56:44로 섞음   Final Mix가 100이므로 원본은 제거되고, 이펙트 소리만 출력     🧩 정리                 요소       설명                       🎛 Ring Mod Freq1/Freq2       사운드를 왜곡하고 톤을 변화시킴                 🎚 Balance       두 변조 주파수의 기여도를 조절                 🎚 Final Mix       Dry/Wet 믹스 조절 (0 = 원본만, 100 = 효과만)                 🎧 결과       금속성, 비정조적, 전자적 사운드 생성           이 효과는 실험적인 음악, 노이즈 음악, 사운드 디자인에서 자주 사용됩니다. "
  },
  
  {
    "title": "AudioKit의 Decimator",
    "url": "/posts/Decimator/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-14 14:30:24 +0900",
    "content": "Decimator  이 코드는 Decimator 효과를 적용하는 DecimatorConductor 클래스를 정의한 것으로, 디지털 오디오에서 흔히 사용되는 디스토션 계열 이펙트 중 하나인 Decimation(데시메이션)을 사용합니다. 아래에서 설명하겠습니다:    🧠 개념 설명  📌 Decimation (데시메이션)이란?     비트 크러싱(bit crushing)과 비슷한 디지털 왜곡 이펙트입니다.   원래의 비트 심도(bit depth)나 샘플 속도(sample rate)를 간접적으로 낮춰서 음질을 거칠고 저해상도처럼 만드는 효과입니다.   하지만 Decimator는 비트 수나 샘플 속도를 직접 설정하지 않고, decimation, rounding 등의 추상적인 파라미터를 통해 조절합니다.     🔧 파라미터 설명                 파라미터 이름       기본값       범위       설명                       Decimation       50.0       0.0…100.0       신호를 얼마나 샘플링 다운(저해상도화)할지 조절합니다. 값이 높을수록 더 거칠고 뭉개지는 소리가 납니다.                 Rounding       0.0       0.0…100.0       샘플 값을 반올림하여 생기는 디지털 왜곡의 느낌을 조절합니다. 값이 높을수록 왜곡이 더 뚜렷하고 날카로워집니다.                 Final Mix       50.0       0.0…100.0       Dry/Wet 믹스 비율입니다. 0은 원래 소리만, 100은 이펙트 소리만, 50은 반반입니다.             🔊 사용 예     Lo-fi 사운드 만들기   게임보이 스타일, 레트로 디지털 악기 효과   드럼 루프에 적용하면 거칠고 전자적인 느낌   사운드 디자인에서 로봇 음성, 노이즈 효과 구현     💡 요약     Decimator는 디지털 해상도를 간접적으로 낮춰 저품질 느낌의 왜곡을 주는 이펙트입니다.   Decimation은 샘플 간격 조절, Rounding은 샘플 수치 반올림으로 신호 왜곡을 만듭니다.   Final Mix는 원본과 이펙트 음을 섞는 비율입니다.   이 효과는 특히 레트로 음악, 글리치 사운드 디자인, 전자음악에서 자주 사용됩니다. "
  },
  
  {
    "title": "AudioKit의 Clipper",
    "url": "/posts/Clipper/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-13 15:06:00 +0900",
    "content": "Clipper  ClipperConductor는 AudioKit의 Clipper 이펙트를 적용하는 클래스이며, 특정 임계값(threshold)을 넘는 오디오 신호의 진폭을 강제로 자르는(clip) 디지털 왜곡 효과를 생성합니다. 주로 기타 같은 악기에서 하드 디스토션 느낌을 만들 때 사용됩니다.    🎛️ 클래스 설명  class ClipperConductor: BasicEffectConductor&lt;Clipper&gt;      Clipper는 오디오의 피크를 잘라내는 하드 클리핑 이펙트입니다.   .guitar 샘플을 입력 소스로 사용합니다.   BasicEffectConductor는 공통 로직을 제공하는 부모 클래스이며, 클리핑 전용 처리만 이 ClipperConductor에서 담당합니다.     🔧 Clipper란?  Clipper는 설정된 Threshold보다 큰 진폭의 오디오를 강제로 잘라내어(flatten) 디스토션 효과를 만드는 비선형(non-linear) 이펙터입니다.     오디오의 파형이 임계값을 초과하면 해당 값을 고정시켜 사각형 모양의 파형으로 만듦   하모닉스(고조파)를 증가시켜 날카롭고 공격적인 톤을 만듦   디지털 느낌의 하드 디스토션 효과와 비슷     🧩 파라미터 설명                 파라미터       범위       기본값       설명                       Threshold       0.0 ... 1.0       1.0       오디오 신호의 진폭이 이 값을 넘으면 잘려나감 (클리핑)값이 낮을수록 더 많은 클리핑이 발생하여 왜곡이 강해짐값이 높을수록 원본과 가까움 (클리핑 없음)             🎶 사용 예시                 Threshold       결과                       1.0       사실상 원본 그대로 (최대 진폭 제한 없음)                 0.7       약간의 디스토션 발생                 0.3       강한 디스토션, 메탈 톤 또는 글리치 사운드                 0.0       무음에 가까운 극단적인 왜곡             Threshold의 단위  Threshold의 단위는 **일반적인 볼륨 단위(dB)**가 아닌, **정규화된 선형 값(normalized linear value)**입니다. 즉:    ✅ Threshold의 단위: 0.0 ~ 1.0 (정규화된 비율)     0.0 → 최소값 (무조건 클리핑됨)   1.0 → 최대값 (오디오가 클리핑되지 않음)   이 범위는 **디지털 오디오의 최대 진폭(1.0)**을 기준으로 한 상대적인 비율 값입니다.     🎚 예시로 보면:                 Threshold 값       의미       결과                       1.0       최대 허용 진폭 = 100%       아무 클리핑도 없음                 0.5       최대 허용 진폭 = 50%       진폭이 0.5를 넘으면 잘림                 0.2       최대 허용 진폭 = 20%       아주 작은 소리만 통과하고, 대부분 클리핑됨             🎧 dB 단위가 아닌 이유?  디지털 오디오 프로세싱에서 클리퍼는 신호 진폭 자체를 직접 잘라버리기 때문에,     dB (데시벨) 단위보다,   0.0 ~ 1.0의 선형 값이 더 적합합니다.     ✅ 정리     Clipper는 임계값 이상을 잘라내는 하드 디스토션 효과   Threshold 값을 낮출수록 더 강한 왜곡 발생   기타, 드럼, 베이스, 노이즈 사운드 디자인 등에 활용 가능   미묘한 색채를 더하거나 극단적인 글리치/디지털 느낌을 줄 때 유용   이 효과는 디스토션과 유사하지만, 진폭 제한을 통한 간단한 처리로 사운드의 거칠기를 조절할 수 있어 많은 신스·기타 이펙트 체인에서 사용됩니다. "
  },
  
  {
    "title": "AudioKit의 BitCrusherConductor",
    "url": "/posts/BitCrusherConductor/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-13 15:05:29 +0900",
    "content": "BitCrusherConductor  BitCrusherConductor는 AudioKit의 BitCrusher 이펙트를 적용하는 클래스이며, 기타 오디오 소스를 받아 비트 크러싱(Bit Crushing) 효과를 줍니다. 아래는 이 클래스의 역할과 각 파라미터의 의미에 대한 설명입니다.    🎛️ 클래스 개요  class BitCrusherConductor: BasicEffectConductor&lt;BitCrusher&gt;      BasicEffectConductor를 상속받아 공통적인 오디오 처리 로직을 재사용   BitCrusher(input)는 입력된 오디오에 대해 비트 크러싱 효과를 적용   source: .guitar → 기타 사운드를 샘플로 사용     🔧 BitCrusher란?     **비트 크러셔(BitCrusher)**는 디지털 오디오를 **낮은 비트 깊이(bit depth)**와 **낮은 샘플링 레이트(sample rate)**로 변환하여 **거친 디지털 왜곡(digital distortion)**을 만드는 이펙트입니다.   이펙트는 종종 Lo-Fi, 게임 보이 스타일, 디지털 노이즈 효과, 글리치 사운드 등을 만들기 위해 사용됩니다.     🧩 파라미터 설명                 파라미터       범위       기본값       설명                       Bit Depth       1.0 ... 24.0       8.0       오디오 신호의 비트 해상도를 조절함.낮을수록 소리가 더 거칠고 노이즈감 많아짐.예: 2~6비트 → 극단적으로 왜곡된 사운드                 Sample Rate       0.0 ... 20000.0       10000.0       샘플링 주파수를 줄이면, 고주파 성분이 손실되고 디지털 느낌의 음질이 나타남.낮을수록 더 메탈릭하고 깨진 듯한 질감             🧠 예시                 설정       효과                       bitDepth = 4, sampleRate = 3000       매우 거친, 로우파이한 효과                 bitDepth = 16, sampleRate = 8000       라디오, 전화기 음질                 bitDepth = 24, sampleRate = 20000       깨끗한 오디오 (사실상 원본과 유사)             🎶 사용 용도     Lo-Fi 음악 제작   게임 사운드 디자인 (8비트 느낌)   신스 노이즈 변형   보컬 글리치 효과   베이스/기타에 디지털 질감 부여     ✅ 요약     BitCrusher는 **비트 수(bit depth)**와 **샘플레이트(sample rate)**를 줄여 디지털 왜곡을 만들어냄   파라미터를 줄이면 줄일수록 더 거칠고 디지털한 질감   디지털 아트, 글리치 음악, Lo-Fi 등에 적합   이 효과는 일반적인 컴프레서나 리버브와는 전혀 다른, 파괴적이고 실험적인 사운드 질감을 만들고 싶을 때 유용합니다. "
  },
  
  {
    "title": "AudioKit의 AppleDistortion",
    "url": "/posts/AppleDistortion/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-13 14:55:39 +0900",
    "content": "Apple Distortion  AppleDistortion은 iOS/macOS의 AVAudioUnitDistortion 클래스를 활용하여 오디오에 디지털 왜곡(distortion) 효과를 주는 Audio Unit입니다. 이는 앰프의 과도한 증폭, 디지털 클리핑, 비선형 처리를 시뮬레이션하며, 일반적으로 기타, 베이스, 전자음향, 노이즈 기반 사운드 디자인 등에 사용됩니다.    🧩 AVAudioUnitDistortionPreset란?  AVAudioUnitDistortion은 Apple에서 사전 설정한 여러 가지 왜곡 효과 프리셋을 제공합니다. 이 프리셋들은 .loadFactoryPreset(_:) 메서드를 통해 쉽게 사용할 수 있으며, 각각 고유의 톤과 질감을 갖고 있습니다.    📦 프리셋 목록 및 설명                 프리셋       설명                       drumsBitBrush       비트 레이트 감소 + 브러시 사운드, 타악기에서 그릿(grit) 추가                 drumsBufferBeats       텍스처와 노이즈 기반, 루프 타악기에 사용                 drumsLoFi       낮은 해상도(Lo-Fi) 느낌의 왜곡, 필터 적용                 multiBrokenSpeaker       스피커가 망가진 듯한 거칠고 깨지는 사운드                 multiCellphoneConcert       핸드폰으로 콘서트를 녹음한 듯한 음질, 노이즈 + 압축된 음상                 multiDecimated1 ~ 4       낮은 샘플레이트와 비트뎁스로 변형된 디지털 디스토션                 multiDistortedFunk       펑키하고 압축된 기타 스타일 사운드                 multiDistortedCubed       왜곡을 3배로 겹쳐서 매우 강한 왜곡감                 multiDistortedSquared       왜곡을 2배로 적용한 느낌, 일반적인 강한 디스토션                 multiEcho1 ~ 2       딜레이와 디스토션을 결합한 사운드                 multiEchoTight1 ~ 2       딜레이가 짧아 더 타이트한 딜레이+왜곡                 multiEverythingIsBroken       노이즈, 클리핑, 비선형성이 가득한 해체적인 사운드                 speechAlienChatter       외계인이 말하는 듯한 변조된 음성                 speechCosmicInterference       우주 잡음, 노이즈 계열 디스토션                 speechGoldenPi       음성에 피치 변화와 반사감이 있는 효과                 speechRadioTower       라디오 수신 상태가 안 좋은 듯한 왜곡                 speechWaves       모듈레이션 + 미세한 디스토션으로 만든 음성 변화                 speechCellphoneConcert       핸드폰 콘서트 녹음 느낌, 로우패스+클리핑                 speechDecimated       낮은 비트율, 디지털 음질 붕괴 느낌                 speechVocalFry       목소리가 갈라지는 듯한 질감             🎛 각 프리셋들의 사용 예시                 용도       추천 프리셋                       기타/베이스       multiDistortedSquared, multiBrokenSpeaker, multiDecimated2                 전자음악/신스       multiEverythingIsBroken, multiEcho1                 음성 디자인       speechAlienChatter, speechVocalFry, speechRadioTower                 Lo-Fi 효과       drumsLoFi, multiDecimated1                 사운드 아트       speechWaves, multiCellphoneConcert             ✅ 요약     AppleDistortion = AVAudioUnitDistortion을 활용한 Apple 기본 오디오 왜곡 유닛   Preset은 Apple이 만든 왜곡 유형을 미리 저장한 세트   multiDecimated, multiDistorted*, multiEcho* 시리즈는 각 효과의 강도나 세부 설정 차이만 있을 뿐, 기본 컨셉은 동일   실시간으로 음원을 로딩해서 .loadFactoryPreset(...)으로 적용 가능   이 기능은 AudioKit에서도 래핑되어 활용되므로, 효과적으로 다양한 음향 실험을 할 수 있습니다. "
  },
  
  {
    "title": "AudioKit의 VariableDelay",
    "url": "/posts/VariableDelay/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-12 18:40:46 +0900",
    "content": "Variable Delay  VariableDelay는 입력 오디오 신호에 가변적인 시간 지연(딜레이)을 적용하는 이펙트입니다. SoundpipeAudioKit에 포함된 효과로, 지연 시간을 실시간으로 변화시킬 수 있는 점이 특징입니다.    🔧 클래스 설명  class VariableDelayConductor: BasicEffectConductor&lt;VariableDelay&gt;      BasicEffectConductor&lt;VariableDelay&gt;를 상속받아 기본적인 플레이어, 이펙트 적용, 믹싱 구조를 재사용합니다.   VariableDelay(input)을 통해 입력 신호에 VariableDelay 이펙트를 적용합니다.     🎛️ 파라미터 설명                 파라미터 이름       기본값       범위       설명                       Delay Time       0.0 s       0.0 ~ 10.0 s       오디오를 지연시키는 시간 (초 단위). 시간이 클수록 소리가 나중에 들립니다. 딜레이 효과의 기본 요소.                 Feedback       0.0       0.0 ~ 1.0       출력된 딜레이된 소리를 다시 입력으로 되돌리는 비율. 0에 가까울수록 반복 없음, 1에 가까울수록 지속적인 에코 발생.             🧠 활용 예시                 상황       설정 예                       간단한 딜레이       Delay Time: 0.3, Feedback: 0.2                 에코 효과       Delay Time: 0.6, Feedback: 0.7                 변조된 반복음       Delay Time을 실시간으로 변화시켜 디지털 특유의 변화를 만듦             🎵 음향적 특징     VariableDelay는 일반 Delay와 달리 지연 시간이 실시간으로 바뀌어도 부드럽게 연결됨.   특히 LFO, 랜덤, 마우스/슬라이더 등 외부 입력으로 Delay time을 조절할 때 유용.   피드백이 크면 점점 작아지는 메아리처럼 들림.     ✅ 요약     VariableDelay는 실시간으로 지연 시간을 변화시킬 수 있는 고급 딜레이 효과.   Delay time: 지연 시간 설정.   Feedback: 반복 여부 및 강도 조절.   실험적인 사운드, 라이브 조작, 자동화 딜레이 등에 이상적.  "
  },
  
  {
    "title": "AudioKit의 TransientShaper",
    "url": "/posts/TransientShaper/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-12 18:32:53 +0900",
    "content": "Transient Shaper  TransientShaper는 오디오 신호의 일시적인 부분(Transients) 을 조정하여 어택(Attack) 과 릴리즈(Release) 의 강도를 강조하거나 약화시키는 이펙트입니다. 주로 타악기(드럼, 퍼커션) 등의 명료도와 타격감을 향상시키거나 부드럽게 만들 때 사용됩니다.    🧠 Transient Shaper란?     Transient: 소리의 초기 순간적인 변화, 특히 드럼처럼 빠르게 올라갔다 내려가는 소리.   Shaper: 특정한 특성을 강조하거나 줄이는 프로세서.   📌 따라서 TransientShaper는 소리의 시작과 끝을 제어하여 질감을 다듬는 효과를 줍니다.    🎛️ 파라미터 설명                 파라미터       기본값       범위       설명                       Input       0.0 dB       -60.0 ~ 30.0 dB       입력 게인. 들어오는 오디오의 전체 볼륨을 조절합니다.                 Attack       0.0 dB       -40.0 ~ 40.0 dB       소리의 시작 부분(transient)의 강조/감소 정도. 양수로 키우면 어택이 더 또렷해지고, 음수면 부드러워집니다.                 Release       0.0 dB       -40.0 ~ 40.0 dB       소리의 끝부분(sustain/release)의 강조/감소 정도. 양수면 여운을 늘리고, 음수면 짧아집니다.                 Output       0.0 dB       -60.0 ~ 30.0 dB       최종 출력 볼륨 조절. 전체적인 레벨 보정용입니다.             🪓 예시     드럼이 너무 뭉개질 때 → Attack +20, Release -10: 킥, 스네어가 더 “툭!” 하고 튀어나옴   기타 스트로크가 너무 거칠 때 → Attack -10, Release +10: 부드럽고 따뜻한 느낌   전체 믹스에 더 날카로움 추가 → Attack +10: 전체에 퍼진 사운드에서 디테일 강조     🧩 사용 목적 요약                 목적       설정 예                       드럼의 타격감 강조       Attack ↑                 소리를 부드럽게       Attack ↓                 리버브 여운 줄이기       Release ↓                 소리 길게 늘리기       Release ↑             ✅ 요약     TransientShaper는 어택과 릴리즈를 독립적으로 제어하여 소리의 명료도, 타격감, 여운을 조절하는 도구입니다.   특히 드럼/퍼커션, 기타, 보컬에 많이 사용됩니다.   Attack과 Release 모두 ±40dB 범위로 조정 가능해 극적인 효과부터 미묘한 보정까지 가능.  "
  },
  
  {
    "title": "AudioKit의 TimePitch",
    "url": "/posts/TimePitch/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-11 15:33:28 +0900",
    "content": "Time Pitch  TimePitchConductor는 재생 중인 오디오 파일의 속도(재생률)와 음높이(피치)를 독립적으로 조절할 수 있도록 하는 AudioKit의 TimePitch 이펙트를 제어하는 클래스입니다.  기본적으로 Apple의 AVAudioUnitTimePitch를 래핑한 것으로, 실시간 입력(live input) 이나 신호 생성기(generated signal) 에는 작동하지 않고, 파일 기반 재생(예: AudioPlayer)에만 적용됩니다.    🧠 영어 코멘트 해석과 의미  // With TimePitch you can easily change the pitch and speed of a player-generated sound.   // It does not work on live input or generated signals.      TimePitch를 사용하면 플레이어에서 생성된 소리의 피치(음높이)와 속도(재생 속도)를 쉽게 변경할 수 있습니다. 그러나 실시간 입력(live input) 또는 오디오 생성기에서 생성된 신호에는 작동하지 않습니다.   즉, 마이크 입력이나 오실레이터에는 적용되지 않으며, .mp3, .wav 등 파일을 재생하는 AudioPlayer에만 적용 가능합니다.    🎚️ 파라미터 설명  TimePitch는 2가지 주요 파라미터를 제공합니다.                 파라미터       기본값       범위       설명                       rate       2.0       0.25 ... 4.0       재생 속도를 조절합니다. 1.0은 원래 속도, 2.0은 2배 빠르게, 0.5는 절반 속도로 재생됩니다.                 pitch       -400       -2400 ... 2400 (센트, cents)       음높이를 조절합니다. +100은 반음(sharp), -100은 반음(flat)에 해당합니다. -400은 4반음 낮게 조정한 것입니다.              🎵 센트(cents): 1반음(semitone)은 100 cents. 따라서 pitch = 1200이면 한 옥타브(12음) 위로 올라갑니다.     🧪 실제 사용 예     보이스 체인저: 낮은 음성(pitch = -400)이나 로봇 음성 효과   리믹스 / DJ 애플리케이션: 속도를 올리되 음높이는 유지 (rate ↑, pitch = 0)   느린 연습 도구: 속도는 줄이고 음은 그대로 (rate = 0.5, pitch = 0)     📌 요약     TimePitch는 파일 재생 음원의 피치와 속도를 독립적으로 조절하는 이펙트입니다.   rate로 재생 속도, pitch로 음높이(센트 단위) 를 조절합니다.   AVAudioUnit 기반이라 ramp 애니메이션은 불가 — 즉, 값은 즉시 적용됩니다.   마이크나 오실레이터 등 실시간 소스에는 사용 불가하므로, AudioPlayer와 함께 사용할 때만 의미가 있습니다.  "
  },
  
  {
    "title": "AudioKit의 StringResonator",
    "url": "/posts/StringResonator/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-11 15:32:30 +0900",
    "content": "String Resonator  StringResonatorConductor는 입력 신호에 현악기 공진 효과(String Resonance)를 적용하는 AudioKit 이펙트 노드를 사용하는 클래스입니다. 구체적으로는 SoundpipeAudioKit 라이브러리의 StringResonator를 래핑하며, 지정된 주파수에 기반한 공진(resonance) 효과를 시뮬레이션합니다.    🎻 StringResonator란?  String Resonator는 현의 공명을 시뮬레이션하여 입력된 오디오 신호에 물리적인 현악기 특유의 울림을 부여합니다. 마치 어떤 신호가 줄 위에서 울리는 것처럼 특정 주파수 대역에서 증폭(resonance) 이 일어나며, 더 자연스럽고 음악적인 울림을 생성할 수 있습니다.    🎛️ 파라미터 설명                 파라미터 이름       기본값       범위       설명                       Fundamental Frequency       100.0       12.0 ... 10000.0       공명할 기본 주파수(Hz)입니다. 이 주파수를 중심으로 공명이 발생합니다. 낮으면 베이스 현처럼, 높으면 바이올린처럼 울릴 수 있습니다.                 Feedback       0.95       0.0 ... 1.0       공명 신호를 얼마나 오랫동안 유지할지를 결정합니다. 1에 가까울수록 더 오랫동안 울림이 지속되며, 0에 가까우면 거의 공명이 발생하지 않습니다.             🧠 예시 사용법     기타 플러그인을 대신하여 현악기 특유의 울림을 줄 때   피아노나 스트링 악기의 음원에 깊이 있는 울림을 더하고 싶을 때   사운드 디자인: 어떤 음향이 울리는 공간이 아니라, 울리는 물체 위에서 발생하는 것처럼 보이게 만듦     📌 정리  StringResonatorConductor는 BasicEffectConductor를 상속받아 기본 오디오 엔진과 드라이/웻 믹싱을 그대로 사용하면서, 현에서 공명하는 듯한 효과를 입력 오디오에 더하는 역할을 합니다. Fundamental Frequency와 Feedback 두 개의 파라미터를 조절하여 원하는 공진 특성을 정밀하게 설정할 수 있습니다. "
  },
  
  {
    "title": "AudioKit의 StereoDelay",
    "url": "/posts/StereoDelay/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-11 15:32:02 +0900",
    "content": "Stereo Delay  StereoDelay는 좌우 채널에 독립적인 지연(Delay) 을 적용하여 넓은 스테레오 이미지를 만들거나, 리듬감 있는 효과, 그리고 반사음 같은 공간감을 만드는 데 사용됩니다. 이 효과는 입력 신호를 복제하여 시간차를 두고 재생하며, 여러 가지 파라미터로 정밀하게 조절할 수 있습니다.    🎛️ StereoDelay 파라미터 설명                 파라미터       기본값       범위       설명                       Delay time (Seconds)       0.0       0.0 ... 2.0       좌우 채널에 적용되는 딜레이 시간입니다. 클수록 에코 간격이 넓어지며, 공간감이 더 커집니다.                 Feedback (%)       0.0       0.0 ... 1.0       딜레이된 소리를 다시 입력으로 보내는 양입니다. 0에 가까우면 한 번만 울리고, 1에 가까울수록 반복적으로 울립니다 (에코 반복).                 Dry-Wet Mix       0.5       0.0 ... 1.0       원본 신호(dry)와 딜레이된 신호(wet)의 비율을 조절합니다. 0이면 원본만, 1이면 딜레이된 신호만 출력됩니다.                 Ping-Pong Mode       0.0       0.0 ... 1.0       좌우 채널을 번갈아 가며 딜레이를 전달하는 효과입니다. 0이면 일반 스테레오 딜레이, 1이면 딜레이가 왼쪽 → 오른쪽 → 왼쪽… 으로 이동하며 반복됩니다. 스테레오 움직임이 강해집니다.             🎧 실제 활용 예     Ping-Pong Delay: 리드 악기나 보컬에 사용하면 공간감과 리듬감을 부여합니다.   Feedback 높임: EDM이나 앰비언트 음악에서 반복적이고 잔향이 긴 효과를 만들 때 사용합니다.   Dry/Wet 조절: 자연스러운 배경 에코로 만들거나, 전면에 나서는 이펙트로 만들 수 있음.     ✅ AudioKit에서의 역할 요약     StereoDelay(input)으로 입력 오디오를 받아,   파라미터로 시간, 반복성, 원/딜레이 비율, 좌우 딜레이 구조를 조정할 수 있음.   즉, 스테레오 기반의 유연한 딜레이 이펙트를 만들 수 있는 노드입니다. "
  },
  
  {
    "title": "AudioKit의 PitchShifter",
    "url": "/posts/PitchShifter/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-10 13:15:57 +0900",
    "content": "Pitch Shifter  PitchShifter는 **입력된 오디오의 피치(pitch)**를 바꾸는 오디오 이펙트입니다. 즉, 재생 속도는 그대로 유지하면서 음정만 높이거나 낮춥니다. 예를 들어, 녹음된 목소리를 고음으로 만든다거나 저음으로 만들 때 사용됩니다.    🎛 PitchShifter의 역할     오디오 신호의 속도를 변경하지 않고 음높이를 조절   보컬 하모니 생성, 특수 효과, 보이스 체인지 등에 유용     🧪 파라미터 설명                 파라미터       기본값       범위       설명                       Shift       0.0       -24.0 ~ 24.0       피치 이동 범위. 세미톤 단위. +12는 한 옥타브 위, -12는 한 옥타브 아래.                 Window Size       1024       0.0 ~ 10000.0       피치 시프트를 위한 분석 창의 크기. 크면 더 정확하지만 지연(latency) 증가. 작으면 반응 빠르지만 품질 저하 가능.                 Crossfade       512       0.0 ~ 10000.0       창을 옮길 때 생기는 경계 소리를 부드럽게 이어주는 범위. 값이 클수록 더 부드럽고 매끄럽지만 더 많은 연산 필요.             🎧 각 수치 변화의 효과  🔹 Shift     +12 → 한 옥타브 위로 이동 (고음)   -12 → 한 옥타브 아래로 이동 (저음)   0 → 변경 없음   🔹 Window Size     작게 설정 (예: 512 이하) → 실시간 반응 빠름 (라이브 효과), 하지만 품질 저하나 잡음 가능   크게 설정 (예: 2048 이상) → 고품질 결과, 그러나 반응이 느림 (약간의 딜레이)   🔹 Crossfade     작게 설정 → 더 날카로운 소리, 간혹 튀는 느낌   크게 설정 → 더 부드럽게 이어짐, 자연스러운 소리     🔊 예시 사용처     자동 하모니 생성기   보이스 피치 조절 (예: 로봇 목소리, 어린이 목소리)   다이나믹 피치 조정 효과 (DJ 효과, EDM 필터)     필요에 따라 이 파라미터들을 실시간으로 슬라이더와 바인딩해 조절하는 것도 가능합니다. "
  },
  
  {
    "title": "AudioKit의 Phaser",
    "url": "/posts/Phaser/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-10 13:12:41 +0900",
    "content": "Phaser  Phaser는 오디오 이펙트 중 하나로, 위상차(phase shift)를 활용해 소리에 움직임과 공간감을 부여하는 모듈레이션 효과입니다. 일렉트릭 기타, 신스 패드, 보컬 등에 자주 쓰이며, 독특한 “스윙” 혹은 “스윕”되는 듯한 소리를 만듭니다.    🌀 Phaser의 작동 방식  Phaser는 입력 신호의 주파수 스펙트럼에 여러 개의 Notch Filter(노치 필터; 특정 주파수만 선택적으로 잘라내는 필터) 를 만들어, 이들을 저주파 오실레이터(LFO) 로 시간에 따라 움직이게 함으로써 독특한 공간감과 움직임을 만들어냅니다.    🔧 파라미터 설명                 파라미터 이름       설명       수치 변화 시 효과                       Min Notch Frequency       노치 필터 주파수의 최소 범위 (Hz)       값이 낮을수록 저역대에서 효과 발생. 예: 100Hz는 베이스에, 1000Hz는 중역에 영향                 Max Notch Frequency       노치 필터 주파수의 최대 범위 (Hz)       값이 높을수록 고역까지 효과가 적용됨                 Notch Width       하나의 노치가 영향을 주는 주파수 대역폭 (Hz)       크면 더 부드럽고 넓게, 작으면 좁고 뾰족한 느낌                 Notch Frequency       LFO가 얼마나 빠르게 주파수를 변화시키는가 (단위 없음, 비율)       1.1~4.0 사이, 값이 높을수록 빠르게 움직임                 Vibrato Mode       0: 기본 위상 효과 / 1: 비브라토처럼 진동 위주 효과       1.0으로 설정 시 피치 변화 느낌 있음                 Depth       효과 적용 강도 (0.0 ~ 1.0)       1.0이면 효과가 최대치, 0이면 원음과 동일                 Feedback       처리된 신호를 다시 입력에 얼마나 섞을지 (0.0 ~ 1.0)       높을수록 더욱 강하고 날카로운 위상감 생성                 Inversion       위상 반전 여부 (0.0: 비활성 / 1.0: 활성)       켜면 사운드가 좀 더 독특하게 바뀔 수 있음                 LFO Frequency       LFO의 진동 주기 (Hz)       값이 높을수록 빠르게 움직이며, 매우 높은 수치는 빠른 떨림 효과 유발             🎧 실질적인 사용 예     값 낮음 → 자연스럽고 느릿한 위상감 (예: 패드, 앰비언스)   값 높음 → 날카롭고 전자적인 느낌 (예: 신스 베이스, 퍼커션)     📌 정리     Phaser는 시간에 따라 움직이는 주파수 필터를 사용해 회전감 있고 요동치는 사운드를 만들어냅니다. 주파수 범위, 깊이, 속도, 피드백 등을 조절함으로써 다양한 캐릭터의 소리를 만들어낼 수 있습니다. 🎛     💡 팁     Depth와 Feedback을 높게 하면 공격적인 소리가,   Notch Frequency와 LFO Frequency를 조절하면 리드미컬하거나 스페이시한 질감이 나옵니다.  "
  },
  
  {
    "title": "AudioKit의 PhaseLockVocoder",
    "url": "/posts/PhaseLockVocoder/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-09 14:39:26 +0900",
    "content": "Phase Lock Vocoder  이 코드는 AudioKit 프레임워크를 사용해 Phase Locked Vocoder를 제어하고 시각화하는 macOS 또는 iOS용 SwiftUI 앱입니다. 주 목적은 사전 녹음된 오디오 파일을 불러와 PhaseLockedVocoder 효과를 적용하고, 사용자 입력에 따라 음성을 조작할 수 있도록 하는 오디오 이펙트 체험 도구입니다.    🧠 프로그램 개요  이 앱은 다음과 같은 역할을 합니다:                 기능       설명                       🎧 오디오 파일 선택       드럼, 피아노 등 다양한 오디오 소스를 선택할 수 있음 (Picker)                 🌀 Vocoder 효과 적용       PhaseLockedVocoder를 통해 입력 오디오에 특수한 변조 효과를 적용                 🎛️ 실시간 조작       Ribbon UI를 통해 position 파라미터를 사용자가 조작 가능                 🔊 오디오 출력       NodeOutputView로 출력 시각화             🔩 주요 구성 요소 설명  PhaseLockedVocoderConductor     ObservableObject를 채택해 SwiftUI 뷰와 바인딩됨.   AudioKit의 AudioEngine, AudioPlayer, **PhaseLockedVocoder**를 초기화하고 연결함.        @Published:             source: 오디오 소스 변경 시 자동으로 setup() 호출하여 효과 적용.       position: 사용자 인터페이스에서 리본 조작 시 Vocoder의 position 파라미터를 실시간으로 업데이트.           setup(source:)     .drums 같은 GlobalSource 열거형을 기반으로 번들에서 오디오 파일을 불러옴.   PhaseLockedVocoder(file:)로 vocoder를 생성하고 AudioEngine 출력에 연결.     PhaseLockedVocoderView     SwiftUI 뷰로 사용자 인터페이스를 구성.   @StateObject로 conductor를 보유하고 있어 상태 변화를 감지.        주요 UI:             Picker: 소스 선택       Text: 현재 position 표시       Ribbon: position 값을 조절       NodeOutputView: 오디오 출력 시각화             🎙️ PhaseLockedVocoder란?  PhaseLockedVocoder는 일반적인 Vocoder와 달리 신호의 위상과 주파수를 동기화하여 더 자연스럽고 명료한 음성 변조를 생성하는 AudioKit의 DSP 이펙트입니다.     원리: 입력 신호의 주파수 성분을 분해한 후, 위상을 고정(fix)한 채 다시 조합하여 새로운 합성된 소리를 생성. 음색은 변형되지만 명료도를 유지함.   효과: 일반 보코더보다 자연스럽고 음정 변화 시 위상 깨짐이 덜함. 로봇 보이스, 특수 보컬 효과 등에 적합함.   Vocoder?  Vocoder(Voice Encoder)는 원래는 음성 압축 기술이었지만, 음악에서는 한 소리(주로 음성)의 특징을 다른 소리(주로 신디사이저 등)에 입혀서 새로운 소리로 만드는 효과를 말합니다. 예: 로봇 목소리, “Daft Punk”나 “Zedd” 등에서 들리는 음성 변조 효과.  파라미터 목록  pitchRatio와 amplitude는 PhaseLockedVocoder에서 소리의 성질을 제어하는 중요한 파라미터입니다. 아래에 각각의 의미와 효과를 설명드리겠습니다.    position: 분석된 주파수 영역 중 어느 위치를 참조할지  (보통 0.0 ~ 1.0 범위).  🎚 pitchRatio: 피치 비율 조절     정의: 원본 오디오의 주파수를 몇 배로 늘릴지를 지정합니다.        값의 범위 예시:             1.0 → 원래 음정       2.0 → 1옥타브 위       0.5 → 1옥타브 아래       1.5 → 완전 5도 위           🎧 효과     pitchRatio = 1.0: 원본의 음정 그대로 재생   &gt; 1.0: 음정이 높아지고, 마치 헬륨가스를 마신 듯한 보컬 느낌   &lt; 1.0: 음정이 낮아지고, 저음의 느린 목소리처럼 들림      💡 보코더 효과의 핵심 조절 요소입니다. 음성을 키우거나 낮추어 특수한 음성 변형을 만듭니다.   📢 amplitude: 출력 음량 조절     정의: vocoder가 출력하는 사운드의 볼륨 레벨을 조절합니다.   일반 범위: 0.0 ~ 1.0   🎧 효과     0.0: 출력 없음 (음소거)   0.5: 절반 정도의 음량   1.0: 원래의 전체 볼륨      이 파라미터는 음색을 바꾸는 것이 아니라 최종 볼륨 크기를 조절할 때 사용됩니다.   🧪 함께 사용할 때     pitchRatio는 음색과 분위기를 바꾸고,   amplitude는 **소리의 강도(볼륨)**를 조절합니다.   예를 들어 pitchRatio = 0.7, amplitude = 0.5로 설정하면 → “낮은 피치의 부드러운 로봇 보컬” 같은 느낌이 납니다.    🧪 사용 예시     음악 앱에서 보컬 트랙을 가공하거나   오디오 실험 앱에서 음성 조작 실습 도구로 사용   실시간 사운드 퍼포먼스에 Vocoder 효과 삽입   🎶 신디사이징 및 리샘플링 도구로도 사용 가능     🎯 왜 position으로 특정 음이 지속되나?  PhaseLockedVocoder는 FFT(고속 푸리에 변환) 기반 분석을 통해 소리를 주파수 스펙트럼으로 분해합니다. 그 스펙트럼 중 한 지점을 position으로 고정하면, 해당 대역에 존재하던 에너지(=음색)를 계속 유지하며 해당 음의 성분만 출력하는 형태가 됩니다.  예시:     position = 0.3: 원본 소리의 30% 지점(주로 특정 음역)의 주파수 성분만 출력   position = 0.8: 더 높은 음역대의 특정 주파수 성분만 출력됨     🧩 이걸 어디에 쓰나?  이건 단순히 음을 재생하는 게 아니라, 음성 또는 소리의 특정 특성(음색, 공명점 등)을 고정하고 그걸 악기처럼 연주하는 데 사용됩니다.  예시 활용:          특정 음색 추출 보컬에서 아, 에, 이처럼 들리는 부분을 고정해놓고 필터처럼 사용           실시간 조작 position을 슬라이더나 리본 UI로 연속 조작하면 음색이 흐르듯 변화 — 보코더 필터처럼 사용 가능           사운드 디자인 화성적 움직임 없이도 음색 기반으로 분위기 구성 가능 (예: 앰비언트 음악, 효과음 등)        🛠 요약                 동작       설명                       position을 고정       특정 음역의 스펙트럼만 유지되어 해당 음만 지속                 슬라이더로 position 이동       음역/음색이 연속적으로 바뀌는 효과 발생                 응용       음성 음색을 기반으로 하는 신디사이저처럼 사용           즉, PhaseLockedVocoder는 단순한 이펙터라기보다 소리의 주파수 특성을 악기처럼 쓰는 음향 도구라고 이해하시면 됩니다.    ✅ 실전 사용 방식          position을 고정             원본 오디오의 스펙트럼 중 특정 위치(음색)를 선택합니다.       예: 보컬 샘플의 ‘아’ 소리가 나는 부분에 해당하는 포지션 0.3 정도                pitchRatio를 조절             고정된 스펙트럼(음색)을 더 높거나 낮은 음으로 피치 변환해서 재생합니다.       즉, 한 음색으로 다양한 음을 연주할 수 있게 됩니다.                (선택) amplitude를 조절             출력 음량(진폭)을 조절하며, 대부분 0.0~1.0 사이로 설정합니다.             🎵 예제 설명  예를 들어 보컬 샘플을 사용한다고 가정할 때:                 설정       의미                       position = 0.25       ‘E’ 발음처럼 들리는 부분을 고정                 pitchRatio = 1.0       원래의 피치로 출력                 pitchRatio = 2.0       한 옥타브 위에서 출력                 pitchRatio = 0.5       한 옥타브 아래에서 출력                 position = 0.8       ‘O’ 소리처럼 무거운 톤으로 전환             📌 요약                 파라미터       역할                       position       음색의 고정 지점 (정적인 주파수 성분 선택)                 pitchRatio       해당 음색의 높낮이 조절 (실제 피치 변경)                 amplitude       출력 음량 조절           이 구조를 활용하면, 한 가지 소리(보컬, 신스 등)를 입력으로 다양한 음을 만드는 보코더 신디사이저처럼 사용할 수 있습니다. "
  },
  
  {
    "title": "AudioKit의 PeakLimiter",
    "url": "/posts/PeakLimiter/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-08 16:22:29 +0900",
    "content": "Peak Limiter  🎚️ 피크 리미터(Peak Limiter)란?  피크 리미터는 오디오 신호의 최대 진폭(peak amplitude)을 강제로 제한(clamp) 하여 지정된 레벨 이상으로 신호가 넘어가지 않도록 막는 효과입니다. 보통 다음과 같은 상황에 사용됩니다:     🔊 클리핑 방지: 신호가 너무 커서 디지털 클리핑이 발생하는 것을 막기 위해   🎤 라이브 입력: 마이크나 악기처럼 예상할 수 없는 큰 소리가 들어올 때   📼 마스터링: 오디오 트랙의 피크를 일정 수준으로 제한해 과도한 출력 방지     🔧 주요 파라미터 설명  Attack Time | 0.012 | 0.0005...0.03 Decay Time  | 0.024 | 0.001...0.04 Pre Gain    | 0.0   | -40.0...40.0   1. 🕒 Attack Time     의미: 입력 신호가 임계값을 초과했을 때 리미팅을 시작하는 데 걸리는 시간 (초)   짧을수록: 빠르게 반응해 순간적인 피크도 잘 잘라냅니다.   길수록: 부드럽게 반응하지만, 빠른 트랜지언트(예: 킥 드럼)는 놓칠 수 있습니다.                  값       효과 설명                       0.0005       극단적으로 빠르게 반응                 0.012       일반적인 설정 (기본값)                 0.03       느리게 반응, 더 자연스러움             2. 🕓 Decay Time     의미: 피크 리미터가 동작한 후 원래 상태로 회복되는 시간 (초)   짧을수록: 리미팅이 빠르게 해제됨 → 소리가 튀듯 들릴 수 있음   길수록: 더 부드럽고 자연스럽게 해제됨 → 지속적인 리미팅 효과                  값       효과 설명                       0.001       빠르게 원상 복구됨                 0.024       일반적인 설정 (기본값)                 0.04       자연스럽고 부드럽게 복원됨             3. 🔊 Pre Gain     의미: 리미터 전에 신호를 증폭 or 감쇠        용도:             음량이 작은 소스를 리미터 수준까지 끌어올릴 때       리미팅 테스트를 위해 신호를 강제로 클리핑 수준까지 올릴 때           양수 값: 리미터가 더 자주, 더 강하게 작동함   음수 값: 신호가 약해져 리미터가 잘 작동하지 않음                  값       효과                       -40.0       거의 리미팅 작동 안 함                 0.0       원래 볼륨                 +10.0       피크 리미팅 자주 발생                 +40.0       매우 자주 리미팅 발생 (강제)             📈 시각적 예시  원래 신호:      ────────▇▇▇▇▇──────────────  리미터 적용 후: ────────█████──────────────  ← 일정 레벨 이상 깎임     참고: 리미터와 컴프레서의 차이  일반적으로 PeakLimiter는 “어느 볼륨부터 리미트를 걸지”에 대한 명시적인 임계값(threshold) 설정이 없습니다. 대신, 내부적으로 고정된 threshold 값을 기준으로 동작합니다. 즉:     PeakLimiter는 사용자가 threshold(임계값)를 직접 설정하지 않아도,   내부에서 적절한 임계값(예: -0.1dBFS, -0.3dBFS 등)을 기준으로 판단하여,   그 이상으로 올라가는 피크에 자동으로 리미트(limiting)를 적용합니다.   📌 리미터 vs 컴프레서 비교                 구분       PeakLimiter       Compressor                       Threshold       사용자가 설정 못함 (내장값 사용)       사용자가 직접 설정함                 Ratio       매우 높음 (∞:1)       다양하게 설정 가능 (예: 2:1, 4:1)                 용도       피크 급락 방지, 클리핑 방지       음량 균형 조절, 다이내믹 톤 연출                 적용 시점       마스터링, 라이브 입력 안정화       개별 트랙 조정, 믹싱 단계 등           💡 내부 임계값이란?  AudioKit의 PeakLimiter는 Apple의 AVAudioUnitPeakLimiter를 감쌌으며, 해당 Apple 문서에서는 threshold 설정이 없고 다음처럼 설명됩니다:     “This effect prevents clipping by automatically limiting the amplitude of audio that exceeds a certain internal threshold. (이 효과는 특정 내부 임계값을 초과하는 오디오의 진폭을 자동으로 제한하여 클리핑을 방지합니다.)”   즉, 사용자가 직접 어느 볼륨부터 자를지는 못 정하고, 리미터가 자동으로 판단해 적용하는 구조입니다.    ✅ 정리                 요소       설명                       PeakLimiter       최대 신호 진폭을 제한하여 클리핑 방지                 Attack Time       리미터가 작동을 시작하는 속도                 Decay Time       리미터가 원상복귀하는 속도                 Pre Gain       리미터 전에 신호 증폭/감쇠                 활용 상황       라이브 입력, 마스터링, 과도한 피크 방지 등           이 리미터는 특히 예상할 수 없는 입력의 최대 음량을 안전하게 제한할 때 유용합니다. "
  },
  
  {
    "title": "AudioKit의 MultiTapDelay",
    "url": "/posts/MultiTapDelay/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-07 14:53:20 +0900",
    "content": "Multi Tap Delay  MultiTapDelayConductor 클래스는 AudioKit을 사용하여 멀티탭 딜레이(Multi-Tap Delay) 효과를 구현하는 Swift 클래스입니다. 여러 개의 지연된 복사본을 입력 신호에 섞어 리듬감 있는 반복 효과나 리버브와 유사한 풍부한 공간감을 만들어냅니다.    📌 클래스 설명  class MultiTapDelayConductor: ObservableObject, ProcessesPlayerInput     ObservableObject: SwiftUI 뷰와 데이터를 바인딩하기 위해 사용됩니다. 슬라이더를 통해 딜레이 시간 및 게인 값이 바뀌면 뷰가 자동으로 업데이트됩니다.   ProcessesPlayerInput: 오디오 재생 처리를 담당하는 AudioKit Cookbook의 프로토콜입니다.     🔧 주요 변수                 변수 이름       설명                       engine       AudioKit의 오디오 엔진                 player       AudioPlayer: 오디오 파일을 반복 재생합니다.                 buffer       오디오 파일을 메모리에 로드한 버퍼. 음원 데이터 저장                 defaultSource       초기 재생할 오디오 파일. 여기서는 .femaleVoice                 delays       VariableDelay 배열. 각 탭의 지연 요소입니다.                 faders       Fader 배열. 각 탭의 게인 조절기입니다.                 times       슬라이더로 조절할 각 탭의 딜레이 시간 ([0.1, 0.2, 0.4]초)                 gains       각 탭의 출력 음량 ([0.5, 2.0, 0.5])             🎛️ init()     player.buffer에 오디오 데이터를 세팅하고 반복 재생을 설정합니다.   engine.output에 multiTapDelay(player, times: times, gains: gains)을 설정하여 엔진 출력에 멀티탭 딜레이 효과를 적용합니다.     🧩 multiTapDelay(_ input: Node, times: [AUValue], gains: [AUValue]) -&gt; Mixer     **입력 노드(input)**의 신호를 딜레이 + 게인 조절해서 믹서에 추가합니다.   딜레이와 게인은 슬라이더로 개별 조정 가능.   Mixer에 원본 입력도 함께 포함되어 Dry/Wet 믹싱 효과가 생깁니다.   for (i, (time, gain)) in zip(times, gains).enumerated() {   delays.append(VariableDelay(input, time: time))   faders.append(Fader(delays[i], gain: gain))   mix.addInput(faders[i]) }   즉, VariableDelay → Fader → Mixer 순으로 체인 구성합니다.    🔄 updateDelays()     슬라이더 값이 변경될 때마다 호출되어 딜레이 및 게인 값을 실시간 반영합니다.   delays[i].time = times[i] faders[i].gain = gains[i]     ✅ 요약                 구성 요소       설명                       🎧 딜레이 타임       [0.1, 0.2, 0.4]초로 지정된 여러 지점에서 입력 신호를 지연                 🎚 게인       각 딜레이된 신호의 볼륨을 개별 조절                 🎼 사용 효과       리듬감 있는 에코, 다층적인 반향, 리버브 유사 환경                 🔁 슬라이더 연동       @Published 값이 변할 때 updateDelays() 호출로 실시간 반영             📊 오디오 체인 구성도  player   │   ├──▶ VariableDelay(time: 0.1) ─▶ Fader(gain: 0.5) ─┐   ├──▶ VariableDelay(time: 0.2) ─▶ Fader(gain: 2.0) ─┤   ├──▶ VariableDelay(time: 0.4) ─▶ Fader(gain: 0.5) ─┤   └──────────────────────────────────────────────────▶ Mixer (최종 출력)     이 구조는 동일한 소스에서 여러 딜레이 시점을 만든 다음, 볼륨 조절 후 믹싱하는 구조로, 공간감 있고 풍부한 사운드를 만드는 데 매우 유용합니다. "
  },
  
  {
    "title": "AudioKit의 Flanger",
    "url": "/posts/Flanger/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-06 13:52:59 +0900",
    "content": "Flanger  Flanger는 오디오 이펙트 중 하나로, **짧은 시간 지연(delay)**과 **지속적인 변조(modulation)**를 이용해 스윙감이 있는 웅웅거리는 소리를 만들어내는 효과입니다. 일종의 위상 간섭을 활용하여 음원에 움직임을 부여합니다.    🎛️ Flanger의 역할     지연된 신호를 원래 신호에 더해서 두 신호 간의 위상 차이로 생기는 콤 필터(Comb Filter) 효과를 이용합니다.   이 지연 시간은 **LFO (Low Frequency Oscillator)**로 주기적으로 변화하며, 이로 인해 움직이는 듯한 “우웅~ 우웅~” 소리가 납니다.   전기 기타, 신디사이저, 드럼, 보컬 등 다양한 소스에 사용됩니다.     🧪 주요 파라미터 설명  1. Frequency (Hz)     범위: 0.1 ~ 10.0   기본값: 1.0   설명: 지연 시간에 변화를 주는 **LFO의 진동수(속도)**입니다. 즉, 플랜저의 움직임이 몇 초에 한 번 반복되는지 결정합니다.                  값       의미                       낮은 값 (0.1 ~ 1)       느린 스윙, 부드러운 움직임                 높은 값 (5 ~ 10)       빠른 진동, 트레몰로처럼 들릴 수 있음             2. Depth (0~1)     범위: 0.0 ~ 1.0   기본값: 0.25   설명: LFO가 지연 시간을 얼마나 변화시키는지, 즉 변조의 깊이입니다.                  값       효과                       낮은 값       미세한 움직임, subtle한 효과                 높은 값       강한 모듈레이션, 휘청거리는 소리             3. Feedback (-0.95 ~ 0.95)     범위: -0.95 ~ 0.95   기본값: 0.0   설명: 지연된 신호를 다시 입력에 섞는 비율입니다. 즉, 신호를 여러 번 순환시켜 더 진한 효과를 만듭니다.                  값       의미                       0.0       기본 플랜저 효과                 &gt; 0.0       점점 더 날카롭고 금속성 느낌                 &lt; 0.0       위상이 반전된 느낌, 다르게 움직이는 소리             4. Dry/Wet Mix (0~1)     범위: 0.0 ~ 1.0   기본값: 0.5   설명: 원래 소리(dry)와 플랜저 처리된 소리(wet)를 얼마나 섞을지 결정합니다.                  값       의미                       0.0       원본 소리만                 0.5       반반 혼합                 1.0       완전한 플랜저 효과만             🎧 예시 상황     🎸 일렉기타에 적용하면: “제트기 지나가는 듯한” 움직임이 생김   🧑‍🎤 보컬에 적용하면: 공중에 떠 있는 듯한 공간감   🥁 드럼에 적용하면: 리듬에 변화감 부여     📝 요약 표                 파라미터       설명       높일수록                       Frequency       LFO의 진동 속도       빠르게 움직이는 소리                 Depth       지연 시간의 변화 폭       강한 효과, 울렁거림                 Feedback       반복 횟수       금속적이고 진한 효과                 Dry/Wet       원본:이펙트 비율       100%면 완전히 변형된 소리             Flanger는 모듈레이션 기반 효과 중에서도 가장 개성 있는 이펙트 중 하나로, 잘만 쓰면 음원에 생동감과 움직임을 추가할 수 있습니다.  🎧 Flanger는 다음과 같은 상황에서 자주 사용됩니다. 핵심은 움직임·깊이감·특수 효과를 주고 싶을 때입니다:    🎸 1. 일렉트릭 기타     가장 전통적이고 널리 알려진 사용처입니다.   지연된 신호와 원음을 합쳐서 제트기 소리처럼 “쉭~ 우웅~” 하는 위상 간섭이 생김.   🎶 예: Van Halen – Ain’t Talkin’ ’Bout Love, The Police – Walking on the Moon      ✦ 특히 록, 메탈, 프로그레시브 록에서 배경을 몽환적으로 만들 때.     🎛️ 2. 신디사이저 / 패드 사운드     정적인 코드 진행에 움직임과 공간감을 부여함.   딜레이나 리버브처럼 공간계 효과는 아니지만, 모듈레이션 기반의 공간감을 줄 수 있음.   EDM, Ambient, Synthwave 등에서 많이 사용됨.     🥁 3. 드럼     하이햇이나 심벌, 때론 스네어에 플랜저를 걸어 리듬에 흐름감을 추가하거나,   빌드업 구간에서 점점 깊어지는 플랜저로 긴장감을 조성함.     🧑‍🎤 4. 보컬     리드보컬보다는 백킹보컬, 브리지 파트, 특수 효과용으로 사용   예를 들어, 꿈속 말하는 듯한 느낌이나 사이버 보이스를 연출할 때 적합     🧪 5. 효과음 (SFX)     영화/게임 등에서 레이저, 외계 소리, 사이버틱한 음향 효과를 만들 때 사용   일시적으로 강한 플랜저를 적용해 전환점, 강조 지점에 사용     ✅ 요약                 사용처       목적                       🎸 일렉기타       스윙감, 제트기 같은 소리                 🎛️ 신디사이저       패드에 깊이와 공간감 추가                 🥁 드럼       빌드업, 하이햇에 흘러가는 느낌                 🎤 보컬       몽환적, 미래적 분위기                 🧪 SFX       사이버틱, 외계적인 효과음             💡 팁: Flanger는 적게 쓰면 분위기 강화, 많이 쓰면 효과음화됩니다. 컨텍스트에 맞게 조절하는 것이 중요합니다. "
  },
  
  {
    "title": "AudioKit의 Expander",
    "url": "/posts/Expander/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-05 14:05:42 +0900",
    "content": "Expander  Expander는 작은 소리를 더 작게 만들어서 잡음을 줄이거나, 다이내믹 레인지를 넓히는 데 사용되는 오디오 효과입니다. 압축기(Compressor)와 반대 개념입니다. 아래는 각 파라미터의 역할과 수치 변화에 따른 음향적 효과를 설명한 내용입니다.    🔧 Expander 파라미터 상세 설명  1. Expansion Ratio (확장 비율)     설명: Threshold 이하의 소리 신호를 얼마나 줄일지를 결정합니다.   값 범위: 1.0 ~ 50.0   기본값: 2.0        작동 방식:             비율이 1.0:1이면 확장 없음 (flat)       비율이 2.0:1이면 threshold보다 2dB 낮은 입력은 4dB 감소       비율이 높을수록 작은 소리를 더 작게 만들어, 배경 소음 제거 효과 증가           ⬆ 증가 시 효과:     더 과감한 **노이즈 게이팅(noise gating)**처럼 작동   소리가 작을 때 거의 무음에 가깝게 됨   ⬇ 감소 시 효과:     소리의 자연스러움을 유지하며 미세한 잡음만 억제     2. Expansion Threshold (확장 임계값)     설명: 확장이 적용되기 시작하는 입력 레벨 (dBFS)   값 범위: -120.0 ~ 0.0 dB   기본값: 0.0   ⬆ 증가 시 효과:     더 큰 소리에만 확장이 적용되어, 덜 민감하게 작동   ⬇ 감소 시 효과:     아주 작은 신호도 확장되어, 미세한 소리까지 억제됨     3. Attack Time (공격 시간)     설명: 신호가 threshold를 넘어섰을 때 확장이 해제되는 시간 (초)   값 범위: 0.001 ~ 0.3 초   기본값: 0.001   ⬆ 증가 시 효과:     느리게 복원되므로 작아진 신호가 천천히 커짐 → 부드러운 동작   ⬇ 감소 시 효과:     빠르게 반응하여 더 뚜렷하게 변화 → 팍팍 꺼짐 느낌     4. Release Time (릴리스 시간)     설명: 신호가 다시 threshold 아래로 떨어졌을 때 확장이 다시 적용되기까지 걸리는 시간   값 범위: 0.01 ~ 3.0 초   기본값: 0.05   ⬆ 증가 시 효과:     확장 효과가 천천히 적용됨, 더 자연스럽게 소리 줄어듦   ⬇ 감소 시 효과:     빠르게 확장 적용, 즉시 작게 만듦 → 노이즈 컷에 유리하지만 부자연스러울 수 있음     5. Master Gain (출력 볼륨 보정)     설명: 전체 출력 신호의 최종 볼륨 조절   값 범위: -40.0 ~ +40.0 dB   기본값: 0.0   ⬆ 증가 시 효과:     전체 출력 신호의 음량을 올림   ⬇ 감소 시 효과:     전체 음량을 줄여서 더 부드러운 소리로 만듦     📝 요약                 파라미터       설명       증가 시 효과                       Expansion Ratio       작은 소리의 감소 비율       배경 소음 강하게 억제                 Threshold       확장 시작 레벨       확장 작동 범위 축소                 Attack Time       확장 해제 반응 속도       부드럽고 느린 복원                 Release Time       확장 적용 반응 속도       자연스러운 볼륨 감소                 Master Gain       전체 출력 볼륨       최종 볼륨 보정             🎧 응용 예시     보컬 트랙에서 리버브나 호흡 소리를 줄이고 싶을 때   녹음된 소스의 잡음을 제거할 때   부드러운 게이트처럼 사용하여 공간감을 조절할 때   Expander는 Compressor보다 쓰임새가 정교하지만, 잘 조절하면 소리의 명료도와 깨끗함을 향상시킬 수 있습니다. "
  },
  
  {
    "title": "딜레이(Delay)란?",
    "url": "/posts/Delay/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-05 14:03:00 +0900",
    "content": "Delay  음향에서 **딜레이(Delay)**는 소리를 일정 시간 지연시켜 다시 재생하는 **시간 기반 이펙트(time-based effect)**입니다. 이는 원래의 소리(dry signal)에 지연된 복제본(wet signal)을 더하여 공간감, 깊이, 리듬감, 반복 효과 등을 만들어냅니다.    📌 딜레이의 기본 개념     입력된 소리를 n 밀리초(또는 초) 동안 기다렸다가 다시 재생   인간의 귀는 30ms 이상의 지연을 “반사” 또는 “메아리”처럼 인식함     🎧 예시          에코(Echo)             “하이”라고 말하면, 잠시 후 “하이… 하이…”가 반복됨 → 딜레이 타임과 피드백이 큰 경우                슬랩백 딜레이(Slapback Delay)             짧은 딜레이(약 80~120ms)로 “하이-하이” 느낌 → 일렉트릭 기타 등에서 흔히 사용됨             ⚙️ 주요 매개변수                 매개변수       설명                       Delay Time       소리를 얼마나 늦게 재생할지 (ms 또는 s)                 Feedback       지연된 소리를 몇 번 반복할지 (0.0 ~ 1.0)                 Mix / Balance       원래 소리와 지연된 소리의 비율 조절                 Wet/Dry       Wet = 효과음, Dry = 원래 소리             🎼 딜레이의 응용                 응용 분야       설명                       보컬 딜레이       라이브 공연, 믹싱에서 공간감과 감정을 강조                 기타 딜레이       음을 겹쳐 풍부한 사운드를 만듦                 EDM / 힙합       리듬을 강조하고 루프 효과를 추가                 앰비언트 사운드       깊고 지속적인 공간감 생성             🔬 작동 원리 (기초적인 알고리즘)  [Input Signal] → [Delay Buffer] → [Output]                               ↑                        (Feedback Loop)      소리가 Delay Buffer에 저장됨   정해진 시간이 지나면 출력으로 나감   Feedback이 있으면 그 출력이 다시 Delay Buffer로 들어가 재반복됨     🔊 딜레이 vs 리버브                 항목       딜레이       리버브                       지연 횟수       명확한 반복       수많은 잔향                 공간 표현       메아리, 반복       방 크기, 반사                 시간 간격       수십 ms ~ 수 초       보통 짧은 밀리초 단위 다수                 용도       리듬, 강조       공간감, 자연스러움             ✅ 요약     딜레이는 소리를 늦게 재생하여 반복, 에코, 리듬, 공간 효과를 만듦   다양한 음악 장르와 사운드 디자인에서 핵심적인 역할   딜레이 시간, 피드백, 믹스 값에 따라 느낌이 크게 달라짐   따라서 딜레이는 단순히 소리를 반복하는 것을 넘어 감정과 공간을 디자인하는 도구라고 할 수 있습니다.  "
  },
  
  {
    "title": "데시벨(db)이란?",
    "url": "/posts/Decibel/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-05 14:03:00 +0900",
    "content": "Decibel    🎧 1. dB란 무엇인가요?  ▸ “데시벨”은 소리의 크기를 표현하는 단위입니다.     원래 이름은 “벨(Bell)”이었고, 전화기의 발명자 알렉산더 그레이엄 벨의 이름에서 따왔습니다.   하지만 벨은 너무 큰 단위여서, 실제로는 **1/10 크기인 “데시벨(dB)”**을 사용합니다. → 즉, 1 벨 = 10 dB   ✅ 왜 소리를 숫자로 표현해야 하나요?     우리의 귀는 아주 작은 소리부터 굉장히 큰 소리까지 엄청나게 넓은 범위를 들을 수 있습니다.   그런데 이걸 그냥 1, 2, 3으로 표현하면, 너무 급격하게 늘어나거나 너무 작게 보여서 측정하기도, 비교하기도 불편합니다.     🔢 2. 왜 로그(log) 단위를 쓸까요?  ▸ 사람은 소리의 “비율”을 인식합니다.     예: ● 1에서 2로 커졌을 때 → “어, 좀 더 크네?” ● 10에서 20으로 커졌을 때 → “어, 또 좀 더 크네?” ▶ 우리는 2배 차이일 때 비슷한 느낌을 받습니다. → 이것이 로그 감각입니다.   ✅ 로그는 어떻게 적용되나요?     예: 소리의 에너지가 10배로 커지면 → +10 dB 에너지가 2배로 커지면 → +3 dB (정확히는 약 3.01 dB) 에너지가 절반이 되면 → -3 dB   🎯 즉, dB는 소리의 절대적인 크기보다, 변화의 ‘배율’을 표현하는 단위입니다.    📏 3. 상대값 vs 절대값 dB  ✅ dB (상대값)     기준이 없음, 단순히 얼마나 커졌는지/작아졌는지만 말합니다.   “이 소리, 6dB 더 키워줘” → 지금 상태보다 6dB만큼 증가시키라는 말.   실무에서 믹싱할 때 가장 많이 쓰는 표현입니다.   ✅ dBu, dBV, dB SPL, dBFS 등 (절대값)     기준이 있는 dB입니다. 즉, “얼마나”가 아니라 “몇 볼트인지, 몇 데시벨인지”를 정확히 수치로 표현한 것.                  단위       기준값       용도 예시                       dBu       0.775V RMS       프로용 오디오 장비                 dBV       1V RMS       가정용 오디오 장비                 dBm       1mW (600Ω 기준)       구형 전화/오디오 장비                 dB SPL       20μPa (마이크 기준 압력)       소리의 실제 크기 (데시벨 측정기)                 dBFS       디지털 최대값 (0dBFS = 클리핑)       디지털 오디오 믹싱/마스터링             🎛️ 4. VU 미터 vs 실제 전압  ▸ 0VU는 진짜 ‘0’이 아닙니다!     오디오 장비에는 흔히 VU 미터라는 눈금계가 있습니다.   이 눈금의 0점은 장비마다 기준이 다릅니다:                  장비 종류       0VU 기준       실제 단위       전압(V)                       프로용       +4dBu       약 1.23V       고급 장비 (스튜디오 등)                 아마추어용       -10dBV       약 0.316V       가정용 오디오, 캠코더 등           🎯 즉, 같은 0VU라고 해도, 어떤 장비에선 더 크고, 어떤 장비에선 더 작게 들릴 수 있습니다. 이게 인터페이스 매칭이 중요한 이유입니다.    💡 5. dB를 쉽게 이해하는 비유                 개념       설명                       dB (상대값)       “앞으로 3칸만 가!” → 지금 위치에서의 변화량                 dBu, dBV 등 (절대값)       “지금 너는 정확히 1.23V 위치야” → 정확한 수치 기준             ✅ 최종 요약     dB: 변화량 (상대 단위) → “지금보다 6dB 키워줘”   dBu, dBV: 정확한 기준이 있는 수치 → 장비 연결 시 중요   dB SPL: 환경 소음 등 실제 소리의 크기 측정 시 사용   dBFS: 디지털 오디오에서 소리 크기의 최댓값 기준 (0이 최고치, 더 크면 클리핑)   VU 미터: 장비에 따라 기준이 다르므로 주의 필요     수치 및 변환 예제  아래는 dBu, dBV, dBFS, dB SPL 등의 대표적인 dB 단위들의 수치 예제와 상호 변환 예제를 상세히 정리한 내용입니다. 수식도 함께 소개하겠습니다.    📐 1. dBu, dBV, dBFS, dB SPL 간단 요약                 단위       기준 값       의미       주로 쓰이는 분야                       dBu       0.775V (RMS)       전압 기준, 프로 오디오 장비용       믹서, 인터페이스 등                 dBV       1V (RMS)       전압 기준, 가정용/소비자 오디오용       CDP, 하이파이 등                 dBFS       디지털 최대값 (0dBFS)       디지털의 최대값 기준       DAW, 디지털 믹싱                 dB SPL       20μPa       소리의 압력 기준       마이크, 환경 소음계             🧮 2. dBu ↔ 전압 변환 예제  공식:     V (RMS) = 0.775 × 10^(dBu / 20)   dBu = 20 × log10(V / 0.775)                  dBu       전압 (V RMS)       비고                       0 dBu       0.775V       기준값                 +4 dBu       약 1.23V       프로 오디오 표준                 -10 dBu       약 0.245V       약한 신호 수준                 +10 dBu       약 2.45V       비교적 강한 신호             🧮 3. dBV ↔ 전압 변환 예제  공식:     V (RMS) = 10^(dBV / 20)   dBV = 20 × log10(V)                  dBV       전압 (V RMS)       비고                       0 dBV       1.00V       기준값                 -10 dBV       약 0.316V       컨슈머 오디오 표준                 +6 dBV       약 2.00V       강한 신호 수준             🔄 4. dBu ↔ dBV 변환 예제  공식:     dBV = dBu - 2.21   dBu = dBV + 2.21                  dBu       dBV       설명                       +4 dBu       +1.79 dBV       프로 오디오 기준 전환값                 0 dBu       -2.21 dBV                         -10 dBV       -7.79 dBu                     🧮 5. dBFS 예제 (디지털 오디오)     dBFS는 **디지털 오디오에서 최대치(클리핑 지점)**를 0으로 놓고 상대값을 계산합니다.   일반적으로 0 dBFS가 가장 큰 소리, 그보다 작으면 음량이 낮은 상태입니다.                  dBFS       의미                       0 dBFS       디지털 최대값 (클리핑 지점)                 -6 dBFS       최대값의 약 50%                 -12 dBFS       최대값의 약 25%                 -18 dBFS       일반적인 믹싱 기준 (헤드룸 확보)                 -60 dBFS       아주 약한 신호           🎯 dBFS는 절대값처럼 보이지만 디지털 장비 기준의 상대값이라고 이해하셔도 좋습니다.    🧮 6. dB SPL 예제 (음압)  공식:     dB SPL = 20 × log10(P / Pref) 여기서 Pref = 20μPa (2 × 10^-5 Pa) = 인간이 들을 수 있는 가장 작은 소리                  dB SPL       실생활 예시                       0 dB SPL       거의 무음 (사람이 간신히 들을 수 있는 소리)                 30 dB SPL       속삭임, 아주 조용한 방                 60 dB SPL       일반 대화                 85 dB SPL       도로 소음, 위험 경계선                 100 dB SPL       지하철, 시끄러운 음악                 120 dB SPL       귀가 아픈 소리, 통증 시작 지점             🔁 예제 변환 시나리오  🎧 예제 1: +4 dBu는 몇 dBV인가요?     dBV = dBu - 2.21 = 4 - 2.21 = 1.79 dBV     🎧 예제 2: 0.316V는 몇 dBu인가요?     dBu = 20 × log10(0.316 / 0.775)   계산하면 ≈ -10.2 dBu     🎧 예제 3: -6 dBFS는 dBu로 얼마일까요?     이건 디지털 장비가 아날로그로 변환되는 출력 단계에서만 의미가 있습니다.   예: 디지털 인터페이스의 기준 출력이 0 dBFS = +18 dBu라고 가정하면, → -6 dBFS는 약 +12 dBu에 해당합니다. (이는 장비 설정에 따라 다릅니다)     🧭 참고 팁     dBu, dBV는 전압 기반   dBm은 전력 기반 (잘 안 쓰임)   dBFS는 디지털 최대값 기준   dB SPL은 공기의 압력 기반     "
  },
  
  {
    "title": "AudioKit의 DynamicRangeCompressor",
    "url": "/posts/DynamicRangeCompressor/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-03 14:11:05 +0900",
    "content": "DynamicRangeCompressor  DynamicRangeCompressor는 오디오의 다이내믹 레인지(Dynamic Range), 즉 가장 조용한 소리와 가장 큰 소리 사이의 차이를 줄이는 데 사용되는 오디오 이펙트입니다. 이 컴프레서는 작은 소리는 상대적으로 키우고, 큰 소리는 줄여서 전체 소리를 더 일관되고 듣기 쉽게 만듭니다.    🎛️ 역할: DynamicRangeCompressor란?     소리가 너무 크면 자동으로 줄여주고, 너무 작으면 상대적으로 키워줌   방송, 팟캐스트, 보컬 믹싱, 마스터링 등 다양한 분야에서 사용   AudioKit의 DynamicRangeCompressor는 실시간으로 이 처리를 수행     ⚙️ 주요 파라미터 설명                 파라미터 이름       기본값       범위       의미                       ratio       1.0       0.01 ... 100.0       압축 비율 (압축 강도)                 threshold       0.0       -100.0 ... 0.0 dB       압축이 시작되는 기준 레벨                 attackDuration       0.1       0.0 ... 1.0 sec       소리가 커졌을 때 얼마나 빠르게 압축을 시작할지                 releaseDuration       0.1       0.0 ... 1.0 sec       소리가 다시 작아졌을 때 얼마나 천천히 압축을 풀지             🔍 파라미터 상세 설명  🧮 1. Ratio (비율)     압축 비율: 입력이 threshold를 넘었을 때 얼마나 줄일지   예: ratio = 4.0 → threshold보다 4dB 큰 입력이 들어오면 출력은 1dB만 증가 (4:1)            참고: 1(1:1)은 압축 없음, 100.0(∞:1)은 리미터처럼 작동           값이 클수록 압축이 강해짐                  Ratio       효과                       1.0       압축 없음                 2.0       부드러운 압축                 10.0 이상       리미터에 가까운 강한 압축             🎚 2. Threshold (임계값)     몇 dB 이상부터 압축을 적용할지 설정   예: threshold = -20.0 → 입력 레벨이 -20dB보다 크면 압축 시작   일반적으로 보컬: -12dB ~ -24dB 권장     ⚡️ 3. Attack Duration (공격 시간)     압축 시작까지의 시간 지연   짧으면 소리의 순간적인 피크도 줄이고, 길면 **어택(강조되는 처음 부분)**을 살림                  값       설명                       0.01~0.05초       매우 빠름 (피크 억제)                 0.1초 이상       느림 (자연스러움)             🌊 4. Release Duration (해제 시간)     입력이 threshold 아래로 떨어졌을 때, 압축을 완전히 해제하기까지의 시간   짧으면 빠르게 원래대로, 길면 부드러운 복원     🔊 사용 예시          보컬 다이내믹 정리:             threshold = -20, ratio = 3, attack = 0.05, release = 0.3                마스터링 전체 트랙:             threshold = -10, ratio = 1.5, attack = 0.1, release = 0.5             ✅ 요약                 파라미터       설명                       ratio       출력 레벨을 얼마나 압축할지                 threshold       압축을 시작할 기준 입력 레벨                 attackDuration       압축 시작까지의 시간                 releaseDuration       압축 해제까지 걸리는 시간           DynamicRangeCompressor는 음원의 불균형을 다듬고, 더 프로페셔널한 사운드를 만들어주는 핵심 도구입니다. AudioKit에서는 이 파라미터들을 실시간으로 조절하여 효과를 직관적으로 확인할 수 있습니다. "
  },
  
  {
    "title": "AudioKit의 LowPassCutoff",
    "url": "/posts/LowPassCutoff/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-02 14:36:36 +0900",
    "content": "Low Pass Cutoff  Low Pass Cutoff는 오디오 필터에서 **저역 통과 필터(Low-Pass Filter, LPF)**의 핵심 설정값입니다. 아래에서 LPF의 개념과 cutoff frequency가 실제로 어떤 영향을 주는지 자세히 설명드리겠습니다.    🎛 Low-Pass Filter (저역 통과 필터)란?     저주파수(낮은 소리)는 통과시키고, 고주파수(높은 소리)는 차단하는 필터      주로 소리를 부드럽게 만들거나, 고주파 잡음을 줄일 때 사용   Delay, Reverb, Distortion 등 다양한 효과에서 필터링 용도로 포함됨     🔧 Cutoff Frequency (컷오프 주파수)     “어디까지를 통과시키고, 그 이상부터는 감쇄시킬지”를 결정하는 경계점   예시:     cutoff = 15000Hz → 15kHz 이하의 소리는 그대로 통과, 15kHz 이상은 점점 약해지며 감소   감쇄는 점진적으로 일어남  → 흔히 -6dB/octave, -12dB/octave 등의 기울기(slope)를 가짐 즉, 컷오프를 지난 주파수는 갑자기 잘리는 게 아니라, 부드럽게 약해짐    📉 시각적 비유 (간단한 ASCII 그래프)  출력 레벨 100% |        _______      |       /      |      /      |     /      |    /      |   /    ← 점점 줄어드는 고주파수      |__/         ↑      컷오프 주파수     🔊 AudioKit의 Delay에서의 역할  AudioKit의 Delay 노드는 내부적으로 딜레이된 신호가 점점 줄어들며 반복되는데, 여기서 고주파 성분이 계속 남아 있으면 날카로운 잔향이 생깁니다.  따라서:     cutoff = 15000Hz → 대부분의 고역은 유지 (선명한 딜레이)   cutoff = 4000Hz → 고역을 많이 줄이고, 더 부드러운 느낌의 딜레이로 바뀜   cutoff = 1000Hz 이하 → 딜레이가 저음 위주로만 들림 (무겁고 둔탁함)     ✅ 요약                 용어       설명                       Low-Pass Filter       고주파를 줄이고 저주파는 통과시키는 필터                 Cutoff Frequency       고주파 차단이 시작되는 지점 (Hz)                 AudioKit 활용       딜레이 또는 리버브에서 잔향을 부드럽게 하거나, 고주파수를 줄이기 위해 사용             🎧 실용 팁:     보컬 딜레이 → cutoff ≈ 8000~12000Hz : 선명하면서 자연스러움   기타 앰비언트 → cutoff ≈ 4000~6000Hz : 부드럽고 깊이감 있음   베이스 → cutoff ≈ 1000Hz 이하 : 저음의 웅장함 유지   필요에 따라 cutoff frequency를 조절하여, 딜레이 톤을 “밝게” 혹은 “어둡게” 만드는 도구로 생각하시면 됩니다. "
  },
  
  {
    "title": "AudioKit의 Delay 및 DryWetMixer",
    "url": "/posts/Delay+DryWetMixer/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-02 14:32:57 +0900",
    "content": "Delay  DelayConductor 클래스는 오디오 입력을 받아 지연 효과(Delay)를 적용한 후, **원본 신호(dry)**와 **효과가 적용된 신호(wet)**를 DryWetMixer로 섞어서 출력하는 구조를 갖습니다. 아래는 코드와 함께 각 구성 요소 및 주석의 의미를 상세히 설명한 내용입니다.    🎛 클래스 역할 및 구조  DelayConductor는 다음을 수행합니다:     기본 오디오 소스(.strings)를 메모리에 로드하고   AudioPlayer로 재생   Delay 이펙트를 걸고   원본과 이펙트가 적용된 신호를 DryWetMixer로 섞어 출력     🧱 주요 구성 해설  🔹 delay = Delay(player)     지연 효과를 적용할 노드입니다.   원본 player로부터 오디오를 입력 받아서 처리합니다.   🔹 delay.feedback = 0.9     피드백(Feedback): 효과된 신호가 다시 입력으로 되돌아가 반복되는 비율입니다.   0.9이면 한 번의 딜레이로 끝나지 않고, 서서히 줄어드는 에코처럼 들림.   🔹 delay.time = 0.01     지연 시간 (단위: 초)   0.01초 → 빠르게 반복되는 딜레이 → 거의 플랜저(flanger)나 코러스 같은 효과로 들릴 수 있음.     🧪 delay.dryWetMix = 100의 의미  // 지연에 내장된 dry/wet 믹스를 사용하지 않습니다. // dry/wet 결과를 탭(tapping)하여 그래프로 표시하기 때문입니다. delay.dryWetMix = 100      기본적으로 Delay 노드에도 자체적인 Dry/Wet Mix가 있지만,        그래프 표시를 위해 효과된 신호만 분리해서 사용하고 싶을 경우, dryWetMix = 100으로 설정합니다.             즉, Delay 노드가 순수한 Wet 신호만 출력하도록 함           대신에 외부의 DryWetMixer로 dry/wet 비율을 통합 조절합니다.     🧩 dryWetMixer = DryWetMixer(player, delay)     💡 주석 해석: “두 개의 입력을 정확히 믹싱하는 것은 매우 흔한 일입니다. 하나는 처리 전, 다른 하나는 처리 후, 그 결과 두 입력이 결합된 결과가 생성됩니다.”      DryWetMixer는 player(dry 신호)와 delay(wet 신호)를 합칩니다.   이런 방식은 오디오 시각화(UI 그래프) 또는 커스텀 효과 체인 구성에 더 유연함을 줍니다.     📊 Delay 파라미터 정리                 파라미터       기본값       범위       설명                       Dry-Wet Mix       100.0       0.0~100.0       Delay 자체의 내부 믹스 → 이 코드에서는 사용 안함                 Delay Time       0.01초       0.0001~2.0       얼마나 지연되었는지, 0.01초는 매우 짧은 딜레이                 Feedback       0.9       -99.9~99.9       에코의 지속 시간에 영향, 0.9는 반복이 길고 강함                 Low Pass Cutoff       15000Hz       10~22050       딜레이 신호의 고역 제한 (고주파수 컷오프)             🧠 요약     DelayConductor는 원본 소리와 효과 적용된 소리를 DryWetMixer로 분리해서 다룸   내장 믹스를 사용하지 않고 외부에서 직접 믹싱 → 시각화나 제어에 유리   DryWetMixer는 특히 복잡한 효과 체인이나 직관적 제어 UI 구성에 적합함     이 방식은 향후 다른 이펙트 체인(예: 리버브 → 컴프레서 → 코러스 등)을 구성할 때도 효과적으로 확장 가능합니다. "
  },
  
  {
    "title": "AudioKit의 Convolution",
    "url": "/posts/Convolution/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-06-01 14:37:39 +0900",
    "content": "Convolution  이 코드는 AudioKit과 SoundpipeAudioKit을 사용해 컨볼루션 리버브(Convolution Reverb) 효과를 구현한 예제입니다. 특히, 두 개의 다른 임펄스 응답(Impulse Response) 파일을 혼합하여 사용자 지정 리버브 환경을 만드는 것이 핵심입니다.    🔊 핵심 개념 요약  🔹 Convolution     Convolution Reverb는 실제 공간에서 녹음된 ‘임펄스 응답(Impulse Response)’과 입력 오디오 신호를 **곱셈-합산 연산(convolution)**하여, **실제 공간의 리버브를 시뮬레이션합니다.   입력 오디오와 IR 파일을 합성(convolve)하여 현실적인 반향 효과를 구현합니다.     📌 간단 정리                 용어       설명                       Convolution       입력 신호와 임펄스 응답(IR)을 수학적으로 합성하여 실제 공간과 유사한 반향을 만드는 과정                 Impulse Response (IR)       특정 공간에서 “짧고 강한 소리”(예: 박수)를 녹음한 오디오 파일. 공간의 잔향 특성을 포함                 Ftable (Function Table)       AudioKit과 같은 DSP 환경에서 사용하는 신호 데이터 테이블, 예: 샘플/파형/IR 등을 담은 배열             🎛️ Convolution 클래스 정의  // This module will perform partitioned convolution on an input signal using an ftable as an impulse response.      input signal: 마이크, 음원 등의 오디오 신호   ftable: 임펄스 응답 데이터를 담고 있는 파형 테이블, 흔히 .wav 파일에서 변환됨   partitioned convolution: IR을 여러 작은 조각으로 나눠 계산해 CPU 부하를 줄이고 지연(latency)을 줄이는 방식     🔉 예시로 이해하기     당신이 플루트 소리를 건물 계단실에서 연주했다고 가정   실제 계단실에서 녹음된 IR (Impulse Response) 파일: stairwell.wav        AudioKit의 Convolution은:             입력된 플루트 소리를 stairwell.wav의 ftable과 합성해, 마치 그 계단실에서 직접 플루트를 연주한 것처럼 들리게 함             💡 왜 ftable을 쓰는가?     오디오를 실시간 처리하기 위해선 미리 처리된 IR 데이터를 배열(테이블)로 변환하는 게 효율적   이 테이블을 기반으로 빠르게 수학적 곱셈/합산 연산을 진행할 수 있음     🧱 구조 및 동작 흐름  1. 🔧 ConvolutionData  struct ConvolutionData {   var dryWetMix: AUValue = 0.5   var stairwellDishMix: AUValue = 0.5 }      dryWetMix: 원본 소리(player)와 리버브 처리된 소리(믹서 출력) 간 비율.   stairwellDishMix: 두 리버브 (stairwell, dish) 간 비율.     2. 🛠️ 임펄스 응답 파일 불러오기  let stairwellURL = ... let dishURL = ...           각각의 리버브 환경을 묘사하는 .wav 파일             stairwell.wav: 계단실과 같은 큰 공간 느낌       dish.wav: 금속성 또는 특이한 잔향 느낌             3. 🔄 Convolution 효과 구성  stairwellConvolution = Convolution(player, impulseResponseFileURL: stairwellURL, partitionLength: 8192) dishConvolution = Convolution(player, impulseResponseFileURL: dishURL, partitionLength: 8192)      partitionLength: 처리 블록 크기. 값이 작을수록 지연은 줄지만 CPU 사용률이 증가   두 개의 서로 다른 공간 리버브 효과 생성     4. 🔀 DryWetMixer 체인  stairwellDishMixer = DryWetMixer(stairwellConvolution, dishConvolution, balance: 0.5) dryWetMixer = DryWetMixer(player, stairwellDishMixer, balance: 0.5) engine.output = dryWetMixer      리버브 A와 B를 섞은 결과 → 원본과 또 섞음   최종 출력은 dryWetMixer        [Player]         │  ┌─────┴─────┐  ▼           ▼ Stairwell   Dish   │           │   └─────┬─────┘         ▼  stairwellDishMixer         │         ▼    dryWetMixer (← player)         │      [Engine Output]     7. 🧪 리버브 활성화  stairwellConvolution.start() dishConvolution.start()      AudioKit의 Node는 사용 전 .start() 필수     🧩 요약                 요소       설명                       player       오디오 재생용                 Convolution       IR 기반 리버브 처리                 stairwellDishMixer       두 리버브를 섞는 믹서                 dryWetMixer       원본과 리버브를 섞는 믹서                 data       두 믹서의 balance를 실시간 제어             📌 활용 예시     게임에서 공간 이동에 따른 잔향 효과   음악에서 마이크 녹음 시 실제 공간 질감 추가   Foley 사운드 제작    "
  },
  
  {
    "title": "AudioKit에서 AudioPlayer 재생 길이 문제",
    "url": "/posts/AudioPlayer%EC%9E%AC%EC%83%9D%EA%B8%B8%EC%9D%B4%EB%AC%B8%EC%A0%9C/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-31 16:02:15 +0900",
    "content": "AudioPlayer 재생 길이 문제  Q. 코드에서 음원 파일을 로딩해서 재생하는 기능이 있는데 재생 길이가 들쭉날쭉한데 (어쩔 떄는 전체 재생하는데, 어쩔 떄는 중간에 끊김) 해결방법은? A. Buffer 문제 가능성일 수 있음 ❌ Q.conductor.player.buffer 를 nil 로 하더라도 동일한 문제가 발생하는데 다른 곳에 문제는 없음?   맞는 답변  conductor.player.buffer = nil로 설정해도 문제가 동일하게 발생한다면, 문제는 버퍼 자체보다는 player.file과 player.buffer의 동시 사용 방식 또는 AVAudioEngine의 연결 구조에 있을 가능성이 높습니다. AudioPlayer는 buffer 또는 file 중 하나만 사용할 수 있으며, 둘을 동시에 설정하면 예기치 못한 동작(중간에 끊김 등)이 발생할 수 있습니다.    ✅ AudioKit AudioPlayer 동작 방식 요약                 설정된 값       동작 방식                       .file만 설정       스트리밍 재생 (긴 오디오에 적합)                 .buffer만 설정       메모리에 올려서 재생 (짧은 클립에 적합)                 둘 다 설정       ⚠️ 비권장 — 예기치 않은 문제 발생 가능             🔍 지금 코드의 의심 지점  conductor.player.file = try? AVAudioFile(forReading: url) conductor.player.isLooping = true conductor.player.buffer = buffer   위처럼 file과 buffer를 동시에 설정하면 충돌 가능성이 있습니다.  추가  Effects 코드의 오디오 플레이어 설정 방법  버퍼만 설정  buffer = Cookbook.sourceBuffer(source: defaultSource) player.buffer = buffer player.isLooping = true   기존 PlayersControl 코드  버퍼 + 오디오 파일 설정이 추가?  conductor.player.file = try? AVAudioFile(forReading: url) // &lt;- ?? conductor.player.isLooping = true conductor.player.buffer = buffer     ✅ 해결 방법  방법 1: **file을 지우고 buffer만 사용 ☑️  **  conductor.player.stop() conductor.player.file = nil // file은 사용하지 않음 conductor.player.buffer = buffer conductor.player.isLooping = true   방법 2: **file만 사용하고 buffer는 설정하지 않음 ❌ **  conductor.player.stop() conductor.player.buffer = nil // buffer는 사용하지 않음 conductor.player.file = try? AVAudioFile(forReading: url) conductor.player.isLooping = true   둘 중 하나만 사용하세요.    📌 추가 확인 사항     engine.output이 올바르게 연결되어 있는지 (AudioPlayer가 output chain에 포함되어야 함)   buffer.frameLength가 실제 음원 길이와 일치하는지 (짧게 잘려 있지 않은지)   .play() 이후에 isPlaying이 true인지 확인 (player.isPlaying 체크)     🧪 디버깅 팁  Log(\"buffer length:\", buffer.frameLength) Log(\"buffer duration:\", buffer.frameLength / buffer.format.sampleRate)   또는  Log(\"file duration:\", file.length / file.processingFormat.sampleRate)   을 통해 실제 재생되는 길이를 확인하세요.    ✅ 결론  buffer와 file은 동시에 쓰면 안 됩니다. 둘 중 하나만 설정해야 하고, 중간에 끊김 문제가 있다면 이중 설정을 제거하는 것부터 확인해야 합니다. "
  },
  
  {
    "title": "컴프레서(Compressor)란 무엇인가?",
    "url": "/posts/%EC%BB%B4%ED%94%84%EB%A0%88%EC%84%9C(Compressor)/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-31 15:19:22 +0900",
    "content": "컴프레서 (Compressor)  음향에서 **Compressor(컴프레서)**는 오디오 신호의 다이내믹 레인지(Dynamic Range) — 즉, 가장 작은 소리와 가장 큰 소리 사이의 음량 차이 — 를 줄이는 도구입니다.    ✅ “소리를 압축한다”는 의미  “압축”이란 말 그대로 소리의 볼륨 차이를 줄이는 것입니다. 즉, 너무 큰 소리는 줄이고, 작은 소리는 상대적으로 부각시켜서 전체적으로 보다 균형 잡힌 소리를 만듭니다.  예를 들어, 녹음된 보컬에서 어떤 단어는 너무 크고 어떤 단어는 너무 작게 들릴 수 있는데, 컴프레서는 이 차이를 줄여 일정한 볼륨감으로 만들어줍니다.    🎯 컴프레서를 사용하는 이유  1. 볼륨 균형 맞추기     마이크 앞에서 말하는 사람이 갑자기 크게 말하거나, 작게 말하면   컴프레서가 이를 감지해 큰 소리는 줄이고, 작은 소리는 상대적으로 부각 → 듣는 사람이 더 편안하게 들을 수 있게 합니다.   2. 사운드를 더 밀도 있게 만들기     다양한 악기의 음량 차이를 줄이면 믹스 전체가 더 탄탄하고 밀도 있게 들립니다.   특히 방송, 팟캐스트, 광고 등에서는 매우 중요   3. 음악적인 효과     특정 사운드에 컴프레서를 걸면 소리가 더 세게, 더 타이트하게 느껴짐   드럼이나 베이스에 컴프레서를 쓰면 퍼지는 느낌을 잡아주고, 명확한 어택감을 줌     📊 예시로 보는 작동 방식  예를 들어,     Threshold(문턱값)를 -20dB로 설정해 놓으면   입력되는 소리 중 -20dB보다 큰 신호만 컴프레서가 반응합니다.   그리고 그 큰 신호를 미리 정한 비율(Ratio)만큼 줄입니다.                  입력 레벨       출력 레벨 (예시)                       -10 dB (크다)       -15 dB (줄어듦)                 -30 dB (작다)       -30 dB (그대로)           결과적으로 **소리의 볼륨 차이(Dynamic Range)**가 줄어듭니다.    📍 어떤 상황에서 주로 사용?                 사용 대상       사용 목적                       보컬       단어별 음량 차이 정리                 드럼       피크 컨트롤, 명확한 어택                 기타       코드 연주 시 일관성 유지                 전체 믹스 (마스터링)       전체 곡의 일관된 출력 볼륨 확보             📌 마무리  컴프레서는 음악 제작, 음향 편집, 방송, 게임 사운드 디자인 등 거의 모든 오디오 작업에 필수적입니다. 적절히 사용하면 듣기 좋은, 깔끔한 소리를 만들 수 있고 과하게 사용하면 소리가 답답하거나 인위적이 될 수 있으니 주의가 필요합니다. "
  },
  
  {
    "title": "AudioKit의 Compressor",
    "url": "/posts/Compressor/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-31 15:18:54 +0900",
    "content": "Compressor  Compressor는 오디오의 다이내믹 레인지를 조절해주는 이펙트입니다. 즉, 소리를 일정하게 유지하고 지나치게 크거나 작은 소리를 조절해줍니다.  AudioKit의 Compressor는 다음 5개의 주요 파라미터를 가지고 있으며, 각각의 의미와 값의 범위, 그리고 값이 클수록/작을수록 어떤 효과가 있는지를 아래에 설명드립니다.    🎛 Compressor 파라미터 해설                 파라미터 이름       기본값       범위       설명                       Threshold       -20.0 dB       -100.0 … 20.0       이 값보다 큰 신호에만 컴프레션을 적용합니다. 값이 높을수록 작은 신호도 압축함.                 Head Room       5.0 dB       0.1 … 40.0       컴프레션이 적용되기 시작한 후 완전히 걸리기까지의 버퍼 구간. 값이 크면 부드럽고 자연스럽게, 작으면 급격히 압축됨                 Attack Time       0.001 sec       0.001 … 0.3       압축 시작까지 걸리는 시간. 값이 짧을수록 빠르게 반응, 길면 느리게 부드럽게 반응                 Release Time       0.05 sec       0.01 … 3.0       압축을 멈출 때까지의 시간. 작으면 빠르게 복원, 크면 잔향처럼 압축 유지                 Master Gain       0.0 dB       -40.0 … 40.0       전체 출력 볼륨 보정값. 압축 후 작아진 소리를 보정할 때 사용.             🔧 파라미터 변화 예시                 파라미터       작은 값       큰 값                       Threshold       큰 소리만 압축       작은 소리도 압축                 Head Room       압축이 갑자기 시작됨       부드럽게 압축됨                 Attack       순간적인 피크 억제       킥·스네어 같이 날카로운 소리 보존                 Release       빨리 압축 해제       잔향 유지처럼 천천히 압축 해제                 Master Gain       소리 작게 유지       출력 소리 증폭 가능             🎧 실전 적용 팁     보컬: 빠른 attack + 느린 release → 말의 앞부분 잡아주고 자연스럽게 이어짐   드럼: 낮은 threshold + 빠른 attack → 피크 컨트롤   전체 믹스: 중간 threshold + 느린 attack/release → 전체 소리 밀도 강화    "
  },
  
  {
    "title": "AudioKit의 Chorus",
    "url": "/posts/Chorus/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-30 14:18:44 +0900",
    "content": "Chorus  이 코드는 AudioKit과 DunneAudioKit을 이용해 Chorus 효과를 적용하는 오디오 재생기입니다.    🔶 DunneAudioKit이란?  DunneAudioKit은 AudioKit의 일부로, 특정 신시사이저와 고급 이펙트를 제공하는 확장 프레임워크입니다.     개발자: Paul Batchelor와 Shane Dunne   포함된 요소: Chorus, Flanger, Synths 등 일반 AudioKit에서는 제공하지 않는 특별한 DSP 효과 포함   내부적으로 C++ 기반 고성능 처리를 Swift에서 쉽게 사용할 수 있도록 래핑되어 있음      따라서 Chorus는 DunneAudioKit에서 제공하는 고급 이펙트입니다.     🔷 Chorus의 역할  **Chorus (코러스)**는 다음과 같은 효과를 만듭니다:     원본 신호에 약간 지연된 복제본을 추가해 겹치게 함   미세한 피치 변조(LFO)를 주어, 풍부하고 넓은 사운드를 생성   현악 합주단, 보컬 합창, 신시사이저 패드처럼 “두터운” 느낌 연출   🎧 쉽게 말하면:     마치 하나의 악기를 여러 명이 동시에 연주하는 듯한 소리가 납니다.     🎛️ Chorus 파라미터 설명                 파라미터 이름       기본값       범위       설명                       Frequency (Hz)       1.0       0.1…10.0       LFO(저주파 진동)의 속도. 피치 변화 주기. 클수록 불안정하고 떨림                 Depth (0~1)       0.25       0.0…1.0       피치 변조의 강도 (깊이). 클수록 흔들림 큼                 Feedback (0~1)       0.0       0.0…0.95       출력된 사운드를 다시 입력에 섞는 비율. 클수록 잔향 증가                 Dry/Wet Mix (0~1)       0.25       0.0…1.0       원본 신호(dry)와 효과 적용 신호(wet)의 혼합 비율           예시 변화     frequency = 5.0 → 더 빠르게 진동하여 불안정하고 떨리는 소리   depth = 0.8 → 진한 코러스 효과   feedback = 0.6 → 에코처럼 울림이 반복됨   dryWetMix = 0.0 → 이펙트 없음, 1.0 → 100% 코러스만 출력됨     🔧 전체 구조 요약     Piano 음원 불러옴   player에 버퍼 연결   Chorus 이펙트를 player에 적용   원본+이펙트를 DryWetMixer로 믹스        최종 출력을 engine.output에 설정      📝 정리     DunneAudioKit은 AudioKit의 고급 이펙트 확장   Chorus는 음원에 풍부함과 공간감을 주는 대표적 이펙트   파라미터를 조정하여 속도, 깊이, 울림, 적용 강도 등을 제어 가능   이 이펙트를 사용하면 신시사이저 패드나 스트링 사운드에 훨씬 깊은 생동감을 줄 수 있습니다. "
  },
  
  {
    "title": "AudioKit의 오실레이터(Oscillator)",
    "url": "/posts/%EC%98%A4%EC%8B%A4%EB%A0%88%EC%9D%B4%ED%84%B0(Oscillator)/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-29 13:08:10 +0900",
    "content": "오실레이터 (Oscillator)    오실레이터(oscillator)는 지속적인 주기적 파형을 생성하는 소리의 원천입니다. 디지털 오디오나 신시사이저에서 **기본적인 “소리 생성 장치”**라고 생각하시면 됩니다.    🎧 오실레이터란?          정의: 오실레이터는 사인파, 사각파, 톱니파 등과 같은 주기적인 파형을 생성하는 신호 발생기입니다.           역할: 디지털 음악에서 **주파수(frequency)**와 **진폭(amplitude)**를 설정하면, 해당 파형의 음을 지속적으로 만들어냅니다. → 즉, 음고(높이)와 볼륨을 결정하는 신호를 생성        🧪 예: 사인파 오실레이터  let osc = Oscillator() osc.frequency = 440  // A4 음 (라) osc.amplitude = 0.5 osc.start()      440Hz → 초당 440번 진동하는 사인파 → 우리가 듣기에 “라”로 인식되는 소리   **start()**를 호출하면 파형이 재생되기 시작함     📊 자주 사용하는 파형 종류                 파형       설명       소리 느낌 예시                       Sine wave       가장 부드러운 파형 (기본음)       튜닝 포크, 플루트                 Square wave       짧고 강한 진동 (홀수 배수 포함)       8비트 게임 사운드                 Sawtooth       치솟았다가 뚝 떨어지는 모양       브라스, 신시 리드음                 Triangle       부드럽지만 약간 날카로움       클라리넷 느낌             📌 요약                 항목       설명                       기능       음파 생성기                 제어 요소       frequency, amplitude, waveform 등                 사용 예시       신시사이저 기본 음, 튜너, 테스트 톤, 효과음 생성 등             🧠 즉, 오실레이터는 “음향의 첫 단추”로, 소리를 만드는 디지털 음의 씨앗입니다. 여기에 필터나 앰프, 모듈레이션 등을 적용해 최종 음색을 구성하게 됩니다. "
  },
  
  {
    "title": "AudioKit의 Balancer",
    "url": "/posts/Balancer/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-29 12:58:54 +0900",
    "content": "Balancer  이 코드는 AudioKit을 이용해 **재생 중인 오디오(피아노 소스)**와 지속적인 사인파(440Hz 등)를 비교하여 밸런스를 맞추는 오디오 신호처리 구조입니다. 아래에서 각 구성 요소와 오디오 흐름, 그리고 핵심 역할인 Balancer를 중심으로 설명드립니다.    📌 클래스 목적  BalancerConductor는 AudioKit의 Balancer 노드를 활용해 두 오디오 신호(오디오 플레이어와 사인파 오실레이터)를 비교하여 레벨 균형을 맞춘 후 DryWetMixer로 두 소리를 혼합합니다. 사용자 조작으로는:     사인파 주파수(frequency)   오디오 재생 속도(rate)   Dry/Wet 믹스 비율(balance)을 조절할 수 있습니다.     🔁 신호 흐름  [Audio File] --(VariSpeed)--&gt; [Fader] --&gt;┐                                          ├──[Balancer]──┐ [Oscillator] ---------------------------&gt;┘             │                                                         ├─[DryWetMixer]─▶ Output [Fader] ------------------------------------------------┘     🧩 구성 요소 설명                 구성 요소       설명                       AudioPlayer       피아노 샘플을 불러와 루프 재생                 Oscillator       440Hz 사인파 생성. frequency로 조절 가능                 VariSpeed       피아노 재생 속도 조절. rate로 설정                 Fader       VariSpeed의 출력을 볼륨 조절용으로 래핑                 Balancer       오실레이터의 출력을 기준으로 fader 출력을 레벨 밸런싱                 DryWetMixer       원본(fader)과 보정된(balancer) 출력을 블렌딩                 Engine.output       최종 믹싱된 결과를 출력             🎚️ @Published 변수                 변수       설명                       frequency       오실레이터의 주파수를 0.5초에 걸쳐 슬라이딩 조절 ramp(to: frequency, duration: 0.5)                 rate       VariSpeed를 통해 오디오 재생 속도 조절 (1.0이 원래 속도)                 balance       DryWetMixer의 블렌딩 비율 조절. 0 → 원본만 / 1 → 밸런서만             🎧 Balancer란?     Balancer(source, comparator)는 source의 레벨을 comparator에 맞춰 보정합니다.        이 경우:             source: 오실레이터 (톤 기준)       comparator: 피아노 파일 (재생된 사운드)           즉, 오실레이터 신호의 레벨이 피아노와 일치하도록 자동 조정됩니다.   이는 두 소스 간 일정한 레벨 밸런스를 유지할 때 유용합니다 (예: 모노소스 정렬, 분석 기준 맞춤 등).     🔍 실용적 의미     이 코드는 음향 비교, 레벨 정규화, 주파수 기반 음향 실험에 적합합니다.   특히 정현파(사인파) 기준으로 다른 소리의 볼륨을 맞추고 싶을 때, 이 구조가 적절합니다.   사용자는 실시간으로 주파수(frequency), 재생속도(rate), DryWet 비율(balance)를 변경해가며 음향 실험을 진행할 수 있습니다.     시각적 의미    🔊 기본 개념  Balancer는 다음 두 신호의 레벨 차이를 비교하고, source의 게인을 자동으로 조정합니다:     source: 조정 대상 (여기서는 osc = 사인파)   comparator: 기준 레벨 (여기서는 fader = 피아노 재생 소스)     📈 시각적 예시  예: osc는 일정한 레벨의 사인파, fader는 볼륨이 점점 커졌다 작아지는 피아노 소리라고 할 때:  Time → --&gt;  comparator (피아노 볼륨):  ░░░░░▒▒▒▒▒▓▓▓▓▓██████▓▓▓▓▓▒▒▒▒▒░░░░░      &lt;-- 커졌다가 줄어듦  source (원래 오실레이터 출력):  ██████████████████████████████████      &lt;-- 항상 일정  Balancer(source, comparator) 출력:  ░░░░░▒▒▒▒▒▓▓▓▓▓██████▓▓▓▓▓▒▒▒▒▒░░░░░      &lt;-- comparator에 맞춰 조정됨   즉, osc의 신호는 실제로는 그대로지만, Balancer가 comparator의 레벨을 추적하여 볼륨을 자동으로 매칭합니다.    🧠 응용 시나리오     기준 신호(예: 백그라운드 노이즈나 기준톤)에 맞춰 다른 소리를 정렬   두 채널 간 음압 차이를 줄일 때   실시간 신호 비교 및 교정   “참조 기준” 대비 신호 변화를 분석하고자 할 때     이해를 돕기 위한 간단한 다이어그램:     +---------+          +-----------+         +----------+    |  Osc    |──┐       |  Fader    |──┐      |          |    | (source)|  ├─────▶ |(comparator)| ├────▶ | Balancer |──▶ Output    +---------+  │       +-----------+  │      +----------+                 │                      │                 └──────────────────────┘     용어 설명    🎧 1. 모노 소스 정렬 (Mono Source Matching / Alignment)          의미: 하나의 모노 오디오 신호를 다른 신호의 음량 또는 에너지 레벨에 맞춰 조정하는 것           예시: 믹스 중에 보컬 신호(모노)를 기준으로, 사인파(모노 톤)를 같은 음압으로 들리도록 맞추고 싶을 때 사용           실제 활용:             사운드 테스트용 기준 톤을 맞출 때       비교 대상이 되는 음성/악기 신호에 맞춰 임의 신호(예: 톤)를 정렬할 때       머신러닝/오디오 분석에서 “기준 볼륨”에 맞춰 데이터 정규화할 때             🔬 2. 분석 기준 맞춤 (Comparator Level Matching / Normalization)          의미: 특정 신호(분석 대상)의 레벨을 기준 신호(분석 기준)에 맞추는 작업           즉, “A 소리”를 “B 기준 레벨”에 맞춰서 자동 조정함           예시:             사운드 A를 기준 사운드 B의 에너지 레벨에 맞춰 비교 가능하도록 볼륨을 자동 보정       실시간으로 들어오는 마이크 입력을, 기준 신호에 따라 자동 볼륨 조정       예: 노이즈 프로파일에 맞춰 마이크 신호를 억제하거나 강조             🧠 쉽게 비유하자면:     기준이 되는 “모델 소리”가 있고, 그 기준에 따라 “학생 소리”가 그에 맞춰 음량을 조정당한다고 보면 됩니다. Balancer는 이 “모델 소리”를 comparator로 사용하고, source 신호를 모델에 맞게 맞춰주는 역할을 합니다.    "
  },
  
  {
    "title": "AudioKit의 AutoPanner 및 Wah",
    "url": "/posts/AutoPanner,Wah/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-29 12:57:46 +0900",
    "content": "AutoPanner  AutoPanner는 오디오 신호의 위치를 자동으로 좌우로 이동(Panning) 시키는 효과(이펙트)입니다. 음악에서 흔히 말하는 “스테레오 공간에서의 움직임”을 만들 수 있게 해주는 도구로, 리듬감이나 공간감을 더해주는 데 유용합니다.    ## 🎛️ AutoPanner의 역할     입력된 오디오를 좌우 스피커로 시간에 따라 자동 이동시킴   예: 좌→우→좌→우 식으로 반복되면서 사운드가 흔들리거나 회전하는 듯한 공간감을 형성   흔히 Ambient, Electronic, Lo-Fi 음악에서 활용됨     ## 🧾 주요 파라미터 설명                 파라미터 이름       기본값       범위       설명                       frequency       10.0       0.0 ... 100.0       초당 몇 번 좌우 이동(pan) 할지를 의미하는 속도 (단위: Hz)값이 클수록 빠르게 움직임                 depth       1.0       0.0 ... 1.0       좌우 이동의 범위(강도)0은 전혀 이동하지 않고, 1.0은 완전히 왼쪽과 오른쪽으로 반복 이동             ## 📊 예시     frequency = 0.5, depth = 1.0 → 좌우로 천천히 크게 이동 (느린 스윙 느낌)   frequency = 10, depth = 0.3 → 빠르게 미세하게 이동 (가벼운 진동 느낌)   frequency = 0, depth = 1.0 → 움직이지 않음 (panning 비활성)     ## 🎧 시청각적 효과     🎵 좌우 스피커를 활용하여 청자에게 움직임을 주는 것   🧠 정적인 음원에 생동감 부여   🎚️ 다이내믹 믹싱 시 공간 분리 및 집중도 향상     즉, AutoPanner는 오디오에 ‘공간적 움직임’을 부여하는 간단하면서도 강력한 이펙트이며, frequency와 depth는 속도와 강도를 조절하는 핵심 요소입니다.    AutoWah  AutoWah는 기타 이펙트로 유명한 “와우(Wah)” 필터 효과를 자동화(Auto)한 오디오 효과입니다. 원래는 연주자가 페달로 조작하는 Wah 필터를 입력 신호의 강도에 따라 자동으로 작동하게 한 것이 AutoWah입니다.    ## 🎛️ AutoWah의 역할     “와우 와우” 소리 같은 음색 변화를 만들어냅니다.   **밴드패스 필터(bandpass filter)**의 중심 주파수를 입력 음의 세기(amplitude)에 따라 자동으로 움직이게 합니다.   즉, 세게 연주할수록 고음이 강조되고, 약하게 연주할수록 저음 중심으로 필터링됩니다.   기타, 베이스, 신스 등에서 많이 사용되며 펑키한 느낌, 말하는 듯한 소리를 연출할 때 유용합니다.     ## 🧾 파라미터 설명                 이름       기본값       범위       설명                       Wah Amount       0.0       0.0...1.0       Wah 필터의 효과 강도값이 클수록 필터 이동폭이 커져 더 극적인 wah 효과 발생                 Dry/Wet Mix       1.0       0.0...1.0       원본 소리와 Wah 효과가 적용된 소리의 혼합 비율1.0은 100% Wah만 출력, 0.5면 반반 믹스                 Overall level       0.1       0.0...1.0       최종 출력의 볼륨 조절 (전체 게인)Wah 효과로 음량이 낮아질 수 있으므로 보정용             ## 🎧 예시 활용   autoWah.$parameter1.ramp(to: 0.8, duration: 0.1) // Wah Amount  autoWah.$parameter2.ramp(to: 1.0, duration: 0.1) // Dry/Wet Mix  autoWah.$parameter3.ramp(to: 0.3, duration: 0.1) // Overall Level      Wah 효과를 강하게 주되, 볼륨은 보정해주는 설정     결론적으로, AutoWah는 연주의 강도에 따라 자동으로 음색이 변하는 반응형 필터 효과이며, 위 세 가지 파라미터를 통해 효과의 강도, 혼합도, 최종 볼륨을 유연하게 조절할 수 있습니다. "
  },
  
  {
    "title": "AudioKit의 피드백(Feedback)",
    "url": "/posts/%ED%94%BC%EB%93%9C%EB%B0%B1(Feedback)/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-27 20:41:58 +0900",
    "content": "Feedback    음향에서 피드백(feedback)은 출력된 소리의 일부를 다시 입력으로 되돌려서 재사용하는 것을 말합니다. 주로 딜레이(Delay), 리버브(Reverb) 등의 이펙트에서 사용되며, 반복되거나 잔향이 남는 소리를 만드는 데 쓰입니다.    🎧 예시로 설명          딜레이 이펙트가 있는 오디오에서:             원래 소리: “Hello”       피드백이 없을 때 → “Hello (딱 한 번 반복됨)”       피드백이 있을 때 → “Hello… hello… hello…” 점점 작아지며 반복됨             🎛 기술적인 설명     피드백 값이 0이면 한 번만 반향이 생기고 바로 사라짐   피드백 값이 1에 가까울수록 소리가 더 오랫동안, 더 많이 반복됨        예:             feedback = 0.3: “Hello” → echo 1~2번 들리고 끝남       feedback = 0.9: “Hello” → 수초간 반복됨             🎼 음악적 활용     앰비언트/패드 사운드에서 공간감을 주기 위해 사용   디지털 딜레이에서 텍스처를 풍부하게 만듦   라이브 퍼포먼스에서는 효과적인 사운드 디자인 도구     간단히 말해, “되돌아오는 소리”의 세기가 피드백입니다. "
  },
  
  {
    "title": "AudioKit의 STKEnsemble",
    "url": "/posts/STKEnsemble/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-27 20:41:58 +0900",
    "content": "STK Ensemble  https://github.com/user-attachments/assets/fcab9142-670f-4026-a257-19ec9dce263e  이 코드는 AudioKit, STKAudioKit, 그리고 SwiftUI를 활용하여 세 개의 가상 악기(Flute, Clarinet, Tubular Bells)를 조합한 **음악 합주 시스템(Ensemble Generator)**입니다. 주기적으로 음을 무작위로 선택하여 세 악기가 연주되며, 각 악기의 볼륨을 조절하고, 스케일(Scale)과 전조(Transpose)를 실시간으로 반영할 수 있습니다.    🔧 주요 구성 요소  🧩 STK 악기     Flute, Clarinet, TubularBells: STKAudioKit의 물리 기반 모델링 악기   trigger(note:velocity:): 지정한 MIDI 음과 벨로시티로 소리를 내는 메서드   stop(): 악기의 소리를 끈다   🔈 Fader     각 악기에 대한 볼륨 조절   fluteFader, clarinetFader, bellsFader는 각각 대응하는 악기를 감싼 Fader   .gain을 통해 실시간 볼륨 조절 가능   🎛 Mixer 및 AudioEngine     Mixer(fluteFader, clarinetFader, bellsFader)로 세 악기 음원을 혼합   engine.output = mixer를 통해 최종 출력 연결   🔁 CallbackLoop     loop = CallbackLoop(frequency:)는 지정된 주기(Hz)마다 클로저를 실행   loop.start() / loop.stop()으로 실행 제어   현재 playRate가 1.67이면 약 0.6초 간격으로 실행됨     🎶 음원 생성 로직  let scale = [60, 62, 64, 66, 67, 69, 71]      MIDI 노트 값으로 C Lydian 스케일   let transposedScale = [... down + base + up ...]      전조(transpose)를 반영하고,   원래 스케일의 뒷부분은 한 옥타브 아래, 앞부분은 한 옥타브 위로 보강하여 음역 확대   if random(0.45) { flute.trigger(...) }      악기마다 확률을 다르게 하여 음을 낼지 결정   무작위로 노트를 선택하고 trigger() 호출   벨로시티는 30~100 사이 무작위 (randomVelocity())     📌 상태 변수                 변수       설명                       playRate       loop 주파수 (Hz 단위, 루프 반복 속도)                 scale       현재 사용하는 스케일 (MIDI 음 배열)                 transpose       스케일 전조 값                 fluteGain       플루트 볼륨                 clarinetGain       클라리넷 볼륨                 bellsGain       벨 볼륨                 playingNotes       최근 연주된 노트 (악기별)             📝 주요 함수  random(_ probability: Double) -&gt; Bool     0~1 사이 확률로 true 반환 → 연주 유무를 확률적으로 결정하는 데 사용   randomVelocity(...)     벨로시티(세기)를 랜덤으로 생성 → 자연스러운 음색 변화   stopAllInstruments()     세 악기를 모두 멈춤 (음이 겹치거나 끊기지 않게 관리)     🎯 활용 예시  이 클래스를 SwiftUI에서 사용하면,     스케일 선택기, 트랜스포즈 슬라이더, 볼륨 조절 노브 등 UI를 통해 실시간으로 음원을 조작할 수 있음   예:  Slider(value: $conductor.fluteGain, in: 0...1) Picker(\"Scale\", selection: $conductor.scale) { ... }     ✅ 정리  STKEnsembleConductor는 오디오 합성을 위한 재생 루프, 확률 기반 음 선택, 실시간 볼륨 조절, 스케일 조작, STK 악기 연주를 모두 포함한 오디오 합주 클래스입니다. 음향적으로도, 무작위성과 악기 간의 주파수 분산이 혼합되어 자연스럽고 흥미로운 합주 효과를 만들어 냅니다. "
  },
  
  {
    "title": "AudioKit의 PluckedString",
    "url": "/posts/PluckedString/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-27 15:35:34 +0900",
    "content": "Plucked String  이 코드는 AudioKit과 SoundpipeAudioKit을 사용하여 플럭 현악기(plucked string) 소리를 자동 생성하고, 여기에 딜레이와 리버브 효과를 적용하는 구조입니다. 아래에 각 구성요소별로 자세히 설명드리겠습니다.    🔧 주요 구성 요소 설명  let pluckedString = PluckedString()     SoundpipeAudioKit의 PluckedString 노드입니다.   실제 기타, 하프 등 줄을 튕기는 소리의 물리적 모델링으로 소리를 생성합니다.   trigger()를 호출하면 소리가 발생합니다.   frequency: 재생될 음의 주파수   amplitude: 음의 크기   playRate = 3.0     초당 3번 루프가 반복됨을 의미합니다.   CallbackLoop(frequency:)에서 사용되어, 약 0.33초마다 트리거가 발생합니다.     🎼 init() – 노드 연결 및 효과 설정          DryWetMixer(pluckedString, pluckedString2)             두 플럭 사운드를 합칩니다.       dry/wet 구분 없이 두 음원을 섞는 믹서입니다.                Delay(mixer)             딜레이 효과 적용       delay.time = 1.5 / playRate → 약 0.5초 딜레이       delay.feedback = 0.9: 반복된 신호의 강도가 강함 (잔향 길어짐)                Reverb(delay)             전체 사운드에 리버브를 걸어 공간감을 추가       dryWetMix = 0.9: 대부분의 신호를 리버브 처리                engine.output = reverb             오디오 엔진 출력으로 설정             🔁 loop = CallbackLoop(frequency: playRate)     1초에 3번 반복하는 콜백 루프   콜백 안에서는 다음이 실행됩니다:   let scale = [60, 62, 64, 66, 67, 69, 71]      C 리디안 스케일입니다.        MIDI Note Number이며 각각 다음과 같습니다:             C4, D4, E4, F♯4, G4, A4, B4           let note1 = Int.random(...) let note2 = Int.random(...)      무작위로 두 음 선택 → 두 개의 pluckedString에 할당   if AUValue.random(...) &gt; 15 {   pluckedString.trigger()   pluckedString2.trigger() }      확률적으로 50%의 확률로 둘 다 트리거     ✅ @Published var isRunning     SwiftUI와 바인딩되어 있으며, 사용자가 ON/OFF 조작 시 loop.start() 또는 loop.stop()을 실행     🧠 요약                 구성 요소       설명                       PluckedString       줄을 튕기는 악기 사운드 생성                 CallbackLoop       일정 주기로 콜백 호출 (음 트리거용)                 Delay, Reverb       공간감 있는 음향 효과 적용                 isRunning       루프 시작/정지 상태           이 코드는 자동으로 리듬감 있게 연주되는 플럭 스트링을 만들며, 풍부한 잔향과 공간감을 주기 위해 딜레이와 리버브를 결합하여 앰비언트 음악이나 사운드 디자인에 적합한 사운드를 구성합니다. "
  },
  
  {
    "title": "AudioKit의 VocalTractOperation",
    "url": "/posts/VocalTractOperation/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-26 14:05:58 +0900",
    "content": "Vocal Tract Operation  이 코드는 AudioKit의 OperationGenerator를 사용해 인간의 음성을 물리적으로 모델링한 음향 합성기를 구성합니다. vocalTract는 **성도(목구멍~입)**의 구조를 모사한 음향 모델이며, 다양한 인자에 따라 음색이 변합니다. 아래는 주요 변수와 연산자의 역할을 중점적으로 설명합니다.    🔁 전체 구조  let generator = OperationGenerator { ... }      Swift 클로저 안에서 AudioKit Operation DSL을 사용해 신호 흐름을 정의합니다.   반환값은 Operation.vocalTract(...): 인간 음성을 시뮬레이션하는 메인 오퍼레이션     🔊 각 파라미터 설명  1. 성문 주파수 (Glottal Frequency)  let frequency = Operation.sineWave(frequency: 1)   .scale(minimum: 100, maximum: 300)      sineWave(frequency: 1) → 1Hz 속도로 천천히 진동   .scale(minimum: 100, maximum: 300) → 100~300Hz 범위로 변환   사람 목소리의 음 높이 범위에 해당하는 값   2. 지터 (Jitter)  let jitter = Operation.jitter(   amplitude: 300,   minimumFrequency: 1,   maximumFrequency: 3 ).scale()      지터: 음성의 미세한 주파수 흔들림 → 자연스러움/불안정성 부여   amplitude: 300 → 최대 300Hz 변화폭   .scale() → -1 ~ 1 사이의 랜덤값을 가진 사인파로 정규화됨   3. 혀 위치 (Tongue Position)  let position = Operation.sineWave(frequency: 0.1).scale()      아주 느리게(0.1Hz) 움직이는 사인파   .scale()은 기본적으로 -1 ~ 1로 스케일링됨   혀의 앞뒤 위치를 조정 → 모음 종류 변화   4. 혀 직경 (Tongue Diameter)  let diameter = Operation.sineWave(frequency: 0.2).scale()      혀의 높낮이 조절 → 음색 변화   5. 긴장도 (Tenseness)  let tenseness = Operation.sineWave(frequency: 0.3).scale()      성대의 긴장도 → 목소리의 강약, 날카로움, 부드러움에 영향   6. 비음도 (Nasality)  let nasality = Operation.sineWave(frequency: 0.35).scale()      비강(코)으로 얼마나 소리를 흘리는지를 나타냄 → 콧소리 비율 제어     🔚 최종 합성  return Operation.vocalTract(   frequency: frequency + jitter,   tonguePosition: position,   tongueDiameter: diameter,   tenseness: tenseness,   nasality: nasality )      vocalTract는 위 파라미터들을 이용해 목소리의 음높이, 모음형, 억양을 종합적으로 결정   frequency + jitter → 안정된 음 높이 + 지터를 통한 자연스러움 부여     💡 요약                 파라미터       역할       효과 예시                       frequency       기본 음 높이 (톤)       남성·여성 목소리 음역 차이 조정                 jitter       주파수 흔들림       더 자연스럽고 인간다운 발성 구현                 position       혀 위치 (전방/후방)       [i], [u], [a] 같은 모음 차이                 diameter       혀의 위아래 위치       열림 모음/닫힘 모음 구분 등                 tenseness       성대 긴장       부드럽거나 긴장된 발성                 nasality       비음도 (콧소리 성분)       영어 [n], [m], [ŋ] 같은 발음 구현           이 모델은 실제로도 Pink Trombone 알고리즘 기반이며, 사람의 음성 생성 메커니즘을 물리적으로 시뮬레이션합니다. "
  },
  
  {
    "title": "AudioKit의 VariableDelayOperation",
    "url": "/posts/VariableDelayOperation/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-25 14:27:09 +0900",
    "content": "Variable Delay Operaion  이 코드는 AudioKit을 기반으로 한 가변 딜레이 효과(variable delay effect) 를 구현하는 구조입니다. 입력된 오디오에 지속적으로 변하는 시간 및 피드백을 적용하여, 공간감 있고 유기적인 사운드를 만들어냅니다. 아래에서 전체 구조, 변수 역할, 각 수치가 의미하는 바를 상세히 설명드리겠습니다.    🧱 전체 구조 요약  class VariableDelayOperationConductor: ObservableObject, ProcessesPlayerInput      ObservableObject: SwiftUI에서 상태를 관찰하여 UI를 갱신 가능   ProcessesPlayerInput: 사운드 소스를 불러오고 재생하는 역할   핵심 요소: AudioPlayer, OperationEffect, DryWetMixer     🔁 오디오 체인 구조  AudioPlayer (\"Piano\" 샘플)        ↓ OperationEffect (VariableDelay)        ↓ DryWetMixer (dry / wet 믹스)        ↓ AudioEngine.output     🎛 주요 변수 설명  VariableDelayOperationData  이 구조체는 슬라이더 UI 등에서 조정 가능한 파라미터들을 저장합니다.                 변수명       설명       단위       기본값                       maxTime       최대 지연 시간, 시간 파형이 이 값 이하에서 변동       초 (s)       0.2                 frequency       딜레이 시간 변조에 사용되는 사인파의 주파수       Hz       0.3                 feedbackFrequency       피드백 양을 변조하는 사인파 주파수       Hz       0.21                 rampDuration       파라미터 값 변경 시 점진적으로 적용될 시간       초 (s)       0.1                 balance       dry/wet 믹스 비율 (0 = 원음만, 1 = 이펙트만)       0~1       0.5             🎚 OperationEffect 내 실제 처리  let time = Operation.sineWave(frequency: params.n(2))   .scale(minimum: 0.001, maximum: params.n(1))      params.n(1) = maxTime   params.n(2) = frequency   → 이 구문은 사인파 형태로 주기적으로 변하는 딜레이 시간(time) 을 만듭니다.     예) maxTime = 0.2, frequency = 0.3Hz → 3.3초에 한 번 주기가 도는 지연시간 파형   let feedback = Operation.sineWave(frequency: params.n(3))   .scale(minimum: 0.5, maximum: 0.9)      params.n(3) = feedbackFrequency   → 피드백 역시 사인파로 진동하며 변화 (잔향 길이가 계속 변함)  return player.variableDelay(   time: time,   feedback: feedback,   maximumDelayTime: 1.0 )      실제 적용되는 딜레이 함수.   maximumDelayTime은 시스템이 버퍼를 얼마나 잡을지 결정하는 상한값 (안전상 1.0초 설정)     🔁 DryWetMixer  dryWetMixer = DryWetMixer(player, delay)      원본 소리 (dry)와 이펙트가 적용된 소리 (wet)를 섞는 믹서   balance 값을 통해 비중 조절 가능 (0.5면 반반)     🔄 실시간 파라미터 반영  delay.$parameter1.ramp(to: data.maxTime, duration: data.rampDuration)      .ramp(to:, duration:)는 지정한 값으로 부드럽게 천천히 변화   클릭이나 슬라이더 조작 시 뚝뚝 끊기지 않고 자연스럽게 변화     📈 결과적으로 만들어지는 사운드 특징     딜레이 시간과 피드백 양이 계속 진동하므로, 소리가 흔들리듯 반사되고 잔향도 길이가 계속 변함   유기적인 공간감, 리드미컬한 배경음에 적합   재즈, 앰비언트, 전자음악에서 흔히 사용되는 형태     ✅ 요약                 요소       설명                       time       사인파로 진동하는 딜레이 시간 (0.001초 ~ maxTime)                 feedback       사인파로 진동하는 피드백 비율 (0.5 ~ 0.9)                 frequency       위 사인파들의 진동 속도 설정                 rampDuration       파라미터 변경 시 딱딱 끊기지 않고 부드럽게 적용                 balance       dry/wet 음을 섞는 비율                 전체 효과       공간이 계속 변화하는 듯한 모듈레이션 딜레이 효과            "
  },
  
  {
    "title": "AudioKit의 Stereo Operation",
    "url": "/posts/Stereo-Operation/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-24 15:34:51 +0900",
    "content": "Stereo Operation  이 코드는 스테레오 오디오 신호를 생성하고, 실시간으로 좌우 패닝(pan) 및 주파수 변경이 가능한 AudioKit 기반의 StereoOperationConductor 클래스입니다. 기존 코드에서 확장된 부분과 함께 전체적인 동작을 음향적 의미와 수치 단위까지 포함하여 설명드리겠습니다.    🧱 전체 구조  class StereoOperationConductor: ObservableObject, HasAudioEngine      ObservableObject → SwiftUI에서 @StateObject로 상태 추적 가능.   HasAudioEngine → AudioKit의 오디오 엔진을 직접 제어.     🔊 주요 구성요소  1. generator: OperationGenerator     스테레오 2채널 사운드를 생성함.   파라미터 params[0], params[1]을 통해 좌우 주파수를 외부에서 실시간 조정 가능.   let generator = OperationGenerator(channelCount: 2) { params in ... }     2. 비브라토(Vibrato)와 트레몰로(Tremolo)  slowSine (비브라토)  let slowSine = round(Operation.sineWave(frequency: 1) * 12) / 12 let vibrato = slowSine.scale(minimum: -1200, maximum: 1200)      1Hz 저주파 사인파를 12단계로 양자화 → 1옥타브(12세미톤) 단위의 스텝으로 변함.   -1200 ~ +1200 cent = -1옥타브 ~ +1옥타브 범위   frequency + vibrato → 사운드의 피치를 흔들리게 만듦 (비브라토 효과)   fastSine (트레몰로)  let fastSine = Operation.sineWave(frequency: 10) let volume = fastSine.scale(minimum: 0, maximum: 0.5)      10Hz 고주파 사인파 → 1초에 10번 볼륨이 흔들림.   0.0 ~ 0.5 범위의 진폭(amplitude) 변화를 통해 트레몰로 효과 (소리의 세기가 규칙적으로 변화)     3. 좌우 사운드 생성  let leftOutput = Operation.sineWave(   frequency: params[0] + vibrato,   amplitude: volume ) let rightOutput = Operation.sineWave(   frequency: params[1] + vibrato,   amplitude: volume )      params[0]: 좌측 시작 주파수 (leftStartFreq)   params[1]: 우측 시작 주파수 (rightStartFreq)   vibrato는 양쪽 모두에 동일하게 적용   결과적으로 좌/우 주파수 차이 + 진폭 변화 → 공간감 있는 스테레오 사운드 생성     4. 패닝(Panner)  private let panner: Panner      Panner(generator)를 통해 좌/우 사운드를 하나로 섞어서 출력할 때 위치 조절 가능.   pan 범위: -1.0 (완전 왼쪽) ~ 0.0 (중앙) ~ +1.0 (완전 오른쪽)   @Published var pan: AUValue = 0.0 {   didSet { panner.pan = pan } }     5. 초기 파라미터 설정  generator.parameter1 = leftStartFreq generator.parameter2 = rightStartFreq      앱 실행 시 기본 좌/우 주파수를 지정 (440Hz, 220Hz)     🧠 수치적 의미 요약                 요소       수치 범위       단위/역할                       slowSine       ±1 옥타브 (±1200)       센트 (pitch)                 fastSine       0.0 ~ 0.5       진폭 (volume)                 leftFreq       440 (A4)       Hz (좌 채널 시작음)                 rightFreq       220 (A3)       Hz (우 채널 시작음)                 pan       -1.0 ~ 1.0       좌/우 공간 위치             ✅ 요약     좌/우 채널의 주파수를 따로 조절 가능   비브라토, 트레몰로가 각 채널에 동일하게 적용되어 리듬감 있고 공간감 있는 사운드를 만듦   Panner로 전체 사운드의 좌우 위치 조절 가능   AudioKit을 활용한 인터랙티브 스테레오 사운드 디자인 구조로, 사운드 실험, 설치음악, 실시간 제어에 유용함    "
  },
  
  {
    "title": "AudioKit의 StereoDelayOperration",
    "url": "/posts/StereoDelayOperration/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-23 15:05:15 +0900",
    "content": "Stereo Delay Operation  이 코드는 AudioKit을 활용해 좌우 독립적인 스테레오 딜레이 이펙트를 적용하는 Swift 오디오 처리 예제입니다. 주요 구성요소와 음향 처리 흐름에 따라 설명드리겠습니다.    🧱 구조 요약  class StereoDelayOperationConductor: ObservableObject, ProcessesPlayerInput      ObservableObject: SwiftUI에서 상태 관리를 위해 사용됩니다.   ProcessesPlayerInput: 오디오 입력을 재생하고 이펙트를 거치는 공통 프로토콜입니다.     🎧 핵심 변수 설명  struct StereoDelayOperationData {   var leftTime: AUValue = 0.2   var leftFeedback: AUValue = 0.5   var rightTime: AUValue = 0.01   var rightFeedback: AUValue = 0.9 }      leftTime: 왼쪽 채널의 딜레이 시간 (초 단위)   leftFeedback: 왼쪽 딜레이 반복 강도 (0~1 사이)   rightTime, rightFeedback: 오른쪽 채널도 동일   딜레이 효과는 시간 차를 두고 소리를 반복 재생하는 효과이며, feedback 값이 클수록 반복이 더 오래 이어집니다.    🧠 처리 흐름  1. 오디오 재생 버퍼 초기화  buffer = Cookbook.sourceBuffer(source: \"Female Voice\") player.buffer = buffer player.isLooping = true      \"Female Voice\" 샘플을 메모리에 불러오고 무한 반복 설정     2. OperationEffect 생성 (채널 수: 2)  effect = OperationEffect(player, channelCount: 2) { _, params in      channelCount: 2로 지정되어, 좌우 채널을 독립적으로 처리할 수 있습니다.   클로저 내에서 params는 1~4번까지 할당된 딜레이 파라미터들을 받아 사용합니다.     3. 좌우 채널 독립 딜레이 적용  let leftDelay = Operation.leftInput.variableDelay(   time: params.n(1),   feedback: params.n(2) ) let rightDelay = Operation.rightInput.variableDelay(   time: params.n(3),   feedback: params.n(4) )      .leftInput, .rightInput: 각 채널의 입력 소리   .variableDelay(...): 시간과 반복 강도를 설정한 딜레이 효과를 생성   이렇게 하면 왼쪽 채널은 예: 0.2초 딜레이 + 중간 정도의 반복, 오른쪽 채널은 0.01초 짧은 딜레이 + 높은 반복 같은 식으로 완전히 다르게 설정 가능합니다.    4. 딜레이 출력 결합  return [leftDelay, rightDelay]   좌우 두 채널의 출력 배열을 반환해 스테레오 출력으로 구성됩니다.    5. AudioEngine 출력 설정  engine.output = effect      player → effect → engine.output으로 연결되어 재생과 이펙트가 함께 처리됩니다.     6. 슬라이더 등 외부에서 값 변경 대응  @Published var data = StereoDelayOperationData() {   didSet {     effect.parameter1 = data.leftTime     effect.parameter2 = data.leftFeedback     effect.parameter3 = data.rightTime     effect.parameter4 = data.rightFeedback   } }      SwiftUI 슬라이더 등에서 data 값을 바꾸면 자동으로 딜레이 파라미터가 반영됩니다.     🎵 음향적 특징     좌우 딜레이가 다르면 공간감과 스테레오 이미지가 크게 확장됩니다.   한쪽에 긴 피드백을 주고 한쪽은 짧게 주면, 잔향이 치우치거나 퍼지는 효과를 줍니다.   보컬, 신스 패드 등에 잘 어울리는 풍성한 딜레이 느낌을 연출할 수 있습니다.     ✅ 요약표                 구성 요소       역할                       AudioPlayer       오디오 재생                 OperationEffect       좌우 독립 딜레이 처리                 data       딜레이 파라미터를 묶은 구조체                 params.n()       딜레이 인자 접근용                 engine.output       전체 오디오 출력 연결            "
  },
  
  {
    "title": "AudioKit의 SmoothDelayOperation",
    "url": "/posts/SmoothDelayOperation/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-22 13:33:25 +0900",
    "content": "Smooth Delay Operation  이 코드는 AudioKit과 SwiftUI를 이용하여 Smooth Delay 이펙트를 적용한 오디오 플레이어를 구현한 것입니다. 각 구성 요소가 어떻게 작동하는지 음향 처리 흐름 중심으로 자세히 설명드리겠습니다.    🔧 구조 요약  class SmoothDelayOperationConductor: ObservableObject, ProcessesPlayerInput      ObservableObject: SwiftUI에서 상태 변경을 감지할 수 있도록 함.   ProcessesPlayerInput: AudioPlayer를 기반으로 이펙트를 처리한다는 의미의 커스텀 프로토콜.     📦 SmoothDelayOperationData  struct SmoothDelayOperationData {   var time: AUValue = 0.1         // 딜레이 시간 (초)   var feedback: AUValue = 0.7     // 피드백 양 (0.0 ~ 1.0)   var rampDuration: AUValue = 0.1 // 파라미터 변화 시 부드럽게 변화하는 시간 }      사용자가 UI에서 조절할 수 있는 딜레이 관련 매개변수를 하나의 구조체로 관리합니다.     🔊 @Published var data  @Published var data = SmoothDelayOperationData() {   didSet {     effect.$parameter1.ramp(to: data.time, duration: data.rampDuration)     effect.$parameter2.ramp(to: data.feedback, duration: data.rampDuration)   } }      data가 변경되면 파라미터 1, 2를 부드럽게 변화(ramp) 시켜 딜레이 이펙트에 반영합니다.   ramp()는 값이 즉시 튀지 않고 자연스럽게 변화하도록 함.     🛠 init()  buffer = Cookbook.sourceBuffer(source: \"Piano\") player.buffer = buffer player.isLooping = true      \"Piano\" 샘플 파일을 로드하여 버퍼에 저장하고 AudioPlayer에 할당   루프 재생 설정     🔄 OperationEffect 정의  effect = OperationEffect(player) { player, params in   let delayedPlayer = player.smoothDelay(     time: params[0],     feedback: params[1],     samples: 1024,     maximumDelayTime: 2.0   )      return mixer(player.toMono(), delayedPlayer) }   🔍 player.smoothDelay(...) 설명     time: 딜레이 타임 (param[0]) — 얼마나 늦게 소리가 반복될지   feedback: 반복되는 소리가 얼마나 강하게 들릴지 (param[1])   samples: 내부 계산용 샘플 수 (1024개 샘플 단위로 버퍼 처리)   maximumDelayTime: 최대로 허용되는 딜레이 시간 (2초)   🎛 mixer(...) 의미     player.toMono(): 원본 dry 신호   delayedPlayer: 이펙트가 적용된 wet 신호 ➡️ 두 신호를 믹싱하여 출력합니다.     🔚 최종 연결  engine.output = effect      AudioKit 오디오 엔진의 출력은 이 effect 노드로 설정됩니다.     📊 요약                 구성 요소       역할                       AudioPlayer       소스 오디오를 재생 (루프됨)                 OperationEffect       AudioKit의 이펙트 노드로, Smooth Delay 연산을 수행                 parameter1, parameter2       각각 딜레이 시간과 피드백 비율 제어                 ramp(to:duration:)       값이 부드럽게 전환되도록 처리                 engine.output = effect       엔진 출력으로 연결하여 실제 사운드 출력 가능             📣 음향적 특징     smoothDelay: 오디오 버퍼를 내부적으로 샘플 단위로 처리하여 좀 더 부드러운 반향을 생성   feedback: 반복되는 에코 효과, 값이 높을수록 리버브처럼 들림   딜레이 + 피드백을 이용한 리듬감, 공간감 생성에 유용   이 코드는 실시간으로 딜레이 파라미터를 조작할 수 있도록 구성되어 있어 인터랙티브한 사운드 디자인에도 적합합니다. "
  },
  
  {
    "title": "AudioKit의 SegmentOperation",
    "url": "/posts/SegmentOperation/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-21 15:36:12 +0900",
    "content": "Segment Operation  이 코드는 AudioKit, SporthAudioKit을 기반으로 음향 합성을 수행하는 Swift 클래스 SegmentOperationConductor입니다. 특히 **라인 세그먼트(line segment)**와 **지수 세그먼트(exponential segment)**를 활용한 시간 변화 기반의 음향 합성을 구현한 예제입니다.    💡 전체 개요  SegmentOperationConductor는 시간에 따라 변화하는 주파수와 진폭을 가지는 사인파를 생성하고, 딜레이와 리버브 이펙트를 적용한 사운드를 출력합니다.    🔧 주요 구성 요소 설명  let generator = OperationGenerator { params in   OperationGenerator는 오디오 신호 그래프를 생성하는 핵심이며, Sporth DSL을 Swift 문법으로 만든 구조입니다. params는 외부에서 제어 가능한 파라미터를 전달받습니다.  🎚 params[0] = updateRate  let updateRate = params[0]      이 값은 metronome 트리거의 빈도를 조절합니다.   이 트리거는 특정 시간 간격마다 아래 라인 세그먼트, 지수 세그먼트를 **재시작(트리거)**하게 만듭니다.     🌀 라인 세그먼트 (lineSegment)  let start = Operation.randomNumberPulse() * 2000 + 300 let duration = Operation.randomNumberPulse() let frequency = Operation.lineSegment(   trigger: Operation.metronome(frequency: updateRate),   start: start,   end: 0,   duration: duration )   Operation.randomNumberPulse()    0.0부터 1.0 사이의 난수(random number) 를 일정 주기마다 출력합니다.   기본적으로 초당 10번 (10Hz) 갱신되며, 설정하지 않으면 default입니다.   샘플 홀드형 노이즈와 비슷하게 일정 주기마다 값이 바뀝니다.   ✔ Operation.lineSegment(...)의 뜻     “선형 구간(line segment)”: 선형적으로 값이 변하는 함수입니다. → 마치 그래프에서 직선으로 이어진 구간처럼 시작 값에서 끝 값까지 일정 시간에 걸쳐 선형으로 변화합니다.   이 코드에서는?     랜덤한 주파수(start)에서 0Hz까지 천천히 내려감   이 과정은 duration (지속시간)에 따라 변화   metronome이 트리거되어 주기적으로 반복됨   결과     소리의 피치가 매번 다르게 시작해서 서서히 내려가고 끊어짐.     📉 지수 세그먼트 (exponentialSegment)  let amplitude = Operation.exponentialSegment(   trigger: Operation.metronome(frequency: updateRate),   start: 0.3,   end: 0.01,   duration: 1.0 )      “지수 구간(exponential segment)”: 시작값에서 끝값으로 지수적으로 감소합니다.   이 경우엔 볼륨(진폭)이 0.3에서 0.01로 매우 빠르게 줄어듭니다.   trigger에 의해 주기적으로 재시작     🎛 오실레이터 생성  return Operation.sineWave(frequency: frequency, amplitude: amplitude)      위에서 정의한 시간에 따라 감소하는 주파수와 진폭을 가진 사인파를 생성합니다.     🎧 효과 추가  let delay = Delay(generator) delay.time = 0.125 delay.feedback = 0.8      125ms의 딜레이를 넣고, 80% 피드백으로 에코처럼 반복되는 소리를 생성   let reverb = Reverb(delay) reverb.loadFactoryPreset(.largeHall)      리버브는 큰 홀(hall) 프리셋을 사용해서 소리를 공간감 있고 울리게 만듭니다.   engine.output = reverb      최종 출력은 리버브된 사운드입니다.     🔁 실행 제어  @Published var isRunning = false {   didSet {     isRunning ? generator.start() : generator.stop()   } }      SwiftUI에서 isRunning 값을 바꾸면 generator의 재생/정지가 동기화됩니다.     ✅ 요약                 요소       역할                       lineSegment       주파수를 점차 줄이게 하는 선형 구간 함수                 exponentialSegment       진폭(볼륨)을 빠르게 줄이게 하는 지수 함수                 metronome       위 두 세그먼트를 주기적으로 트리거함                 sineWave       실제 음을 발생시킴                 Delay       잔향처럼 소리 반복                 Reverb       공간감 있게 소리를 울림             🧠 비유로 이해하면     lineSegment = “산에서 썰매 타기”: 높이에서 출발 → 밑으로 서서히 내려옴 (Pitch 낮아짐)   exponentialSegment = “불 꺼지기”: 처음은 밝다가 점점 어두워짐 (볼륨 급속히 줄어듦)    "
  },
  
  {
    "title": "AudioKit의 PitchShiftOperation",
    "url": "/posts/PitchShiftOperation/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-20 15:25:23 +0900",
    "content": "Pitch Shift Operator  이 코드는 AudioKit 프레임워크를 활용해, 하나의 오디오 음원에 피치 쉬프팅(Pitch Shifting) 이펙트를 주고, 원본과 이펙트 신호를 믹싱하여 출력하는 과정을 다룹니다. 주요 클래스는 PitchShiftOperationConductor입니다.    📦 전체 구성 흐름 요약  AVAudioBuffer (음원)    ↓ AudioPlayer (루프 재생)    ↓───────┐            └─────▶ OperationEffect (피치 쉬프팅 처리)                         ↓               DryWetMixer (원본/이펙트 믹스)                         ↓                   AudioEngine.output     ✅ 1. PitchShiftOperationData 구조체  struct PitchShiftOperationData {   var baseShift: AUValue = 0   var range: AUValue = 7   var speed: AUValue = 3   var rampDuration: AUValue = 0.1   var balance: AUValue = 0.5 }                  항목       설명                       baseShift       기본 피치 시프트 양 (세미톤 단위, 예: +12는 한 옥타브 위)                 range       진동의 범위 (진폭) — sin 곡선의 위아래 피치 이동 폭                 speed       피치를 흔드는 속도 — 초당 몇 번 흔들릴지 (주파수)                 rampDuration       파라미터 값이 바뀔 때 얼마나 부드럽게 변화할지                 balance       Dry/Wet 믹스 비율. 0 = 원본만, 1 = 이펙트만, 0.5 = 절반 믹스              📝 ramp: 오디오에서는 어떤 값을 “서서히” 바꾸는 것을 의미. 예: 갑자기 바꾸면 튀므로 0.1초 동안 점진적으로 바꿈.     ✅ 2. PitchShiftOperationConductor 클래스  주요 객체  let engine = AudioEngine() // 전체 오디오 처리 엔진 let player = AudioPlayer() // 버퍼 재생기 let pitchShift: OperationEffect // 피치 쉬프팅 이펙트 let dryWetMixer: DryWetMixer // 원본과 이펙트를 믹싱 let buffer: AVAudioPCMBuffer // 오디오 데이터를 담고 있음     🔷 버퍼 및 플레이어 설정  buffer = Cookbook.sourceBuffer(source: \"Piano\") player.buffer = buffer player.isLooping = true      \"Piano\"라는 이름의 오디오 파일을 로딩하고,   무한 반복으로 재생 설정     🔷 OperationEffect로 피치 쉬프팅 정의  pitchShift = OperationEffect(player) { player, params in   let sinusoid = Operation.sineWave(frequency: params[r(3)])   let shift = params[r(1)] + sinusoid * params[r(2)] / 2.0   return player.pitchShift(semitones: shift) }   설명                 코드       설명                       params[r(1)]       baseShift                 params[r(2)]       range                 params[r(3)]       speed                 Operation.sineWave(...)       주어진 주파수로 사인파 생성 (피치를 위아래로 흔드는 기반 신호)                 shift = base + sine * range / 2       사인 곡선의 값이 -1 ~ 1 사이이므로 range/2를 곱해 전체 범위 조절                 player.pitchShift(semitones: shift)       최종적으로 실시간으로 피치를 흔듦             🔷 초기 파라미터 값 설정  pitchShift.parameter1 = 0    // baseShift pitchShift.parameter2 = 7    // range pitchShift.parameter3 = 3    // speed     🔷 Dry/Wet Mixer 설정  dryWetMixer = DryWetMixer(player, pitchShift) engine.output = dryWetMixer      원본 player와 이펙트가 적용된 pitchShift의 신호를 믹싱함   balance 값에 따라 둘 중 어떤 비율로 출력할지를 조절     🔷 외부에서 슬라이더 등으로 조절할 수 있게  @Published var data = PitchShiftOperationData() {   didSet {     pitchShift.$parameter1.ramp(to: data.baseShift, duration: data.rampDuration)     pitchShift.$parameter2.ramp(to: data.range, duration: data.rampDuration)     pitchShift.$parameter3.ramp(to: data.speed, duration: data.rampDuration)     dryWetMixer.balance = data.balance   } }      SwiftUI에서 data가 바뀔 때마다 이펙트 파라미터를 실시간 업데이트   ramp(to:duration:)로 값을 부드럽게 전환     🎧 사운드 처리 흐름 (음향적으로)     AudioPlayer가 원본 음원을 재생        OperationEffect가 사인파 기반의 시간 변화에 따라 피치를 위아래로 진동시킴             결과적으로 비브라토(vibrato) 같은 효과가 생성됨           DryWetMixer가 원본과 이펙트 음을 섞음   최종적으로 AudioEngine에서 소리를 출력     ✅ 요약                 요소       역할                       AudioPlayer       원본 오디오를 재생                 OperationEffect       피치를 흔드는 이펙트를 실시간 적용                 DryWetMixer       원본 + 이펙트 비율을 믹싱                 @Published var data       SwiftUI와 연동되는 이펙트 조절 슬라이더                 ramp(...)       매끄러운 값 변화 제공           이 코드는 AudioKit을 활용한 모듈식 사운드 디자인의 전형적인 예시로, 사용자가 실시간으로 피치 변화 속도, 범위 등을 조절할 수 있어 창의적 음향 실험에 매우 적합합니다. "
  },
  
  {
    "title": "AudioKit의 PhasorOperation",
    "url": "/posts/PhasorOperation/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-19 15:11:17 +0900",
    "content": "Phasor Operation  이 generator는 AudioKit의 OperationGenerator를 이용한 절차적 사운드 생성 예시입니다. 이 코드는 랜덤한 피치의 음을 천천히 변화시키며 재생하고, 여기에 **고전적인 리버브 효과(Chowning Reverb)**를 입혀 깊이감 있고 예측 불가능한 앰비언트 사운드를 만듭니다.  아래는 음향 생성 과정 중심으로 단계별 설명입니다.    ✅ 전체 개요     목표: 시간에 따라 변화하는 임의의 MIDI 음을 재생하고, 이를 Chowning Reverb로 공간감을 추가하여 믹싱     🔁 1단계: 시간 기반 위치 생성  let phasing = Operation.phasor(frequency: 0.5)      phasor: 0에서 1까지 선형 증가하는 파형 (Sawtooth)   frequency: 0.5Hz → 2초에 한 번 주기   사운드 생성 흐름에서 시간 기반 인덱스 역할을 함 (0.0 ~ 1.0 사이의 값을 시간에 따라 순차적으로 제공)     🎲 2단계: 난수 기반 속도 가변화  * Operation.randomNumberPulse(     minimum: 0.9,     maximum: 2,     updateFrequency: 0.5   )      phasor 값에 랜덤한 스케일링을 적용하여 음이 얼마나 빠르게 변할지를 조절   updateFrequency: 0.5Hz → 2초마다 한 번 새로운 랜덤 값 생성   결과적으로 phasor의 속도가 매번 조금씩 변동되어 불규칙한 음의 변화 타이밍을 유도     🎵 3단계: MIDI 음 → 실제 주파수로 변환  let frequency = (floor(phasing * noteCount) * interval + startingNote)   .midiNoteToFrequency()      phasing * noteCount → 0 ~ 24 사이의 float 값   floor(...) → 정수화 → 0 ~ 23 정수        * interval + startingNote → MIDI 음으로 변환 (startingNote: 48 = C3)             예: 0 → 48, 1 → 50, … (2 간격)           .midiNoteToFrequency() → MIDI 음을 Hz 주파수로 변환   👉 최종적으로 시간에 따라 랜덤한 MIDI 음이 천천히 순차적으로 선택됨    🔊 4단계: 오실레이터 생성  var amplitude = (phasing - 1).portamento()      phasing - 1 → 0에서 1로 갈수록 -1 → 0 값이 생성됨 (초기값은 음소거)   .portamento() → 부드럽게 변화시켜 클릭 소리 방지   var oscillator = Operation.sineWave(   frequency: frequency,   amplitude: amplitude )      위에서 만든 frequency와 amplitude를 이용해 사인파 음 생성   매 2초마다 임의의 음이 사인파로 출력됨     🌫 5단계: 리버브 추가 – Chowning Reverb  let reverb = oscillator.reverberateWithChowning()           reverberateWithChowning():             John Chowning의 고전적인 리버브 모델       3개의 Allpass Filter, 4개의 Comb Filter, 2개의 Decorrelated Delay Line을 사용       실제 음향 공간의 반사 특성을 모델링       디지털 방식으로 구현된 풍부하고 깊은 잔향             🎚 6단계: 믹싱  return mixer(oscillator, reverb, balance: 0.6)      dry (oscillator) : wet (reverb) = 4 : 6 비율로 믹싱   리버브가 중심이지만, 원음도 어느 정도 들리는 자연스러운 공간감 제공     📊 음향적 특성 요약                 구성 요소       설명                       phasor + random pulse       불규칙한 속도의 시간 흐름 생성                 floor(phasing * noteCount)       MIDI 음 높이 결정                 sineWave       기본 사운드 생성기 (부드러운 톤)                 portamento()       클릭 방지용 부드러운 볼륨 변화                 Chowning Reverb       깊이감 있는 공간 효과                 mixer       dry/wet 비율 조절로 톤의 중심성 제어             ✅ 요약  이 코드는:     불규칙하게 변화하는 음정을 가진 사인파를   클릭 소리 없이 자연스럽게 생성하고   빈티지하면서 깊은 리버브를 입혀   앰비언트 사운드, 백그라운드 음악, 설치음향 등에 적합한 결과물을 만들어냅니다.     속도 조절  속도를 느리게 하려면 음이 바뀌는 속도를 느리게 조절해야 하며, 이 경우 아래 두 가지 중 핵심은 phasor의 frequency 조절입니다.    ✅ 1. phasor(frequency:) 값을 낮추기 → 가장 직접적인 방법  let phasing = Operation.phasor(frequency: 0.5)      0.5Hz → 2초에 한 번 cycle이 돎 → 즉, 2초에 한 번 음이 바뀜   0.25Hz로 줄이면 4초에 한 번 음이 바뀌어 더 느려짐   ✅ 예시:  let phasing = Operation.phasor(frequency: 0.25) // 4초 주기     🔄 2. randomNumberPulse(updateFrequency:)는 변화량 랜덤 주기에만 영향을 줌  Operation.randomNumberPulse(minimum: 0.9, maximum: 2, updateFrequency: 0.5)      updateFrequency는 무작위 스케일값이 얼마나 자주 바뀔지를 정함   이것만 줄이면 “속도 자체”보다는 변화의 무작위성 주기가 느려질 뿐임   즉, 실제로 음이 바뀌는 템포를 느리게 하고 싶다면 phasor(frequency:) 값을 줄이는 것이 정답입니다.    🔚 요약                 변경할 항목       효과       조절 예시                       phasor(frequency:)       음이 바뀌는 주기 자체 느리게       0.5 → 0.25 → 0.1 등                 randomNumberPulse(updateFrequency:)       랜덤값의 갱신 주기 느리게       0.5 → 0.2 등           실제 사운드의 템포를 느리게 만들고 싶다면 **phasor 주파수(frequency)**를 낮추세요. "
  },
  
  {
    "title": "AudioKit의 LFOOperation",
    "url": "/posts/LFOOperation/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-18 14:04:42 +0900",
    "content": "LFO Operation  이 코드는 AudioKit의 OperationGenerator를 사용해 시간에 따라 동적으로 변화하는 FM(Frequency Modulation) 신디사이저를 정의한 예입니다. 각 요소를 하나씩 분석해 보겠습니다.    🧱 구조 전체 요약  let generator = OperationGenerator {   // ... FM 오실레이터 정의 }      OperationGenerator: Operation 기반으로 모듈식 사운드 신호 체인을 만들 수 있게 해주는 객체입니다.   내부 클로저 안에는 모듈 간 연결 로직과 제어 파라미터 정의가 들어갑니다.     🔁 LFO 정의  이 코드의 핵심은 4개의 LFO(Low-Frequency Oscillator) 를 사용해 FM 파라미터들을 시간에 따라 변화시키는 것입니다.  1️⃣ frequencyLFO: 정사각형파로 베이스 주파수를 제어  let frequencyLFO = Operation.square(frequency: 1)   .scale(minimum: 440, maximum: 880)           Operation.square(frequency: 1): 1Hz의 정사각형파 생성.             주파수가 1Hz이므로, 1초에 한 번 위아래로 바뀜 (즉, 0과 1 사이를 반복).                .scale(minimum: 440, maximum: 880):             0 → 440Hz, 1 → 880Hz로 스케일 조정       즉, 1초 주기로 440Hz ↔ 880Hz를 오가는 베이스 주파수           2️⃣ carrierLFO: 삼각파로 캐리어 멀티플라이어 제어  let carrierLFO = Operation.triangle(frequency: 1)   .scale(minimum: 1, maximum: 2)      삼각파는 부드럽게 올라갔다 내려갑니다 (정현파처럼 연속적이지만 직선형).   캐리어 멀티플라이어가 1~2 사이로 변화 → 베이스 주파수의 배수값으로 캐리어 주파수를 설정   3️⃣ modulatingMultiplierLFO: 톱니파로 변조 주파수 제어  let modulatingMultiplierLFO = Operation.sawtooth(frequency: 1)   .scale(minimum: 0.1, maximum: 2)      톱니파는 선형적으로 올라갔다가 갑자기 떨어짐 → 급변적인 톤 변화 유도   0.1~2 사이를 1초마다 반복 → 변조기 주파수가 점점 증가하다가 갑자기 리셋되는 느낌   4️⃣ modulatingIndexLFO: 역 톱니파로 변조 지수 제어  let modulatingIndexLFO = Operation.reverseSawtooth(frequency: 1)   .scale(minimum: 0.1, maximum: 20)      역 톱니파는 선형적으로 떨어졌다가 갑자기 올라감   변조 지수(Modulation Index)는 FM 사운드의 복잡도를 결정 → 0.1~20까지 1초마다 줄어들다가 갑자기 복잡하게 바뀜     🔊 FM 오실레이터 정의  return Operation.fmOscillator(   baseFrequency: frequencyLFO,   carrierMultiplier: carrierLFO,   modulatingMultiplier: modulatingMultiplierLFO,   modulationIndex: modulatingIndexLFO,   amplitude: 0.2 )      baseFrequency: 위에서 만든 440~880Hz 사이의 값   carrierMultiplier: base × 1~2 → 캐리어 주파수   modulatingMultiplier: base × 0.1~2 → 변조 주파수   modulationIndex: FM 복잡도, 0.1~20   amplitude: 0.2 고정   이 오실레이터는 1초 주기로 네 가지 파라미터가 모두 변화하므로, 끊임없이 음색이 변화하는 복잡하고 풍부한 톤을 생성합니다.    📈 음향적 결과                 요소       음향적 영향                       베이스 주파수 (440~880Hz)       1초마다 1옥타브 이동 (A3 ↔ A4)                 캐리어 멀티플라이어 (1~2)       주파수 대비 톤의 밝기 변화                 변조기 멀티플라이어 (0.1~2)       빠르게 진동할수록 더 거친/메탈릭한 소리                 변조 지수 (0.1~20)       사운드 복잡도 변화 (0.1은 순음에 가깝고, 20은 거칠고 노이즈적)           결과적으로 사이클이 짧지만 굉장히 다채로운 사운드를 실시간으로 만들 수 있습니다.    ✅ 요약  이 코드는:     4개의 LFO로 FM 오실레이터 파라미터를 제어하여   지속적으로 변화하는 톤을 생성하고   1초 주기로 사운드가 리듬처럼 변화하며   풍부한 음색 디자인과 알고리즘 작곡/사운드 디자인에 활용할 수 있습니다.   이런 방식은 앰비언트 사운드, 배경 음악, 모듈러 신스 이펙트, 또는 절차적 오디오에 매우 유용합니다.    Carrie Multiplier  “캐리어 멀티플라이어가 1~2 사이로 변화 → 베이스 주파수의 배수값으로 캐리어 주파수를 설정” 이 문장은 FM 합성(Frequency Modulation Synthesis)에서 **“캐리어 주파수”**를 어떻게 정하느냐에 대한 설명입니다.    🔊 기본 개념 정리     baseFrequency: 기준이 되는 주파수. 여기서는 frequencyLFO에 의해 440Hz ~ 880Hz 사이를 오감.   carrierMultiplier: 기준 주파수(baseFrequency)에 얼마만큼 곱할지 정하는 값.   carrierFrequency = baseFrequency × carrierMultiplier     🎯 예시로 이해하기  예를 들어:                 baseFrequency (Hz)       carrierMultiplier       결과 carrierFrequency (Hz)                       440       1.0       440                 440       1.5       660                 440       2.0       880                 880       1.0       880                 880       1.5       1320           이처럼, **캐리어 주파수는 베이스 주파수의 “배수”**로 설정되며, carrierMultiplier 값이 1에서 2로 바뀌면, 오실레이터가 점점 더 높은 음을 만들어냄을 의미합니다.    🧠 음향적으로 어떤 의미?     carrierMultiplier가 1.0: 캐리어와 베이스 주파수가 같아서 가장 기본적인 톤   carrierMultiplier가 2.0: 캐리어가 한 옥타브 위에 있어서 더 밝고 날카로운 소리   중간 값 (예: 1.5): 음색이 더 복잡하거나 약간 불협한 느낌을 줄 수 있음     ✅ 정리     “베이스 주파수의 배수값”이란 말은 기준 주파수 × multiplier를 의미   캐리어 멀티플라이어가 변화하면 캐리어 오실레이터의 주파수도 계속 바뀌어 음색에 동적인 변화를 줌   이런 방식은 모듈러 신디사이저나 음색 디자인에서 매우 자주 사용됩니다. "
  },
  
  {
    "title": "AudioKit의 InstrumentOperation",
    "url": "/posts/InstrumentOperation/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-17 14:21:48 +0900",
    "content": "Instrument Operation  InstrumentOperationConductor는 SporthAudioKit을 사용하여 간결한 코드로 복잡한 음향 합성 로직을 구현한 ObservableObject 클래스입니다. 이 클래스의 핵심은 OperationGenerator를 통해 FM 신스와 리듬 기반 트리거, 그리고 리버브 공간 처리를 결합한 절차적 악기 연주를 구성하는 데 있습니다.    🎛 구조 요약  class InstrumentOperationConductor: ObservableObject, HasAudioEngine      ObservableObject이므로 SwiftUI에서 @StateObject로 사용할 수 있습니다.   HasAudioEngine 프로토콜을 통해 AudioKit의 engine을 직접 제어합니다.     🎼 OperationGenerator 내부 설명  let generator = OperationGenerator { ... }   이 클로저는 Sporth DSL을 Swift 스타일로 구성한 것으로, 최종적으로 Operation의 signal graph를 생성합니다.    🔹 func instrument(...) 설명  func instrument(noteNumber: MIDINoteNumber, rate: Double, amplitude: Double) -&gt; OperationParameter   이 함수는 하나의 악기 역할을 합니다.  내부 동작:  let metronome = Operation.metronome(frequency: 82 / (60 * rate))      metronome은 트리거 신호를 일정 간격으로 발생시키는 Sporth의 metro 연산자에 해당합니다.   BPM이 82일 때, 지정된 rate에 따라 일정한 시간마다 발동함.   rate는 음 하나가 몇 배 빠르거나 느리게 연주될지를 조절하는 비율 값            rate = 1이면 기본 템포 그대로       rate = 2이면 템포 절반 (느리게)       rate = 0.5이면 템포 두 배 (빠르게)           예제                 rate 값       계산식       metronome 주파수       초당 트리거 횟수       결과                       1       82 / (60 × 1)       ≈ 1.3667 Hz       ≈ 1.37회       느리게 반복                 2       82 / (60 × 2)       ≈ 0.6833 Hz       ≈ 0.68회       더 느리게                 4       82 / (60 × 4)       ≈ 0.3416 Hz       ≈ 0.34회       매우 느리게                 0.5       82 / (60 × 0.5) = 82 / 30       ≈ 2.733 Hz       ≈ 2.73회       빠르게 반복           let frequency = Double(noteNumber.midiNoteToFrequency())      MIDINoteNumber → Hz 주파수로 변환   let fmOsc = Operation.fmOscillator(baseFrequency: frequency, amplitude: amplitude)      Sporth의 fm 연산자에 해당 (주파수 변조 발진기)   Carrier wave를 Modulator wave로 변조하여 보다 복잡한 스펙트럼을 생성합니다.   fmOscillator는 FM(Frequency Modulation) 방식의 오실레이터입니다.            FM 합성(FM Synthesis) 을 기반으로 하며, 입력된 baseFrequency와 amplitude 값을 바탕으로 소리를 생성합니다.           return fmOsc.triggeredWithEnvelope(trigger: metronome, attack: 0.5, hold: 1, release: 1)      triggeredWithEnvelope는 Sporth에서 trig + adsr 조합에 해당   트리거가 발생할 때마다 FM 사운드가 0.5초에 걸쳐 올라갔다가, 1초 유지되고, 1초에 걸쳐 감소합니다.     🔹 여러 음의 합성  let instruments2 = [   instrument(noteNumber: 60, rate: 4, amplitude: 0.5),   instrument(noteNumber: 62, rate: 5, amplitude: 0.4),   instrument(noteNumber: 65, rate: 7, amplitude: 1.3 / 4.0),   instrument(noteNumber: 67, rate: 7, amplitude: 0.125), ].reduce(Operation.trigger) { $0 + $1 } * 0.13      네 개의 instrument(...) 호출로 다양한 음과 리듬을 만들어냅니다.   reduce(Operation.trigger)는 처음에 더미 트리거 (Operation.trigger, 즉 0값)로 시작해서 하나씩 더해 합산된 signal graph를 구성합니다.   마지막에 * 0.13으로 전체 볼륨을 조절합니다.     🔹 리버브 적용  let reverb = instruments2.reverberateWithCostello(feedback: 0.9, cutoffFrequency: 10000).toMono()      Sporth의 FDN(Finite Delay Network) 리버브 모델인 costello를 사용   8개의 딜레이 라인을 이용한 고품질 리버브 모델입니다.   feedback: 0.9: 긴 잔향을 의미하며 홀 같은 공간감을 연출   cutoffFrequency: 10000: 10kHz 이하의 신호만 통과 (고역 감쇠로 더 자연스러운 리버브)   return mixer(instruments2, reverb, balance: 0.4)      dry (원본 신호)와 wet (리버브 신호)를 0.4의 비율(wet이 0.4)로 믹싱합니다.     🔊 Sporth 관점 요약 (예상 변환)  // 각각의 note fm freq=261.63 amp=0.5 trig=metro(82/240) trigadsr(0.5, 1, 1) * + ... costello feedback=0.9 hpcf=10000 mix dry wet balance=0.4     🔈 음향적 설명     이 코드는 FM 합성을 기반으로 다양한 주파수의 음을 불규칙한 간격으로 발생시킵니다.   각 음은 attack-hold-release envelope을 갖기 때문에 자연스럽고 감정적인 연주 스타일을 시뮬레이션합니다.   리버브는 매우 큰 공간감을 제공하므로, 배경음악, 설치예술, 앰비언트 사운드 등에 적합한 느낌을 줍니다.     ✅ 요약                 구성 요소       설명                       OperationGenerator       Sporth DSL 기반의 사운드 생성 엔진                 instrument(...)       FM 사운드 + 리듬 트리거 + envelope                 reverberateWithCostello       고급 리버브로 공간감 추가                 mixer(...)       dry/wet 사운드 믹싱                 전체 목적       다양한 피치와 템포의 FM 톤을 자동 생성하고 리버브를 더해 풍부한 배경음 생성           이 구조는 AudioKit에서 음향 알고리즘 프로토타이핑이나 창작적 사운드 디자인에 매우 유용하게 활용됩니다. "
  },
  
  {
    "title": "AudioKit의 DroneOperation",
    "url": "/posts/DroneOperation/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-16 14:22:30 +0900",
    "content": "Drone Operation  이 코드는 SporthAudioKit을 사용해 간단한 드론(지속음) 사운드를 만드는 예제입니다. OperationGenerator는 Sporth 기반의 모듈식 신디사이저로, 사운드를 코드로 구성할 수 있는 기능을 제공합니다.    📌 전체 개요  let generator = OperationGenerator { ... }      OperationGenerator는 하나의 사운드를 만들어 출력하는 객체입니다.   클로저 내부에서 정의된 OperationParameter 들은 Sporth DSL로 변환되어 오디오를 생성합니다.   여기선 drone()이라는 함수를 통해 3개의 톤을 반복 재생하는 소리를 만들어 평균 냅니다.     🔍 drone 함수 분석  func drone(frequency: Double, rate: Double) -&gt; OperationParameter {   let metronome = Operation.metronome(frequency: rate)   let tone = Operation.sineWave(frequency: frequency, amplitude: 0.2)   return tone.triggeredWithEnvelope(     trigger: metronome,     attack: 0.01,     hold: 0.1,     release: 0.1   ) }   1. Operation.metronome(frequency: rate)     일정한 간격으로 트리거 신호를 발생시킵니다.   rate는 1초당 트리거 발생 횟수입니다. (즉, 속도 조절)   예: rate: 3이면 1초에 3번 트리거가 발생합니다.   2. Operation.sineWave(...)     지정된 주파수와 진폭으로 사인파 톤을 생성합니다.   frequency: 음의 높이 (Hz)   amplitude: 음의 크기 (여기선 0.2로 약한 소리)   3. triggeredWithEnvelope(...)     tone을 metronome에 의해 트리거되도록 설정합니다.   ADSR Envelope 구조입니다:                  파라미터       설명                       attack       소리가 시작될 때 증가하는 시간                 hold       최대 진폭을 유지하는 시간                 release       사운드가 꺼질 때 감소하는 시간           즉, “사인파가 메트로놈 트리거로 짧게 재생되도록 만드는” 것입니다.    🎧 최종 결과  return (   drone(frequency: 440, rate: 3) // A, 1초에 3번 + drone(frequency: 330, rate: 5) // E, 1초에 5번 + drone(frequency: 450, rate: 7) // A♯(B♭), 1초에 7번 ) / 3      A(440Hz), E(330Hz), A♯(450Hz)의 세 개 사운드를 반복적으로 재생합니다.   각 사운드는 서로 다른 트리거 속도로 실행되며,   전체 사운드는 이 3개의 드론을 평균 내어 혼합한 것입니다.   결과: 리드미컬하고 유기적으로 맥동하는 배경음 생성     🧠 요약                 요소       설명                       OperationGenerator       오디오 신호를 동적으로 생성하는 장치                 metronome       트리거 신호 발생                 sineWave       기본적인 음향 생성기                 triggeredWithEnvelope       일정 패턴으로 소리를 짧게 재생                 drone(...)       위 로직을 묶은 재사용 가능한 함수             📝 확장 팁     frequency, rate 등을 랜덤하게 하거나 UI와 연결하면 더 유기적인 사운드가 가능합니다.   OperationGenerator는 AVAudioUnit처럼 사용할 수 있어 오디오 체인에도 삽입 가능합니다.    "
  },
  
  {
    "title": "AudioKit의 CrossingSignal",
    "url": "/posts/CrossingSignal/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-15 14:10:26 +0900",
    "content": "Crossing Signal  CrossingSignalConductor 클래스는 AudioKit 프레임워크를 이용해 영국식 횡단보도 경고음(Crossing Signal Tone)을 생성하고 제어하는 역할을 합니다. 이 클래스는 ObservableObject와 HasAudioEngine을 채택하여 SwiftUI에서 오디오 처리를 UI와 연동할 수 있게 설계되어 있습니다. 아래에서 해당 클래스의 각 구성 요소를 라인별로 분석하고, 그 음향적 의미도 함께 설명합니다.    🔧 클래스 선언  class CrossingSignalConductor: ObservableObject, HasAudioEngine      ObservableObject: SwiftUI에서 이 객체의 속성이 변경되었을 때 UI를 갱신할 수 있도록 함.   HasAudioEngine: AudioKit에서 engine 속성을 기본으로 제공하도록 하는 프로토콜로, 오디오 신호 흐름을 관리할 수 있게 함.     🎛 오디오 엔진  let engine = AudioEngine()      AudioEngine: AudioKit의 핵심 클래스. 노드를 연결하고 재생하는 신호 처리 그래프 역할을 함.   이 engine은 내부적으로 AVAudioEngine을 추상화하고 있으며, generator를 output에 연결하여 사운드 출력을 제어함.     ▶️ 실행 상태 제어  @Published var isRunning = false {   didSet {     isRunning ? generator.start() : generator.stop()   } }      @Published: SwiftUI View에서 상태 변화 감지용.   isRunning이 true가 되면 generator를 시작하고, false이면 멈춤.   UI 버튼을 통해 이 값을 토글할 수 있음.     🔉 OperationGenerator (신호 생성기)  let generator = OperationGenerator {   ... }      OperationGenerator: AudioKit의 고수준 신호 생성기로, Sporth 언어 기반 DSL로 신호를 구성함.   내부 클로저에서 오디오 신호 처리 체인을 정의함.     📡 사운드 구성 상세  let crossingSignalTone = Operation.sineWave(frequency: 2500)      2500Hz 사인파를 생성.   매우 높은 주파수로, 실제 영국 횡단보도에서 청각장애인을 위한 경고음에 가까운 주파수임.     let crossingSignalTrigger = Operation.periodicTrigger(period: 0.2)      0.2초마다 트리거를 발생.   1초에 5번의 주기로 사운드를 깜빡임 (일종의 깜빡이는 경고음 효과).     let crossingSignal = crossingSignalTone.triggeredWithEnvelope(   trigger: crossingSignalTrigger,   attack: 0.01,   hold: 0.1,   release: 0.01 )      트리거가 발생할 때마다 사인파를 ADSR envelope으로 감싸서 짧게 발음.   attack: 0.01초 (빠르게 시작)   hold: 0.1초 (약 0.1초 동안 유지)   release: 0.01초 (빠르게 소멸)   ⏳ → 이 구조는 실제 횡단보도 경고음의 “삐-삐-삐” 패턴을 만들기 위한 구조입니다.    return crossingSignal * 0.2      전체 음량을 줄임 (20%로).   고주파 음이므로 귀에 자극적일 수 있어 음량을 낮춤.     🔌 init()  init() {   engine.output = generator }      AudioEngine의 출력 노드를 generator로 설정.   즉, generator에서 생성된 소리가 최종 출력으로 이어짐.     📈 음향적 관점 요약                 구성 요소       역할                       Sine Wave 2500 Hz       고주파의 청각 경고음 생성                 Periodic Trigger       일정 간격(0.2s)으로 신호 발생                 ADSR Envelope       음을 짧게 트리거하여 “삐-삐” 같은 경고음 형성                 Volume Scaling (0.2)       음량 제한하여 자극 최소화           이런 구조는 실제 철도 건널목, 횡단보도 등의 보행자 경고음 시뮬레이션에 적합합니다.    📦 요약  CrossingSignalConductor는:     AudioKit의 OperationGenerator를 통해 2500Hz의 고주파 사인파를 생성하고   주기적인 트리거와 envelope를 통해 점멸하는 듯한 짧은 경고음을 만들며   SwiftUI와 연동 가능한 형태로 설계되어 있습니다.   이 구현은 Andy Farnell의 “Designing Sound” 에서 영감을 받은 것으로, 실제 세계의 사운드를 디지털로 모사(simulate) 한 전형적인 예입니다. "
  },
  
  {
    "title": "AudioKit의 VocalTract",
    "url": "/posts/VocalTract/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-14 18:01:32 +0900",
    "content": "VocalTract  용어설명  ✅ 성도 (Vocal Tract, 聲道)     정의: 인간의 발성 기관 중, 성문부터 입술까지의 공기 통로를 의미합니다.   구성: 인두(pharynx), 구강(oral cavity), 비강(nasal cavity) 등 포함.   역할: 이 통로의 형태와 크기를 조절함으로써 소리의 공명을 변화시켜 다양한 **말소리(모음, 자음)**를 만들어냅니다. 예: 입을 크게 벌리거나 혀 위치를 바꾸면 음색이 달라지는 이유.   ✅ 성문 펄스 파형 (Glottal Pulse Wave)     정의: **성대(glottis)**가 주기적으로 열리고 닫히며 발생시키는 기초적인 소리 파형입니다.   역할: 이 파형이 바로 음성의 원천적인 진동이며, 이후 성도에서 공명을 거쳐 실제 말소리로 바뀝니다.   예시: 남자의 저음 목소리는 느린 주기로 성대가 열리고 닫히면서 낮은 주파수의 성문 펄스가 발생하는 것.   요약하면:     성도는 소리를 변조하는 필터 역할이고,   성문 펄스 파형은 소리의 원천 신호 (진동원) 역할입니다.     파라미터  VocalTract에서 조정하는 아래 5가지 파라미터는 사람의 음성 생성 과정을 물리적으로 모사한 것이며, 각각이 소리의 성질에 중요한 영향을 미칩니다. 아래는 각 파라미터가 조절될 때 어떤 음향적 특징이 변하는지에 대한 설명입니다.  1. frequency: 성문 주파수 (Glottal Frequency)     정의: 성대의 진동 속도, 즉 1초당 성대가 열리고 닫히는 횟수 (Hz).        영향:             이 값이 높을수록 음의 **높이(피치)**가 올라감.       낮을수록 음성이 굵고 낮은 톤.           예시: 어린이의 목소리는 높은 주파수, 남성의 저음 목소리는 낮은 주파수.   2. tonguePosition: 혀 위치     정의: 입안에서 혀의 앞뒤 위치를 0~1 범위로 나타냄.        영향:             혀가 앞쪽(0)일수록 앞 모음 계열 (예: [i], [e])       뒤쪽(1)으로 갈수록 후설음 계열 (예: [u], [o])           예시: ‘이’와 ‘우’의 차이처럼 혀 위치에 따라 공명 위치가 달라짐.   3. tongueDiameter: 혀 직경     정의: 혀가 차지하는 입안의 공간 크기를 나타냄.        영향:             작을수록 입안의 공간이 좁아져 높은 포먼트 주파수 → 밝고 가는 소리       클수록 공간이 넓어져 낮은 포먼트 주파수 → 둔탁하고 어두운 소리           예시: 입을 크게 벌리거나 혀를 들어올릴 때 음색이 달라짐.   4. tenseness: 음성 긴장도     정의: 성대 근육의 긴장 정도 (0 = 무성음, 1 = 긴장된 유성음)        영향:             값이 낮으면 속삭이는 소리, 숨소리 같이 부드럽고 기식이 섞임       값이 높으면 선명한 유성음, 일반적인 목소리           예시: whisper와 normal voice의 차이   5. nasality: 비음도 (콧소리 성분)     정의: 코를 통한 공기 통과 정도        영향:             값이 높을수록 콧소리가 섞인 듯한 음색       낮을수록 입 중심의 일반적인 소리           예시: “나”, “마”처럼 코를 울리는 소리에서 nasality 값이 높음   📌 요약표                 파라미터       설명       영향을 주는 소리 특성                       frequency       성대 진동 속도       음의 높낮이 (피치)                 tonguePosition       혀의 앞뒤 위치       발음의 공명 위치 (모음의 구분)                 tongueDiameter       혀의 굵기/공간       음색의 밝기/어둠                 tenseness       성대의 긴장도       유성/무성 구분, 속삭임 ↔ 선명도                 nasality       비강의 개방 정도       비음의 정도 (콧소리 포함 여부)           이러한 파라미터들은 함께 작동하여 하나의 음성이 생성되며, 이를 조절하면 사람의 말소리나 다양한 음색을 실제처럼 시뮬레이션할 수 있게 됩니다. "
  },
  
  {
    "title": "AudioKit의 Tuner",
    "url": "/posts/Tuner/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-13 15:24:56 +0900",
    "content": "Tuner  Tuner.swift 파일은 AudioKit을 활용한 튜너(Tuner) 기능을 SwiftUI로 구현한 예제입니다. 핵심 역할은 마이크 입력을 받아 해당 소리의 주파수(Pitch) 와 진폭(Amplitude) 을 측정하고, 현재 음이 어떤 음계(Note)인지 판단하여 사용자에게 알려주는 것입니다.    🧩 TunerConductor 클래스 설명  TunerConductor는 오디오 처리의 중심이 되는 ObservableObject로, AudioKit의 오디오 그래프 구성과 실시간 피치 분석을 담당합니다.  주요 변수와 역할                 변수       설명                       engine       AudioKit의 오디오 엔진. 전체 오디오 흐름의 시작점                 mic       마이크 입력 (engine.input)                 tappableNode       Fader 노드 3개(A, B, C)로 구성된 체인. 각각 분석/시각화 목적                 silence       최종 출력 노드. gain: 0으로 설정되어 실제 오디오 출력은 없음                 tracker       PitchTap 객체. 실시간 피치(Pitch)와 진폭(Amplitude) 추적                 noteInfos       12반음 음계의 기준 주파수와 음 이름 정보 포함           노드 연결 구조 (플레인 텍스트 그림)  [Mic Input] → [Fader A] → [Fader B] → [Fader C] → [Silence (gain: 0)]                      ↑         ↑         ↑                 RollingView  OutputView  FFTView     작동 방식          입력             engine.input을 통해 마이크 입력을 받고 이를 Fader에 연결합니다.       PitchTap(mic) 은 마이크 입력을 tap(오디오 신호 라인 중간에 연결해서 감시(listen)하는 동작) 하여 실시간 피치와 진폭을 측정합니다.                노드 체인 구성             Fader A → B → C 는 동일한 오디오 신호를 단계적으로 연결하여 각기 다른 시각화 뷰에 전달합니다.       silence 노드는 출력이 실제 재생되지 않도록 설정 (gain = 0).                주파수 분석             update(_:_:): 메서드는 PitchTap에서 받은 피치와 진폭을 사용해 현재 음에 해당하는 노트를 계산합니다.       noteInfos 배열과 비교하여 가장 가까운 기준 음을 찾고, 옥타브를 보정하여 결과로 표시합니다.                실시간 시각화             세 종류의 오디오 분석 뷰를 통해 시각적으로 상태를 보여줍니다.             📊 NodeRollingView, NodeOutputView, NodeFFTView 정의 및 차이점                 뷰       정의       목적       차이점                       NodeRollingView       실시간 파형 (오실로스코프처럼)       시간에 따른 파형 형태 확인       단순 오디오 신호의 시간 축 변화                 NodeOutputView       출력 볼륨/레벨 바 (meter)       출력 신호의 세기 (Amplitude) 시각화       amplitude 기반의 단순 레벨 확인                 NodeFFTView       주파수 분석 (스펙트럼)       실시간 주파수 분포(FFT) 분석       소리에 포함된 주파수 성분 시각화           모두 tappableNode의 서로 다른 노드를 대상으로 하기 때문에, 같은 입력이더라도 각기 다른 시각 정보를 제공합니다.    📦 정리     TunerConductor는 실시간 마이크 입력을 받아 음의 주파수 및 진폭을 계산하고, 이를 기준 음에 매칭시켜 화면에 표시합니다.   오디오 신호는 Fader A → B → C로 흐르며, 각각 별도의 뷰로 시각화됩니다.   사용자 입장에서는 현재 음 높이, 세기, 스펙트럼을 동시에 확인할 수 있습니다.   실제 소리는 출력되지 않지만, 모든 신호는 내부적으로 오디오 그래프를 통해 처리되므로 정밀한 분석이 가능합니다.     update(::) 상세 설명  update(_ pitch: AUValue, _ amp: AUValue) 함수는 오디오 입력(마이크 등)에서 실시간으로 받은 주파수(pitch) 와 진폭(amplitude) 을 기반으로 음이름과 옥타브 정보를 추출하는 로직입니다. 아래에 라인별로 상세 분석을 제공합니다.    🔧 전체 함수 시그니처  func update(_ pitch: AUValue, _ amp: AUValue)      실시간으로 PitchTap 콜백에서 전달된 pitch (Hz 단위)와 amp (진폭)를 받아 처리합니다.   AUValue는 Float의 typealias입니다.     1. 진폭이 너무 작으면 무시  guard amp &gt; 0.1 else {   return }      배경 잡음을 필터링하기 위한 조건입니다.   진폭(amp)이 0.1보다 작으면 거의 무음 또는 노이즈로 간주하여 무시합니다.   → 불필요한 pitch 추적을 피합니다.     2. 데이터 저장  data.pitch = pitch data.amplitude = amp      외부 UI에서 관찰 가능한 @Published var data에 값을 저장합니다.   SwiftUI 뷰에서 이 값을 기반으로 화면을 업데이트합니다.     3. 주파수를 1옥타브 범위로 정규화  var frequency = pitch while frequency &gt; Float(noteInfos[noteInfos.count - 1].frequency) {   frequency /= 2.0 } while frequency &lt; Float(noteInfos[0].frequency) {   frequency *= 2.0 }      입력된 pitch(예: 440Hz)가 1옥타브(12음계) 기준 주파수 범위를 벗어날 수 있으므로,   가장 가까운 1옥타브 범위(약 16.35~30.87Hz)로 정규화합니다.   이 과정을 통해 다음 단계에서 12개의 기준 음표(noteInfos) 와 비교할 수 있습니다.     4. 가장 가까운 음을 찾기 위한 초기값 설정  var minDistance: Float = 10000.0 var index = 0      minDistance: 가장 가까운 음표와의 주파수 차이를 저장할 변수   index: 가장 가까운 음의 noteInfos 인덱스를 저장합니다.     5. 12개의 기준 음 중 가장 가까운 음 찾기  for possibleIndex in noteInfos.indices {   let distance = fabsf(Float(noteInfos[possibleIndex].frequency) - frequency)   if distance &lt; minDistance {     index = possibleIndex     minDistance = distance   } }      fabsf: float 값의 절댓값을 구함.   각 note와 frequency 간 차이를 계산하고, 가장 작은 차이를 가진 index를 저장합니다.   즉, 어떤 음(C, C♯ 등) 에 가장 가까운지 찾는 로직입니다.     6. 옥타브 계산  let octave = Int(log2f(pitch / frequency))      원래의 pitch와 위에서 정규화된 frequency의 비율을 log2f로 변환해 옥타브를 계산합니다.   예: pitch = 440, frequency = 27.5 → 440 / 27.5 = 16 → log2(16) = 4 → 옥타브 4차이     7. 결과 음표 이름 저장  data.noteNameWithSharps = \"\\(noteInfos[index].noteNamesWithSharps)\\(octave)\" data.noteNameWithFlats = \"\\(noteInfos[index].noteNamesWithFlats)\\(octave)\"      가장 가까운 음표를 샤프 또는 플랫 이름으로 출력합니다. 예: C♯4, D♭4   이 값은 화면의 텍스트 뷰에서 다음과 같이 보입니다: C♯4 / D♭4     ✅ 요약                 역할       기능                       진폭 필터링       잡음을 제외                 주파수 정규화       12음계 범위로 매핑                 음표 추적       가장 가까운 음표 탐색                 옥타브 추정       주파수 차이 기반 계산                 출력 저장       UI에 표시할 note name 할당           이 함수는 결국 실시간 입력으로부터 “현재 들리는 음은 어떤 음인지, 몇 옥타브인지” 를 계산해주는 핵심 로직입니다. "
  },
  
  {
    "title": "AudioKit의 Telephone",
    "url": "/posts/Telephone/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-12 18:02:47 +0900",
    "content": "Telephone  이 코드는 고전 전화기의 키패드 및 음향을 시뮬레이션하는 SwiftUI 기반 앱으로, AudioKit의 OperationGenerator를 이용해 다이얼 톤, 벨소리, 통화 중 신호, 그리고 DTMF(이중 음향 다중 주파수; Dual-Tone Multi-Frequency) 톤을 생성합니다. 주요 로직은 TelephoneConductor 클래스에 있으며, Sporth(AudioKit의 오디오 DSL)를 사용하여 오디오를 생성합니다.    🔊 TelephoneConductor 클래스 설명  구조     ObservableObject 및 HasAudioEngine을 채택해 SwiftUI와 AudioKit 환경에 맞게 설계됨.   AudioEngine 인스턴스를 생성해 오디오 노드를 연결하고 재생 제어.   📞 주요 사운드 생성기  1. dialTone: 기본 전화 대기음  let dialTone = OperationGenerator {   let dialTone1 = Operation.sineWave(frequency: 350)   let dialTone2 = Operation.sineWave(frequency: 440)   return mixer(dialTone1, dialTone2) * 0.3 }      350Hz + 440Hz 사인파를 섞은 기본 전화기 “뚜—” 대기음.   mixer(...) * 0.3: 두 사인파를 합친 후 볼륨 조정.   2. ringing: 벨소리  let ringing = OperationGenerator {   let ringingTone1 = Operation.sineWave(frequency: 480)   let ringingTone2 = Operation.sineWave(frequency: 440)   ...   let ringTrigger = Operation.metronome(frequency: 0.1666)   ... }      480Hz + 440Hz를 2초간 울리고 6초마다 반복하는 구조.   Operation.metronome(...): 주기적 트리거.   triggeredWithEnvelope(...): 사운드를 일정 시간 동안 유지하고 끄는 ADSR 방식.   triggeredWithEnvelope  triggeredWithEnvelope는 AudioKit의 OperationGenerator 내에서 envelope(진폭 곡선)을 트리거 이벤트에 따라 자동으로 적용해주는 함수입니다.  triggeredWithEnvelope(   trigger: Operation,   attack: Double,   hold: Double,   release: Double )                  파라미터       설명                       trigger       0이 아닌 값이 입력될 때 envelope이 시작됨. 주로 metronome이나 매개변수를 사용                 attack       신호가 0에서 최대 진폭까지 도달하는 시간 (초)                 hold       최대 진폭에서 유지되는 시간 (초)                 release       최대 진폭에서 0까지 떨어지는 시간 (초)              triggeredWithEnvelope는 오디오 신호에 시작-유지-종료 형태의 진폭 곡선(ADSR의 일부)을 자동으로 입히고, 특정 트리거가 들어올 때만 실행되도록 만듭니다. 이로써 시간 제어된 사운드 생성이 가능해집니다.   3. busy: 통화 중 신호  let busy = OperationGenerator {   let busySignalTone1 = Operation.sineWave(frequency: 480)   let busySignalTone2 = Operation.sineWave(frequency: 620)   ...   let busyTrigger = Operation.metronome(frequency: 2) }      480Hz + 620Hz 사인파를 0.25초씩 0.5초 간격으로 반복.   4. keypad: 키패드 톤  let keypad = OperationGenerator {   let op1 = Operation.sineWave(frequency: Operation.parameters[1])   let op2 = Operation.sineWave(frequency: Operation.parameters[2])   let keyPressTone = op1 + op2   let press = keyPressTone.triggeredWithEnvelope(trigger: Operation.parameters[0], ...) }      사용자 입력에 따라 두 주파수를 동적으로 받아 parameters[1], parameters[2]로 사인파 생성.   parameters[0]는 트리거 역할을 하며, 눌렀다 뗄 때 구분함.   triggeredWithEnvelope: 짧은 키 톤 재생을 위해 공격-유지-릴리스 구조.     기타 기능     last10Digits: 최근 입력한 키 10자리 유지.   doit(key:state:): 각 키에 대한 반응을 정의. \"CALL\", \"BUSY\" 등 특별 키와 숫자 키를 구분 처리.        init():             keys: 각 숫자에 해당하는 DTMF 주파수를 정의 (예: \"1\" = 697Hz + 1209Hz).       engine.output: 출력 믹서 설정.             📱 TelephoneView 간단 설명     SwiftUI 기반 UI 구성.   NumberKeyInfo: 키패드의 숫자 및 문자 정보 구조체.   LazyVGrid: 전화기 키패드 형태로 버튼 정렬.   각 키는 .gesture를 통해 눌림/떼짐 이벤트 감지 및 conductor.doit(...) 호출.   PhoneKey, BusyKey, DeleteKey: 각각 통화 시작, 종료, 삭제 역할의 버튼 구성.     결론  이 코드는 SwiftUI와 AudioKit의 OperationGenerator + Sporth 문법을 조합하여 실제 전화기처럼 작동하는 인터랙티브 사운드 앱을 구현한 예시입니다.     OperationGenerator는 저수준 DSP 코드 없이 오디오 신호 처리를 구현할 수 있게 해줍니다.   triggeredWithEnvelope, metronome, parameters는 동적 오디오 제어를 위한 핵심 Sporth 연산자입니다.    "
  },
  
  {
    "title": "AudioKit의 Sporth OperationGenerator",
    "url": "/posts/Sporth_OperationGenerator/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-12 15:19:44 +0900",
    "content": "Sporth  Sporth는 **“Small Portable Real-Time Sound Language”**의 줄임말로, 경량 텍스트 기반 오디오 DSP 언어입니다. C 기반 오디오 라이브러리인 Soundpipe의 일부로 개발되었으며, AudioKit에서도 내장되어 있습니다.    ✅ Sporth란?     목적: 실시간 오디오 신호 처리를 빠르고 간단하게 기술할 수 있도록 설계된 스택 기반 언어   형식: \"sine 440 0.5 mul\" 같은 단순한 텍스트 문자열   실행: 오디오 그래프(DSP 신호 흐름)를 실시간으로 생성하고 처리함   용도: 합성(synthesis), 필터링, 이펙트, 시퀀싱 등 오디오 관련 처리 전반     🔧 Sporth의 작동 방식 (스택 기반)  스택 머신처럼 동작합니다:  440 sine 0.5 mul   이 의미는:     440 → 스택에 440 푸시   sine → 스택에서 440을 꺼내 사인파 생성 → 결과 푸시   0.5 → 0.5 푸시   mul → 두 값을 꺼내 곱함 → 최종 오디오 신호 생성     🧪 예시  1. 사인파 생성  440 sine   → 440Hz 사인파 생성  2. 노이즈 생성 + 필터  pinknoise 8000 tone   → 핑크 노이즈를 8kHz로 로우패스 필터링  3. 오토펜닝 + 볼륨 조절  0.5 0.5 sine pan 0.2 mul   → 오토펜닝된 사운드를 볼륨 20%로 출력    🎯 Sporth의 장점                 항목       설명                       가볍고 빠름       DSP를 직접 제어하는 데 적합함                 실시간 수정       오디오 중단 없이 코드를 바꿀 수 있음                 AudioKit 통합       OperationGenerator에서 쉽게 사용 가능             🧩 AudioKit과의 관계  AudioKit에서는 OperationGenerator(sporth: \"코드\") 형태로 Sporth를 사용할 수 있습니다. 복잡한 UI 없이도 DSP 알고리즘을 간단히 실험하거나 프로토타이핑할 수 있는 좋은 도구입니다.    OperationGenerator  OperationGenerator는 AudioKit에서 제공하는 Node의 서브클래스로, Sporth 코드 기반의 사운드 생성기(Generator) 역할을 합니다. 즉, 사용자가 제공하는 Sporth DSL(도메인 특화 언어) 또는 AudioKit의 Operation API를 바탕으로 오디오 신호를 생성하는 가변형 DSP 노드입니다.    ✅ 주요 특징  1. Node 프로토콜 채택          OperationGenerator는 AudioKit의 Node를 상속받으며,             connections는 빈 배열 (연결된 노드 없음)       avAudioNode는 내부적으로 instantiate(instrument: \"cstg\")를 통해 생성된 AVAudioNode             2. 파라미터 14개 제공     최대 14개의 파라미터 (parameter1 ~ parameter14)를 지원   각 파라미터는 @Parameter 프로퍼티 래퍼를 사용하여 연결됨   실제 AUParameter로 연결되어 외부에서 실시간 조절 가능 (예: UI 슬라이더)     3. 여러 초기화 방식 지원  a. 단일 Operation 기반 초기화  OperationGenerator(operation: { ops in   ops[0].sineWave() })      입력된 ([Operation]) -&gt; ComputedParameter 클로저로부터 Sporth 코드를 생성   단일 채널인 경우 dup, 스테레오인 경우 swap 등을 Sporth 코드에 삽입하여 채널 정렬   b. 파라미터 없는 Operation도 가능  OperationGenerator(operation: {   Operation.sineWave() })   c. 스테레오 Operation 두 개 입력  OperationGenerator(channelCount: 2, operations: { ops in   [ops[0].sineWave(), ops[1].squareWave()] })     4. Sporth 문자열 직접 초기화 가능  OperationGenerator(sporth: \"pinknoise dup\")      Sporth 문자열을 직접 넣어 제너레이터를 구성할 수 있음   내부적으로 akOperationSetSporth()를 통해 DSP 설정     5. trigger()로 사운드 실행  generator.trigger()      au.trigger()를 호출하여 현재 파라미터로 한 번 실행   주로 “보이스”, “샘플”, “효과음” 등에 사용     🔧 활용 예시  let generator = OperationGenerator {   Operation.sineWave(frequency: Operation.parameter(1)) * 0.3 } generator.parameter1 = 440 generator.start() generator.trigger()     🎯 요약                 요소       설명                       Operation 기반       AudioKit Operation API 또는 Sporth로 구성                 파라미터       최대 14개 실시간 제어용                 출력       mono 또는 stereo                 주요 용도       사운드 합성, 효과 생성, 실험적 DSP 노드 구성            "
  },
  
  {
    "title": "SpriteKitAudio 예제",
    "url": "/posts/SpriteKitAudio/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-11 16:17:36 +0900",
    "content": "Sprite Kit Audio  이 코드는 SpriteKit과 AudioKit을 결합한 인터랙티브 사운드 예제입니다. 사용자가 화면을 터치하면 공이 생성되고, 플랫폼에 부딪히면 소리가 나는 구조입니다. 주요 구성요소별로 설명드리겠습니다.    ✅ 전반적 구조     SpriteKit을 이용해 물리 기반 애니메이션 처리   AudioKit을 이용해 플랫폼에 충돌 시 음향 재생   SwiftUI에서 SpriteView로 SpriteKit 장면을 보여줌     1. GameScene (SKScene + 물리 처리)  didMove(to:)     장면 초기 설정   physicsWorld.contactDelegate = self → 충돌 감지 델리게이트 설정   physicsBody = edgeLoopFrom: → 화면 가장자리를 물리적으로 막는 테두리 벽 생성   for i in 1...3 → 3개의 경사진 **플랫폼(plat)**을 생성하고 물리 바디 설정   각 플랫폼 설정     회전각 .pi / 8, -.pi / 8을 사용해 경사 조절   categoryBitMask = 2, contactTestBitMask = 2로 충돌 범주 설정   isDynamic = false로 고정된 물체 (움직이지 않음)     2. touchesBegan(_:with:)          사용자가 화면을 터치하면:             반지름 5짜리 원형 공(box) 생성       랜덤한 색상 적용       해당 위치에 공 생성 후 중력 적용 (affectedByGravity = true)       category와 contact 비트마스크도 2번으로 설정 → 플랫폼과 충돌 감지 가능             3. didBegin(_:)          공이 플랫폼에 닿을 때:             platform1 → MIDI note 60       platform2 → MIDI note 64       platform3 → MIDI note 67       → 각각 다른 음을 재생 (도, 미, 솔)                그 외 바닥에 닿으면 ball 노드를 제거        4. playSound(noteNumber:)     MIDISampler를 이용해 해당 note를 0.1초 동안 연주 후 중지     5. SpriteKitAudioConductor     MIDISampler를 AudioKit에서 초기화   .exs 사운드폰트 로딩 (e.g. sawPiano1.exs)   Reverb로 출력 노드 감쌈 → 약간의 공간감 제공     6. SpriteKitAudioView (SwiftUI)     GameScene을 SpriteView에 넣어 SwiftUI에서 표시   conductor를 장면에 주입   .onAppear / .onDisappear로 AudioKit 엔진 제어     🔊 동작 흐름 요약     화면 터치 → 공 생성 → 중력에 의해 하강   공이 플랫폼에 닿으면 → 해당 음 재생   바닥에 닿으면 → 공 제거     SpriteKit 부분 상세  SpriteKit 부분은 이 프로젝트에서 그래픽과 물리 시뮬레이션을 담당하며, 주로 GameScene 클래스 내에서 구성됩니다. 각 구성 요소를 더 구체적으로 설명드리겠습니다.    🧱 GameScene 구성 요소 상세  📍 didMove(to:)  SpriteKit 장면이 화면에 처음 표시될 때 호출되는 메서드입니다. 여기서 물리 월드 설정과 플랫폼 배치를 합니다.  주요 구성:    physicsWorld.contactDelegate = self   → 물리 충돌 이벤트를 감지하기 위해 SKPhysicsContactDelegate 프로토콜을 채택하고, 해당 delegate를 자기 자신으로 지정합니다.    physicsBody = SKPhysicsBody(edgeLoopFrom: frame)   → 화면 전체를 테두리로 감싸는 물리 벽 생성. 공이 밖으로 나가지 않도록 함.    for i in 1...3 {     ...     addChild(plat)   }   → 경사진 3개의 플랫폼을 반복문으로 생성. 각 플랫폼은 SKShapeNode로 구성되고, 물리 바디가 설정됩니다.  각 플랫폼의 설정:  plat.physicsBody = SKPhysicsBody(rectangleOf: CGSize(width: 80, height: 10)) plat.physicsBody?.isDynamic = false plat.physicsBody?.affectedByGravity = false plat.physicsBody?.categoryBitMask = 2 plat.physicsBody?.contactTestBitMask = 2      isDynamic = false → 위치가 고정되어 물리 반응은 있지만, 움직이지 않음   categoryBitMask &amp; contactTestBitMask → 충돌 감지 대상 설정 (같은 그룹끼리 감지 가능)     📍 touchesBegan(_:with:)  사용자가 화면을 터치하면 호출되는 메서드입니다.     원형 SKShapeNode(box)를 생성   터치 위치에 배치   중력 영향을 받도록 설정 (affectedByGravity = true)   충돌 감지를 위해 물리 바디 설정   예:  let box = SKShapeNode(circleOfRadius: 5) box.physicsBody = SKPhysicsBody(circleOfRadius: 5) box.physicsBody?.affectedByGravity = true box.physicsBody?.categoryBitMask = 2 box.physicsBody?.contactTestBitMask = 2   이 공은 중력으로 낙하하며, platform과 category 설정이 같기 때문에 충돌 시 didBegin(_:) 호출됨.    📍 didBegin(_ contact: SKPhysicsContact)  SpriteKit의 충돌 이벤트가 발생했을 때 자동 호출되는 메서드입니다.     contact.bodyA와 contact.bodyB를 통해 어떤 노드끼리 충돌했는지 확인   충돌한 platform이 어떤 것인지에 따라 다른 MIDI 노트(60, 64, 67)를 재생   또한, 특정 노드가 바닥이나 화면 하단에 닿은 경우 제거 처리도 여기에 포함될 수 있습니다.    🎯 SpriteKit에서 이 예제가 하는 일 요약                 구성 요소       역할                       SKScene       물리 공간 (게임 보드 같은 역할)                 SKPhysicsWorld       중력과 충돌 계산 수행                 SKShapeNode       공 및 플랫폼 노드의 시각적 표현                 SKPhysicsBody       실제 물리 연산을 담당하는 요소                 categoryBitMask, contactTestBitMask       충돌 범주 정의 및 감지 설정                 touchesBegan       공 생성 및 사용자 입력 반응                 didBegin       충돌 시 사운드 재생 로직 실행            "
  },
  
  {
    "title": "AudioKit의 Recorder",
    "url": "/posts/Recorder/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-10 19:50:12 +0900",
    "content": "Recorder  이 Recorder.swift 파일은 AudioKit 기반의 녹음 및 재생 기능을 제공하는 SwiftUI 앱 모듈입니다. 주요 기능은 마이크 입력을 받아 녹음하고, 그 녹음 파일을 재생하는 것입니다. 전체 구조와 각 파트의 역할은 다음과 같습니다:    1. RecorderData 구조체  struct RecorderData {   var isRecording = false   var isPlaying = false }      @Published 데이터 모델로, 녹음 중인지(isRecording)와 재생 중인지(isPlaying)를 나타냅니다.     2. RecorderConductor 클래스  class RecorderConductor: ObservableObject, HasAudioEngine   AudioKit의 오디오 엔진과 노드를 제어하는 오디오 컨덕터 클래스입니다.  주요 멤버 변수     engine: AudioKit의 AudioEngine 인스턴스   recorder: 마이크 입력을 녹음하는 NodeRecorder   player: 녹음된 파일을 재생하는 AudioPlayer   silencer: Fader로, 입력 오디오를 음소거(0dB)하는 역할   mixer: 입력과 재생을 합쳐 최종 출력으로 내보내는 믹서   data 프로퍼티의 역할     data.isRecording이 true → 녹음 시작 (try recorder?.record())   false → 녹음 정지 (recorder?.stop())   data.isPlaying이 true → player.load(file:) 후 재생   false → 정지   init()     마이크 입력 노드를 받아 NodeRecorder, Fader, AudioPlayer, Mixer를 연결   Fader(gain: 0)를 통해 입력은 실제 출력에는 들리지 않게 처리됨 (무음)   노드 연결 상태  RecorderConductor 클래스 내 오디오 노드의 연결 상태는 다음과 같습니다:  [Microphone Input]        │        ▼     [Fader (gain: 0)]  (silencer, 실제 음은 꺼짐)        │        ▼     [Mixer] ◄──────── [AudioPlayer]  ← (녹음된 파일 재생)        │        ▼   [AudioEngine.output]   연결 흐름 요약     engine.input → NodeRecorder에 녹음   engine.input → Fader(gain: 0) → Mixer   AudioPlayer → Mixer   Mixer → engine.output   이 구조는 입력(마이크)은 녹음만 하고 출력에는 들리지 않도록 Fader(gain: 0)로 차단하며, 녹음된 파일만 AudioPlayer를 통해 재생되도록 설계된 것입니다.    3. RecorderView  struct RecorderView: View   구성 요소     버튼 1: \"RECORD\" 또는 \"STOP RECORDING\" (녹음 시작/중지)   버튼 2: \"PLAY\" 또는 \"STOP PLAYING\" (녹음 파일 재생/중지)   마이크 권한이 없을 경우 \"Mic permission required!\" 메시지 표시   마이크 권한 확인     requestMicrophonePermission { granted in ... }를 사용해 권한 요청 후 상태 갱신   프리뷰에서는 isPreview 조건으로 무시됨     기타 기능 및 고려 사항     Fader는 실제 녹음은 하되, 소리가 들리지 않도록 하기 위해 gain: 0으로 설정됨   녹음 파일은 NodeRecorder가 자동 저장   재생 시 player.load(file:)를 통해 그 파일을 다시 읽어옴   @StateObject로 RecorderConductor를 바인딩하여 UI와 연동     ✅ 요약                 구성 요소       역할                       RecorderConductor       AudioKit 오디오 녹음/재생 엔진 제어                 RecorderView       녹음/재생 UI 및 마이크 권한 처리                 Fader       입력 음소거 처리                 NodeRecorder       실시간 마이크 오디오를 파일로 녹음                 AudioPlayer       저장된 오디오 파일을 재생           이 코드는 간단한 마이크 녹음기 앱의 기초 구조를 담고 있으며, AudioKit을 활용한 신호 흐름과 SwiftUI의 상태 바인딩을 효과적으로 활용한 예시입니다. "
  },
  
  {
    "title": "랜덤 노이즈(random noise)란?",
    "url": "/posts/%EB%9E%9C%EB%8D%A4%EB%85%B8%EC%9D%B4%EC%A6%88/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-09 15:56:00 +0900",
    "content": "랜덤 노이즈  화이트 노이즈, 핑크 노이즈, 브라우니안(Brownian) 노이즈는 모두 스펙트럼 에너지 분포가 다른 랜덤 신호입니다. 이들은 소리의 특성과 에너지 분포를 다르게 하며, 오디오 테스트, 사운드 디자인, 백색소음 치료, 모듈레이션 등에 사용됩니다.  아래에 각각의 정의, 청각적 특징, 생성 방식(알고리즘)을 정리해 드리겠습니다.    1. 화이트 노이즈 (White Noise)  정의     모든 주파수 대역에 같은 에너지를 가지는 노이즈   스펙트럼 밀도: 0dB/옥타브   주파수당 에너지 분포가 균등함     청각적 특징     샤아아아아 소리 (TV 안테나 잡음과 유사)   고역이 강조되어 다소 날카롭게 들림   생성 방식  // 샘플마다 랜덤한 값을 생성 sample = Float.random(in: -1.0...1.0)      단순히 uniform 랜덤 값으로 오디오 버퍼를 채우면 됩니다.     2. 핑크 노이즈 🌸 (Pink Noise)  정의     주파수가 2배가 될수록 에너지가 절반으로 줄어듦   스펙트럼 밀도: -3dB/옥타브   인간 청각 특성에 더 자연스럽게 들리는 노이즈     청각적 특징     부드러운 바람소리, 빗소리와 유사   고역이 덜 강조됨   생성 방식          필터 방식:             화이트 노이즈 → 1/f 필터(로우패스 계열 필터)를 통과시켜 감쇠       예: IIR 필터나 FIR 필터 사용                Voss-McCartney 알고리즘:             여러 개의 서로 다른 주기에서 값을 바꾸는 난수 발생기       각 샘플마다 일부만 갱신하여 저역 강조됨                오디오키트 예시:      let pinkNoise = PinkNoise(amplitude: 0.5)      내부적으로는 고역을 점차 감쇠시키는 방식 사용     3. 브라우니안 노이즈 (Brown Noise = Brownian, 적색 노이즈)  정의     주파수 증가에 따라 에너지가 급격히 감소   스펙트럼 밀도: -6dB/옥타브   Brownian motion(브라운 운동)의 누적 효과와 유사     청각적 특징     무거운 저음 중심, 폭풍 소리 느낌   고역 거의 없음   생성 방식  // 이전 샘플값에 현재 난수값을 누적 var lastSample = 0.0 let currentSample = lastSample + Double.random(in: -0.05...0.05) lastSample = currentSample      즉, 화이트 노이즈를 적분한 형태 → 신호가 누적되면서 저역 성분이 강해짐     요약 비교                 구분       에너지 분포       청각 특징       생성 방식 요약                       화이트 노이즈       평탄(0dB/옥타브)       샤아아, 고역 많음       random(-1...1)                 핑크 노이즈       -3dB/옥타브 감소       자연음에 가까움       필터 or Voss-McCartney                 브라운 노이즈       -6dB/옥타브 감소       무겁고 둔탁한 저음       누적형: y[n] = y[n-1] + rand            "
  },
  
  {
    "title": "AudioKit의 MusicToy",
    "url": "/posts/MusicToy/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-08 14:49:13 +0900",
    "content": "Music Toy  이 MusicToy.swift 코드는 AudioKit 기반의 음악 장난감 앱 예제입니다. 사용자가 사운드를 선택하고 템포, 필터, 볼륨 등을 조절하여 아르페지오, 코드, 베이스, 드럼 사운드를 재생할 수 있는 인터랙티브한 SwiftUI 앱입니다. 아래에 전체적인 구조와 핵심 내용을 구조별로 정리해드리겠습니다.    ✅ 전체 구조 요약                 구성       내용                       MusicToyData       사용자 조작에 따라 변하는 상태값(볼륨, 사운드 종류, 필터 등)을 저장하는 모델                 MusicToyConductor       AudioKit 엔진 및 시퀀서/샘플러/필터를 구성하고 상태 변경 시 반응하여 오디오 처리                 MusicToyView       SwiftUI 뷰. UI 컨트롤(버튼, 피커, 노브)을 통해 사용자 입력을 받고 MusicToyData에 반영             📦 1. MusicToyData  struct MusicToyData {   var isPlaying: Bool = false   var bassSound: Sound = .square   ...   var filterFrequency: Float = 1.0   var length: Int = 4 }      사용자 설정값을 저장하는 모델 구조체입니다.   SwiftUI 뷰의 바인딩에 사용되며, 값이 변경되면 MusicToyConductor에서 오디오 설정을 업데이트합니다.   Sound는 square, saw, pad, noisy 타입이며, 이는 .exs 사운드폰트 파일로 연결됩니다.     🎛️ 2. MusicToyConductor: 오디오 처리 담당  핵심 요소  var engine = AudioEngine() var sequencer: AppleSequencer! var arpeggioSynth = MIDISampler() var padSynth = MIDISampler() var bassSynth = MIDISampler() var drumKit = MIDISampler() var filter: MoogLadder?      AudioKit의 주요 컴포넌트들을 선언   filter = MoogLadder(mixer)를 통해 모든 사운드를 하나의 믹서로 묶고, Moog 스타일 필터를 걸어 출력   초기화  useSound(.square, synth: .arpeggio) useSound(.saw, synth: .pad) useSound(.saw, synth: .bass)      처음에는 정해진 사운드로 초기화   드럼은 drumSimp.exs 사운드폰트 로딩   시퀀서 설정  sequencer = AppleSequencer(fromURL: demoMIDIURL) sequencer.enableLooping() sequencer.tracks[1].setMIDIOutput(arpeggioSynth.midiIn) ...      MIDI 파일을 불러와서 각각의 트랙을 해당 샘플러와 연결   상태 동기화  @Published var data = MusicToyData() {   didSet {     updateSounds()   } }      data 값이 바뀌면 updateSounds() 호출됨   음색, 볼륨, 필터, 템포 등 변경 사항을 반영   주요 메서드     adjustFilterFrequency(_:): 필터 컷오프 주파수를 0.0 ~ 1.0 → 30Hz ~ 20kHz로 변환해 설정   adjustVolume(_:instrument:): 각 악기의 볼륨 설정   setLength(_:): 루프 길이 변경   useSound(_:synth:): .exs 사운드폰트 파일을 샘플러에 로딩     🎹 3. MusicToyView: 사용자 인터페이스     SwiftUI 기반의 컨트롤들을 통해 사용자 입력을 받음   값은 conductor.data에 바인딩되어 즉시 반영됨   상단 제어     isPlaying: Play / Stop 버튼으로 시퀀서 재생 제어   rewindSequence(): 되감기   length: 루프 길이(박자 수)   중간 제어     CookbookKnob: 템포, 필터 주파수 노브   사운드 선택 Picker: 아르페지오, 코드, 베이스 음색   하단 제어     각 악기 볼륨을 0.5~1.0 범위에서 조절 가능     🎵 예시 사용 흐름          사용자가 Tempo 노브를 140으로 돌리면:             data.tempo 변경       adjustTempo(140) 호출 → 시퀀서 템포 갱신                아르페지오 음색을 .saw로 선택하면:             .exs 사운드파일 로딩 (useSound)                필터 주파수를 0.2로 내리면:             30Hz~20000Hz 범위 중 저역에 가까운 주파수가 선택되어 고역이 감쇠됨             🧠 기술적 특징 요약                 기술 요소       설명                       AudioKit       오디오 처리 전반 (시퀀서, 필터, 샘플러, 믹서)                 MoogLadder       고품질 아날로그 시뮬레이션 필터                 .denormalized(to:taper:)       0.0~1.0 값을 로그 스케일로 주파수로 변환                 AppleSequencer       MIDI 기반 시퀀서로 루프, 재생 가능                 SwiftUI @StateObject + @Published       UI ↔ AudioKit 상태 양방향 연동            "
  },
  
  {
    "title": "CutOff(컷오프) 주파수란?",
    "url": "/posts/CutOff%EC%A3%BC%ED%8C%8C%EC%88%98/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-08 14:01:23 +0900",
    "content": "CutOff Frequency  컷오프 주파수(Cutoff Frequency)란, 오디오 필터가 신호를 걸러내기 시작하는 주파수의 경계점을 의미합니다.   설명  🎧 예를 들어 설명하면:  ✅ 로우패스 필터(Low-pass filter)의 경우:     컷오프 주파수 이하의 저주파 성분은 통과   컷오프 주파수 이상의 고주파 성분은 감쇠 또는 제거   즉, 컷오프 주파수가 5,000Hz면 → 5kHz보다 낮은 음은 통과시키고, 높은 음은 줄이거나 제거합니다.    📈 컷오프 주파수의 수치 범위  음향에서 일반적인 컷오프 주파수 범위는 다음과 같습니다:     20Hz ~ 20,000Hz (20kHz) → 인간의 청각 범위 전체   예: 30...20000 Hz 라고 쓰면 → 30Hz 이하나 20kHz 이상은 거의 모두 걸러짐     📌 왜 조정하나?  필터의 **톤(tone)**을 바꾸기 위해서입니다.     컷오프를 낮추면 → 소리가 더 어두워짐   컷오프를 높이면 → 고음이 살아남아 밝은 소리     예제: 정규화된 Frequency가 0.8 → 0.2로 줄어들면?  frequency.denormalized(to: 30...20000, taper: 3)에서 frequency가 0.8 → 0.2로 줄어들면, 다음과 같은 의미입니다:     0.8은 상대적으로 높은 컷오프 주파수 → 예: 약 12,000Hz 근처   0.2는 상대적으로 낮은 컷오프 주파수 → 예: 약 100~200Hz 근처   즉, denormalized는 0.0~1.0 사이의 정규화된 값을 로그 스케일로 30Hz~20000Hz 범위에 매핑해주는 함수입니다.    대략적인 값 예시 (taper: 3 기준, 로그 스케일):                 정규화 값       컷오프 주파수 (예상값)                       0.0       30 Hz                 0.2       약 120~200 Hz                 0.5       약 1,000 Hz                 0.8       약 12,000 Hz                 1.0       20,000 Hz           따라서 → 0.8 → 0.2로 바꾸면 → 컷오프 주파수는 약 12,000Hz → 200Hz로 급격히 낮아지며, → 소리가 어두워지고 고음이 잘려나가며 묵직해지는 느낌이 납니다.    denormalized(to:taper:)는 AudioKit에서 사용하는 보간 함수로, 0.0~1.0 값을 실사용 주파수로 비선형(log taper) 변환할 때 사용됩니다.    Log Taper란?  **Log taper(로그 테이퍼)**는 값의 변화가 로그함수 곡선처럼 느리게 시작하고 점점 빠르게 증가하는 방식의 곡선을 말합니다.    🎛 왜 log taper를 쓰나?  ✅ 사람의 귀는 소리의 변화를 **선형(linear)**이 아닌 로그(logarithmic) 방식으로 인식하기 때문입니다.     예: 주파수 100Hz → 200Hz는 큰 차이로 느껴지고 10,000Hz → 10,100Hz는 거의 차이 없음     📈 log taper vs. linear taper                 입력 값       Linear 결과       Log taper 결과 (예시)                       0.0       30 Hz       30 Hz                 0.25       5087 Hz       250 Hz                 0.5       10,015 Hz       1000 Hz                 0.75       14,972 Hz       5000 Hz                 1.0       20,000 Hz       20,000 Hz              Linear: 중간값도 10,000Hz 근처 (느끼기엔 대부분 고음만 변함)   Log: 중간값이 1,000Hz로, 사람 귀에 더 자연스럽고 유효한 조절 가능     🎚 실제 적용 예     EQ(이퀄라이저)의 컷오프 주파수 노브   디지털 신디사이저의 파라미터 슬라이더   UI 슬라이더 값 → 실 주파수/볼륨 매핑 등     Swift에서 taper가 적용된 예  value.denormalized(to: 30...20000, taper: 3)      taper: 1 → linear   taper: &gt;1 → log taper (ex: 3이면 더 강한 곡선)     아래는 **정규화된 값(0.0~1.0)**을 기준으로 한 log taper 와 linear taper의 대략적인 비교 그래프입니다. 가로축은 입력값 (x: 0.0 ~ 1.0), 세로축은 실제 주파수 출력 (y: 30Hz ~ 20000Hz)입니다.  y ↑ │ log taper       ◉ │               ◉ │             ◉ │           ◉ │         ◉ │       ◉ │    ◉ │ ◉ │ │ │ ◉  ◉  ◉  ◉  ◉  ◉  ◉  ◉  ◉◉◉◉  linear taper └──────────────────────────────→ x   0.0       0.5       1.0   📊 해석:     Linear taper는 일정하게 증가 → 대부분 고음에서만 세밀 조절 가능   Log taper는 저역에서 더 섬세하게 조절 가능 → 사람이 듣기에 더 자연스럽고 유용   예를 들어 0.2, 0.4, 0.6, 0.8 정규화 값을 넣었을 때:                 입력값 (x)       Linear (Hz)       Log Taper (Hz, taper:3)                       0.2       ~4026       ~100                 0.4       ~8011       ~500                 0.6       ~11996       ~2000                 0.8       ~15981       ~7000             요약하자면, log taper는 사람의 감각에 맞춘 비선형 조절 방식이며, 보통 UI 슬라이더나 오디오 파라미터에서는 log taper를 사용합니다.   "
  },
  
  {
    "title": "AudioKit의 MIDIMonitor",
    "url": "/posts/MIDIMonitor/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-06 16:18:38 +0900",
    "content": "MIDI Monitor  이 MIDIMonitor.swift 파일은 SwiftUI 기반의 MIDI 모니터 도구입니다. MIDI 장치로부터 수신된 이벤트들을 실시간으로 감지하고 UI로 표시하는 역할을 합니다. AudioKit, SwiftUI, CoreMIDI를 활용하며, 사용자가 MIDI 장치의 입력을 확인하고 디버깅할 수 있도록 돕습니다.    🔧 주요 구조 설명  1. MIDIMonitorData 구조체  struct MIDIMonitorData {   var noteOn, velocity, noteOff, channel, afterTouch, afterTouchNoteNumber, programChange, pitchWheelValue, controllerNumber, controllerValue: Int }      각종 MIDI 이벤트 값을 저장하는 데이터 구조입니다.   @Published로 선언되어 View에서 실시간 바인딩됩니다.     2. MIDIMonitorConductor 클래스  ObservableObject를 채택한 ViewModel 역할의 클래스입니다.  주요 프로퍼티     midi: AudioKit의 MIDI 인터페이스 객체   data: MIDI 이벤트 데이터   isShowingMIDIReceived: MIDI 입력을 수신 중일 때 indicator 표시 여부   isToggleOn: CC 값이 127일 때 on 상태 (ex. 토글 스위치 UI용)   midiEventType: 이벤트 구분용 열거형   주요 메서드     start(): MIDI 입력 포트 열고 리스너 등록   stop(): MIDI 포트 닫기     3. MIDI 이벤트 수신 핸들러 (MIDIListener 구현)  AudioKit의 MIDIListener 프로토콜을 구현하여 다음 이벤트들을 처리합니다:  📌 receivedMIDINoteOn / receivedMIDINoteOff     노트 번호, 벨로시티, 채널을 추출해 데이터 갱신   벨로시티가 0일 경우 Note Off처럼 취급하여 isShowingMIDIReceived = false   📌 receivedMIDIController  if value == 127 {   self.isToggleOn = true } else {   self.isToggleOn = false }      CC 메시지 수신 시 컨트롤러 번호와 값 저장   value == 127이면 isToggleOn을 켜서 UI에 표시 (ex. 이펙터 스위치처럼 on/off 토글용)   📌 기타 이벤트     Program Change, Pitch Wheel, Aftertouch 등도 모두 개별적으로 처리하여 데이터를 반영     4. MIDIMonitorView 뷰     MIDIMonitorConductor를 @StateObject로 사용   수신된 MIDI 이벤트를 List의 Section으로 구분하여 표시   상단에 MIDI 입력 상태와 토글 여부를 나타내는 원형 인디케이터(Circle) 표시   인디케이터 예:  Circle()   .fill(conductor.isShowingMIDIReceived ? mainTintColor : mainTintColor.opacity(0.2))     🧪 특징 및 활용 예시     드럼패드를 누르면 Note On 이벤트 → 인디케이터 반응   노브를 돌리면 CC 메시지 → 컨트롤러 번호와 값 갱신   이펙터 on/off처럼 CC 값이 127 → isToggleOn = true로 빨간 불 표시    "
  },
  
  {
    "title": "AudioKit의 NodeParameter 예제",
    "url": "/posts/NodeParameter_%EC%98%88%EC%A0%9C/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-05 18:20:00 +0900",
    "content": "NodeParameter 예제            Master Volume             전체 소리의 출력 볼륨을 조절합니다.       값이 크면 소리가 커지고, 값이 작으면 소리가 작아집니다.                Pitch bend (semitones)             피치 벤드 휠로 조절할 수 있는 음의 최대 변화 폭을 설정합니다.       값이 크면 더 넓은 음정 변화가 가능하고, 값이 작으면 변화 범위가 좁아집니다.                Vibrato Depth             음정의 진동(비브라토) 강도를 설정합니다.       값이 크면 음이 크게 흔들리고, 값이 작으면 거의 흔들림이 없습니다.                Vibrato Speed (Hz)             진동의 속도를 설정합니다.       값이 크면 빠르게 흔들리고, 값이 작으면 느리게 흔들립니다.                Filter Resonance             컷오프 주파수 주변을 강조합니다.       값이 크면 날카롭고 공명감 있는 소리가 나고, 값이 작으면 부드럽고 평탄한 소리가 납니다.                Glide rate (sec/octave)             음과 음 사이의 포르타멘토(부드러운 피치 이동) 속도를 조절합니다.       값이 크면 음과 음 사이가 천천히 연결되고, 값이 작으면 거의 즉시 전환됩니다.                Attack Duration (s)             소리가 시작된 후 최대로 도달하는 데 걸리는 시간을 설정합니다.       값이 크면 소리가 천천히 올라오고, 값이 작으면 즉시 소리가 납니다.                Hold Duration (s)             Attack 이후 최대 레벨을 유지하는 시간을 설정합니다.       값이 크면 일정 시간 머무르고, 값이 작으면 곧바로 Decay로 넘어갑니다.                Voice Vibrato (semitones)             음정에 적용되는 진동의 깊이를 설정합니다.       값이 크면 음정이 넓게 흔들리고, 값이 작으면 거의 흔들리지 않습니다.                Decay Duration (s)             Attack 이후 Sustain 레벨까지 내려가는 데 걸리는 시간입니다.       값이 크면 천천히 줄어들고, 값이 작으면 빠르게 줄어듭니다.                Voice Vibrato speed (Hz)             음정 진동의 속도를 조절합니다.       값이 크면 빠르게 흔들리고, 값이 작으면 느리게 흔들립니다.                Filter Cutoff             필터가 통과시키는 주파수의 경계점을 설정합니다.       값이 크면 밝고 높은 음이 많이 통과하고, 값이 작으면 어두운 저음만 통과합니다.                Filter Strength             필터에 적용되는 모듈레이션의 강도를 설정합니다.       값이 크면 필터 변화가 크게 적용되고, 값이 작으면 거의 영향을 받지 않습니다.                Sustain Level             키를 누르고 있는 동안 유지되는 소리의 레벨입니다.       값이 크면 소리가 길게 유지되고, 값이 작으면 빠르게 사라집니다.                Release Duration (s)             키를 뗀 이후 소리가 완전히 사라지는 데 걸리는 시간입니다.       값이 크면 소리가 천천히 사라지고, 값이 작으면 즉시 사라집니다.                Filter Attack Duration (s)             필터 컷오프가 상승하는 데 걸리는 시간입니다.       값이 크면 점진적으로 변화하고, 값이 작으면 즉시 적용됩니다.                Filter Decay Duration (s)             필터 컷오프가 Attack 후 줄어드는 데 걸리는 시간입니다.       값이 크면 천천히 줄어들고, 값이 작으면 빠르게 줄어듭니다.                Filter Sustain Level             필터의 컷오프가 지속적으로 유지되는 레벨입니다.       값이 크면 밝은 음색이 유지되고, 값이 작으면 어두운 음색이 유지됩니다.                Filter Release Duration (s)             필터 컷오프가 키 릴리즈 후 원위치로 돌아가는 시간입니다.       값이 크면 천천히 변화하고, 값이 작으면 즉시 사라집니다.                Pitch Attack Duration (s)             음정이 시작 시 변하는 속도를 조절합니다.       값이 크면 피치가 천천히 상승하고, 값이 작으면 즉시 목표 피치에 도달합니다.                Pitch Decay Duration (s)             피치가 Attack 후 목표 값으로 줄어드는 시간입니다.       값이 크면 천천히 줄어들고, 값이 작으면 빠르게 줄어듭니다.                Pitch Sustain Level             피치가 유지되는 값입니다.       값이 크면 피치가 유지되고, 값이 작으면 유지되지 않습니다.                Pitch Release Duration (s)             키를 뗀 후 피치가 원래 값으로 돌아가는 데 걸리는 시간입니다.       값이 크면 천천히 되돌아가고, 값이 작으면 바로 되돌아갑니다.                Pitch EG Amount duration (semitones)             피치에 적용되는 Envelope의 세기입니다.       값이 크면 음정 변동 폭이 커지고, 값이 작으면 변동이 거의 없습니다.                isLegato             레가토(부드럽게 연결된 연주)를 활성화합니다.       값이 크면 음들이 부드럽게 연결되고, 값이 작으면 각 음이 분리되어 들립니다.                Key Tracking             키 높이에 따라 필터 컷오프를 조절합니다.       값이 크면 높은 음일수록 컷오프가 높아지고, 값이 작으면 변화가 없습니다.                Filter Envelope Scaling             필터에 대한 Envelope의 전체 영향을 조절합니다.       값이 크면 Envelope 효과가 크게 적용되고, 값이 작으면 거의 적용되지 않습니다.                restartVoiceLFO             음을 누를 때마다 LFO를 다시 시작할지를 설정합니다.       값이 크면 항상 처음부터 시작되고, 값이 작으면 이전 상태를 유지합니다.                Filter Enable             필터 기능을 켜거나 끕니다.       값이 크면 필터가 적용되고, 값이 작으면 필터가 적용되지 않습니다.                loopThruRelease             Release 중에도 루프가 유지될지를 설정합니다.       값이 크면 릴리즈 동안도 루프가 계속되고, 값이 작으면 릴리즈에서 루프가 멈춥니다.                isMonophonic             모노포닉(한 음만 연주 가능) 모드를 설정합니다.       값이 크면 한 번에 한 음만 연주되고, 값이 작으면 여러 음을 동시에 연주할 수 있습니다.             "
  },
  
  {
    "title": "SFZ 포맷이란?",
    "url": "/posts/SFZ_%ED%8F%AC%EB%A7%B7/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-05 18:12:08 +0900",
    "content": "SFZ 포맷  SFZ 파일은 가상 악기용 샘플 기반 음원을 정의하는 텍스트 기반 포맷입니다. 주로 **샘플러(VSTi 등)**에서 다양한 악기 소리를 재생하기 위해 사용됩니다.    🔍 SFZ란?     확장자: .sfz   형식: 텍스트(ASCII)   역할: 오디오 샘플(WAV 등)의 배치/맵핑 정보를 정의   개발자: Cakewalk (RGC:audio)     🎵 어떻게 동작하나요?     여러 개의 WAV 샘플이 있음 (예: 각 음정별로 녹음된 피아노 소리).   sound.sfz 파일에서 각 샘플을 어떤 음정, 어떤 속도, 어떤 벨로시티에서 재생할지를 정의.   샘플러(예: Sforzando, ARIA, Kontakt 등)가 .sfz를 읽어 악기처럼 재생.   예시:  &lt;region&gt; sample=note_C4.wav lokey=60 hikey=60 pitch_keycenter=60   이건 C4(MIDI 60)에서만 note_C4.wav 샘플이 재생되도록 설정한 예입니다.    📌 SFZ의 특징                 장점       단점                       텍스트 기반으로 가볍고 수정 쉬움       GUI 지원 부족 (직접 코딩해야 함)                 무료 사용 및 확장 용이       복잡한 기능은 표현에 제약이 있음                 다양한 무료/유료 라이브러리 존재       제작 시 구조를 잘 이해해야 함             🔧 어디에 쓰이나요?     디지털 오디오 워크스테이션(DAW)에서 가상악기 로딩   무료/오픈소스 샘플러에서 악기 정의   게임 사운드 또는 개인 음악 제작용     🧾 코드 예제  &lt;group&gt;lokey=0 hikey=127 pitch_keycenter=57 pitch_keytrack=100 &lt;region&gt;lovel=000 hivel=127 amp_velcurve_127=1 loop_mode=loop_continuous loop_start=0 loop_end=220 sample=basicSamples/saw220.wav     🔍 해설  1. &lt;group&gt; 라인  &lt;group&gt;lokey=0 hikey=127 pitch_keycenter=57 pitch_keytrack=100      &lt;group&gt;: 이 뒤에 오는 &lt;region&gt;들에 공통으로 적용될 설정을 정의합니다.   lokey=0: 이 그룹의 음역 최소값은 MIDI 키 0 (C-1)입니다.   hikey=127: 최대값은 MIDI 키 127 (G9)입니다. → 모든 건반에 적용됨   pitch_keycenter=57: 이 샘플의 기준 피치는 MIDI 57 (A3)입니다.   pitch_keytrack=100: 피치 트래킹 100% → 누르는 키에 따라 정확히 해당 음정으로 피치 변경됩니다.     2. &lt;region&gt; 라인  &lt;region&gt;lovel=000 hivel=127 amp_velcurve_127=1 loop_mode=loop_continuous loop_start=0 loop_end=220 sample=basicSamples/saw220.wav      &lt;region&gt;: 실제 샘플을 매핑하는 설정입니다.   lovel=000 / hivel=127: 이 region은 모든 velocity(세기) 구간(0~127)에서 작동합니다.   amp_velcurve_127=1: velocity가 127일 때는 **볼륨 1.0(최대)**로 재생됩니다. → velocity에 따른 볼륨 곡선을 정의하는 파라미터.   loop_mode=loop_continuous: 샘플을 끝없이 루프 재생합니다.   loop_start=0 / loop_end=220: 0프레임부터 220프레임까지 루프합니다. → wav 파일 내에서 해당 영역이 반복됨.   sample=basicSamples/saw220.wav: 실제 재생할 샘플 파일 경로입니다. → basicSamples 폴더에 있는 saw220.wav라는 웨이브 파일 사용.     🎹 결과적으로 어떤 소리가 나나요?     사용자가 어떤 키를 누르든 (0~127), 어떤 velocity로 누르든 (0~127)   saw220.wav 파일이 기준음 A3로 pitch-shift 되어 재생됨.   소리는 0~220 프레임 사이를 무한 루프하며 지속됨.   velocity가 클수록 소리 크기는 커짐 (최대 127에서 1.0)    "
  },
  
  {
    "title": "EQ(이퀄라이저) 중심주파수 대역폭",
    "url": "/posts/EQ-%EC%A4%91%EC%8B%AC%EC%A3%BC%ED%8C%8C%EC%88%98_%EB%8C%80%EC%97%AD%ED%8F%AD/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-03 19:10:04 +0900",
    "content": "중심 주파수, 대역폭의 의미  **“중심 주파수(center frequency)가 32Hz이고, 대역폭(bandwidth)이 44.7Hz”**라는 말은, 해당 필터가 32Hz를 중심으로 한 주파수 범위에 영향을 미친다는 뜻입니다. 하지만 단순히 *“32 ± 44.7Hz”*와 같이 생각하면 안 됩니다. 이건 필터의 종류와 정의 방식에 따라 달라지기 때문입니다.    🎧 정확한 의미 요약  ✅ AudioKit의 EqualizerFilter에서의 bandwidth는 대역폭(Hz)     중심 주파수 f₀ = 32Hz   대역폭 BW = 44.7Hz   이때 필터는 다음과 같은 주파수 대역에 영향을 줍니다:  대략적으로: 32Hz ± (44.7Hz / 2) = 9.65Hz ~ 54.35Hz   즉, 필터는 약 9.65Hz부터 54.35Hz까지의 대역을 부스트 또는 컷하게 됩니다.     정확히 말하자면 “bandwidth”는 필터의 -3dB 지점 간 거리를 의미하며, 중심 주파수를 기준으로 그 좌우에 걸친 대역입니다.     📊 시각적 비유      Gain       ▲       │        _______       │       /       \\       │      /         \\       │_____/           \\______             |           |           (f₁)         (f₂)          9.65Hz       54.35Hz           ←  BW = 44.7Hz →             Center: 32Hz     ✅ 보충 설명: 필터 종류별 해석 차이                 필터 종류       bandwidth 의미                       Peak EQ (Bell)       중심 주파수 기준 -3dB 지점 간 거리                 Bandpass       허용 주파수 범위 (통과 영역)                 Shelf       대역폭이 아닌 경사만 조절              AudioKit의 EqualizerFilter는 내부적으로 bell 또는 band-pass EQ 구조를 사용하므로 위 해석이 적용됩니다.     -3dB의 의미  -3dB가 사용되는 이유는 오디오 및 신호 처리에서 전력(power) 기준으로 절반이 되는 지점을 의미하기 때문입니다. 이 기준은 필터의 대역폭, 컷오프, 주파수 응답의 경계 등을 정의할 때 표준적인 기준점으로 널리 사용됩니다.    📐 왜 -3dB인가?  오디오 필터의 주파수 응답에서:     0dB는 신호 감쇠(또는 증폭) 없이 통과됨을 의미합니다.   -3dB는 신호의 **전력(Power)**이 절반으로 줄어든 상태를 뜻합니다.   수식적으로 보면:  디시벨(dB)은 전력 비율일 때:  $$ \text{dB} = 10 "
  },
  
  {
    "title": "AudioKit의 GraphicEqualizer",
    "url": "/posts/GraphicEqualizer/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-03 18:58:01 +0900",
    "content": "Graphic Equalizer    ✅ 전체 구조 요약  이 코드는 SwiftUI + AudioKit 기반의 6밴드 그래픽 이퀄라이저 구현입니다. 사용자가 각 주파수 대역의 Gain을 조정하면, 해당 대역의 오디오 출력에 실시간으로 반영됩니다.    1. GraphicEqualizerData  struct GraphicEqualizerData {   private var gains: [AUValue] = Array(repeating: 1.0, count: 6)      subscript(_ index: Int) -&gt; AUValue {     get {       1...6 ~= index ? gains[index - 1] : 0     }     set {       1...6 ~= index ? gains[index - 1] = newValue : nil     }   } }      gains[0]부터 gains[5]까지 6개 EQ 밴드의 Gain을 저장   외부에서는 data[1] ~ data[6]으로 접근할 수 있도록 subscript 정의   UI 바인딩 및 필터 Gain 반영에 사용됨     2. GraphicEqualizerConductor – 음향 처리 흐름 설명  🔊 오디오 구성 요소  let engine = AudioEngine() let player = AudioPlayer() let fader: Fader var filterBands: [EqualizerFilter] = []      player: 미리 정의된 오디오 버퍼(Cookbook.sourceBuffer)를 재생   EqualizerFilter: 오디오 필터 체인을 구성 (6개 밴드)   fader: 전체 볼륨 조절   engine.output = fader: 전체 오디오 출력은 fader를 거쳐 출력됨     🧠 필터 체인 구성  let centerFrequencies: [AUValue] = [32, 64, 125, 250, 500, 1_000] let bandwidths: [AUValue] = [44.7, 70.8, 141, 282, 562, 1_112]     각 필터는 센터 주파수와 대역폭을 기반으로 설정됩니다.   centerFrequencies는 각 밴드의 주파수를 정의하며, bandwidths는 필터의 대역폭을 설정합니다.            대역폭이 넓으면 필터의 효과가 넓은 범위에 걸쳐 적용되며, 좁으면 그 범위가 좁아집니다.           🎧 필터밴드 연결 과정  filterBands.append(EqualizerFilter(player)) // dummy index 0  for i in 1...6 {   filterBands.append(     EqualizerFilter(       i == 1 ? player : filterBands[i - 1],       centerFrequency: centerFrequencies[i - 1],       bandwidth: bandwidths[i - 1],       gain: 1.0     )   ) }      EqualizerFilter는 대역 통과 필터입니다. 각 필터는 특정 중심 주파수(centerFrequency)와 대역폭(bandwidth)에 대해 설정됩니다.        Signal Chain:             player → band1 → band2 → ... → band6 → fader → engine.output       순차적으로 필터들이 연결되며, 각 밴드의 gain을 조절해 해당 주파수 대역을 증폭 또는 감쇠합니다.              🎵 예: Band 1은 32Hz 중심의 저주파 필터이며, Band 6은 1kHz 중심의 중고역대 필터입니다.     🎚 실시간 Gain 반영  @Published var data = GraphicEqualizerData() {   didSet {     for i in 1...6 {       filterBands[i].gain = data[i]     }   } }      SwiftUI에서 사용자가 Knob을 통해 gain을 조절하면 data[i] 값이 바뀌고, filterBands[i].gain이 즉시 반영되어 실시간 EQ 처리가 됩니다.     🔈 Fader 및 출력  fader = Fader(filterBands[6], gain: 0.4) engine.output = fader      마지막 필터의 출력을 fader로 감싸 전체 볼륨 조절   이로써 전체 EQ 적용 후 출력이 엔진의 최종 출력이 됩니다     3. GraphicEqualizerView  ForEach(1...6, id: \\.self) { index in   CookbookKnob(text: \"Band \\(index)\", parameter: $conductor.data[index], range: 0...20) }      SwiftUI의 노브 컴포넌트를 통해 사용자가 6개 밴드의 Gain을 조절 가능   @StateObject로 conductor를 관리하여 실시간 반영   하단에는 FFTView를 통해 실시간 주파수 응답을 시각화함     음향적 측면에서의 동작  이 코드는 6개의 주파수 대역에 대해 각각 독립적인 gain 값을 설정하여, 입력된 오디오 신호를 주파수 대역별로 필터링하고 조절할 수 있게 해줍니다.     각 EqualizerFilter는 주파수 대역을 중심으로 신호를 처리하고, 대역폭에 따라 필터의 적용 범위가 다르게 됩니다. 즉, 특정 주파수 대역을 강조하거나 감소시킬 수 있습니다.   gain 값은 각 대역에 대한 강조(증가) 또는 감소를 제어합니다. 예를 들어, 32Hz 대역의 gain을 증가시키면 저주파가 강조되며, 1kHz 대역의 gain을 증가시키면 중고주파 대역이 강조됩니다.   **볼륨 조절기(Fader)**는 필터 체인 후의 출력을 제어하여, 최종적으로 전체 오디오의 볼륨을 조정합니다.   최종적으로, 이 코드의 음향적 효과는 주파수 대역별로 오디오를 조정하고, 최종 출력을 볼륨 수준에서 관리하는 것입니다. 각 밴드의 gain을 변경하여 음성이나 음악의 특성을 세밀하게 조정할 수 있습니다.    🎛 음향적 효과 요약                 밴드       중심 주파수 (Hz)       대역폭       용도 예시                       1       32       44.7       저음 (킥, 베이스의 깊은 저역)                 2       64       70.8       저음 (베이스, 킥 드럼)                 3       125       141       저중역 (스네어 바디, 저보컬)                 4       250       282       중역 (보컬, 기타 본체)                 5       500       562       중고역 (현악기, 밝기)                 6       1,000       1,112       고역 (하이햇, 심벌, 샤프한 소리)              각 밴드는 다른 악기나 성분을 강조/감쇠하기 위한 대역입니다.   주파수 응답 조절로 음색을 커스터마이징할 수 있습니다.  "
  },
  
  {
    "title": "AudioKit의 DrumSynthesizers",
    "url": "/posts/DrumSynthesizers/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-02 20:20:24 +0900",
    "content": "Drum Synthesizers    클래스 개요  이 클래스는 AudioKit 기반의 킥/스네어 드럼 신스 루프를 생성하고 반복 재생하는 미니 드럼 머신입니다.    주요 멤버 구성                 속성명       설명                       engine       AudioEngine 인스턴스. 오디오 처리의 핵심 엔진                 kick, snare       각각 킥과 스네어 드럼 사운드를 생성하는 신스 객체                 reverb       믹서 출력에 리버브 효과 추가                 counter       현재 루프 반복 횟수 (비트 단위로 증가)                 bpm       현재 템포 (기본: 120 BPM)                 loop       CallbackLoop 객체. 지정된 frequency(Hz)로 콜백 실행                 isRunning       재생 여부 (true일 때 루프 시작, false일 때 정지)             loop 정의  CallbackLoop(frequency: bpm / 60 * 4)      bpm / 60 → 초당 박자 수 (beats per second)        × 4 → 16분음표 단위 실행을 위해 한 박자를 4개로 나눔             예: BPM이 120이면 120 / 60 * 4 = 8Hz, 즉 0.125초마다 실행             루프 내부 동작  루프는 약 0.125초마다 실행되며, 매 반복마다 다음을 수행합니다:                 조건       설명       동작                       counter % 4 == 0       1박자마다       킥 드럼 실행                 counter % 8 == 0       2박자마다       스네어 드럼 실행                 counter % 2 == 0 &amp;&amp; random == 0       랜덤 킥 추가 (25%)       킥 드럼 실행 가능성 추가                 counter += 1       매 반복마다 1 증가       박자 흐름 추적용              → 16분음표 단위로 루프가 반복되며, 4개마다 1박자로 계산됨 (즉, 4로 나눈 나머지를 통해 박자 추적)     🎛️ isRunning  @Published var isRunning = false {   didSet {     isRunning ? loop.start() : loop.stop()   } }      이 프로퍼티를 통해 외부에서 루프의 시작/정지를 트리거할 수 있음 (예: 버튼 바인딩)     init()  let mixer = Mixer(kick, snare) reverb = Reverb(mixer) engine.output = reverb      킥과 스네어를 믹싱 후 리버브를 거쳐 최종 출력   engine.output에 연결되어 실제 소리가 나도록 설정     BPM으로부터 Frequency(Hz) 도출  CallbackLoop(frequency:)에 전달하는 frequency(Hz) 는 1초에 몇 번 콜백할지를 의미합니다. 이걸 BPM과 리듬 단위로 바꾸려면 다음 공식을 사용할 수 있습니다:    공식  frequency = (BPM / 60) × 분기 단위 비율   예를 들어:                 리듬 단위       분기 단위 비율                       4분음표마다       1                 8분음표마다       2                 16분음표마다       4                 32분음표마다       8             예시: BPM 90에서 16분음표 단위로 루프 돌리기  frequency = (90 / 60) × 4 = 6   → CallbackLoop(frequency: 6) 으로 설정    일반화 함수  func frequency(for bpm: Double, division: Int) -&gt; Double {   return (bpm / 60.0) * Double(division) }      division: 1 = 4분음표, 2 = 8분음표, 4 = 16분음표 …     요약     120 BPM 기준 16분음표 단위 루프 (0.125초마다 실행)   kick: 매 박자마다 + 25% 확률로 중간에 추가   snare: 두 박자마다 (4박 기준으로 2, 4 위치에서 주로 등장)   counter를 통해 타이밍 제어   CallbackLoop(frequency:)를 템포에 맞춰 계산하여 정확한 리듬 유지    "
  },
  
  {
    "title": "AudioKit의 DrumSequencer",
    "url": "/posts/DrumSequencer/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-05-01 20:48:21 +0900",
    "content": "Drum Sequencer  이 DrumSequencerConductor 클래스는 AudioKit과 SwiftUI를 활용한 드럼 시퀀서 로직을 담당하며, 기본적인 구조와 기능은 다음과 같습니다:    📦 클래스 개요  @Observable class DrumSequencerConductor: ObservableObject, HasAudioEngine      ObservableObject이므로 SwiftUI 뷰와 바인딩 가능.   @Observable은 상태 변화를 자동 감지하여 뷰 갱신을 가능하게 함 (Swift Macros).   HasAudioEngine은 engine을 제공하는 AudioKit 프로토콜.     🧠 주요 프로퍼티                 프로퍼티       설명                       engine       AudioKit의 오디오 엔진                 drums       MIDI 샘플러로, 드럼 소리를 낼 수 있음                 midiCallback       시퀀서에서 재생된 MIDI 노트를 실제 소리로 바꿔주는 콜백                 sequencer       MIDI 파일을 기반으로 재생 가능한 AppleSequencer 인스턴스                 tempo       현재 BPM (변경 시 실시간 반영됨)                 isPlaying       재생 상태 (true면 재생, false면 정지)                 hiHatsRoll       하이햇 패턴의 시각화 문자열 (🟩와 ⬜️로 표시됨)             🥁 기능 설명  🎵 init()  초기화 시 다음 작업을 수행합니다:     MIDI 노트 콜백 설정 → drums.play(...)로 음 재생.   샘플 오디오 파일 로드 → drums.loadAudioFiles(audioFiles!)   시퀀서 초기 설정:            MIDI 출력 연결, 루프 설정, 템포 설정       트랙별 노트 추가 (총 4트랙)                    트랙 0, 1: 베이스 드럼           트랙 2: 하이햇 (8비트 패턴)           트랙 3: 스네어                           하이햇 시각화 업데이트     🧪 randomizeHiHats()     트랙 2의 기존 노트를 제거한 후   새로운 16개의 하이햇 노트를 생성합니다 (1마디 분량)            음높이: 30 또는 31 (랜덤)       세기: 80~127 (랜덤)       위치: 0부터 15까지 16분음표 단위       길이: 0.5 비트 (짧은 소리)           updateHiHatsRoll() 호출로 UI 반영     🟩 updateHiHatsRoll()     트랙 2에 있는 노트 정보를 기반으로   noteNumber == 30이면 🟩, 아니면 ⬜️로 표현   4개 단위로 띄어쓰기 추가 → 가독성 높임     🎧 audioFiles (Computed Property)     sampleFileNames 배열을 기반으로 AVAudioFile 인스턴스 생성   Bundle.main에서 오디오 샘플 파일을 로드하여 반환     🎼 전체 트랙 요약                 트랙       용도       노트 번호       설명                       0       베이스       24       시작(0), 중간(2)에 추가됨                 1       서브베이스       24       중간(2)에만 추가됨                 2       하이햇       30       기본 8비트 패턴 or 랜덤 패턴                 3       스네어       26       중간(2)에 추가됨            "
  },
  
  {
    "title": "AudioKit의 Drums",
    "url": "/posts/Drums/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-04-30 15:55:38 +0900",
    "content": "Drums  이 코드는 AudioKit을 활용한 드럼 패드 앱의 핵심 구조를 보여주는 예제입니다. 사용자가 UI 상에서 패드를 누르면 대응되는 드럼 사운드가 재생됩니다. 코드 전체는 다음 3가지 주요 구성 요소로 나뉩니다:    1. DrumSample – 드럼 사운드 데이터 모델  struct DrumSample {   var name: String        // 화면에 표시될 이름   var fileName: String    // 번들 내 오디오 파일 이름   var midiNote: Int       // MIDI 노트 번호   var audioFile: AVAudioFile?   var color: UIColor = .red }      각 드럼 패드의 정보를 담는 구조체입니다.   초기화 시 번들에서 오디오 파일을 불러와 AVAudioFile로 저장합니다.   색상(color) 속성도 포함되어 있어 시각적 효과에 활용됩니다.     2. DrumsConductor – 오디오 처리 및 패드 재생 로직 (ViewModel 역할)  class DrumsConductor: HasAudioEngine      AudioKit의 AppleSampler를 사용하여 8개의 드럼 샘플을 로드하고 재생합니다.   playPad(padNumber:) 함수는 해당 패드의 MIDI 노트를 통해 소리를 재생합니다.   @Observable을 통해 SwiftUI에서 상태 관찰이 가능합니다.   초기화 시 샘플 오디오들을 drums.loadAudioFiles(...)로 등록합니다.     3. SwiftUI 뷰: DrumsView, PadsView  ▶ DrumsView struct DrumsView: View     상위 뷰이며 PadsView를 렌더링합니다.   .onAppear / .onDisappear를 통해 AudioKit 엔진을 시작/정지합니다.     ▶ PadsView struct PadsView: View   주요 기능:     2x4 드럼 패드 UI를 구성   각 패드는 Rectangle 뷰로 시각화   패드 ID는 row * 4 + column 계산식을 사용해 1차원 배열처럼 관리   드래그 제스처로 패드를 눌렀을 때:            padId가 downPads에 없다면 → padsAction(padId) 실행 + downPads에 추가       손을 뗄 때(.onEnded) → 해당 padId를 downPads에서 제거           제스처 처리:  .onChanged {   if padId not in downPads {     padsAction(padId)     downPads.append(padId)   } } .onEnded {   downPads.remove(padId) }   이 구조를 통해 UI 반응성과 상태 변경 처리가 동시에 이루어집니다.    🎨 시각적 상태 처리  padColor(padId:) 함수     downPads에 포함된 padId라면 .gray로 색상 처리   아니면 해당 드럼 샘플에 정의된 색상(sample.color) 사용     🧠 정리                 구성 요소       역할                       DrumSample       드럼 하나의 데이터 구조 (이름, 파일명, 색상 등)                 DrumsConductor       오디오 엔진 및 샘플 로드, 패드 재생 제어                 DrumsView       상위 SwiftUI 뷰, 오디오 엔진 생명주기 제어                 PadsView       패드 레이아웃, 제스처 입력 처리, 상태 UI 반영            "
  },
  
  {
    "title": "AudioKit의 Audio3D는 무엇인가?",
    "url": "/posts/Audio3D/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-04-29 16:23:27 +0900",
    "content": "Audio3D  이 코드는 3D 오디오 시뮬레이션과 시각화를 구현하는 SwiftUI 앱입니다. 주된 목표는 사용자의 시점(Camera)과 음원(Source)의 위치에 따라 오디오 환경이 실제처럼 동적으로 반응하도록 만드는 것입니다. 핵심은 AudioEngine3DConductor와 SceneCoordinator이며, 두 객체는 각각 오디오 처리와 3D 장면 좌표 추적 및 업데이트 역할을 맡습니다.    🔊 AudioEngine3DConductor – 오디오 엔진 및 3D 사운드 구성  AudioEngine3DConductor는 오디오 엔진을 설정하고, 3D 공간에서 위치 기반 사운드를 처리합니다. UpdateAudioSourceNodeDelegate 프로토콜을 구현하여 외부에서 전달되는 카메라와 음원의 위치 및 방향에 따라 엔진 내 3D 사운드 정보를 갱신합니다.  주요 구성 요소    engine: AudioKit의 메인 오디오 엔진   player: 루프 재생 가능한 AudioPlayer   source1Mixer3D: 3D 공간 내 위치 조절이 가능한 Mixer3D   environmentalNode: 3D 환경 효과를 제공하는 노드 (AVAudioEnvironmentNode 기반)   설정 흐름    player에 buffer를 할당하고 루프 재생 설정   player를 Mixer3D에 연결하고, 이 Mixer를 EnvironmentalNode에 연결   EnvironmentalNode는 공간 처리 알고리즘과 리버브 설정   최종적으로 engine.output = environmentalNode로 출력 설정   위치/방향 갱신    updateListenerPosition3D: 리스너(카메라)의 위치 갱신   updateListenerOrientationVector: 리스너의 방향(벡터 기반) 갱신   updateSoundSourcePosition: 사운드 소스 위치 갱신     🎥 SceneCoordinator – SceneKit 기반 3D 공간의 상태 추적  SceneCoordinator는 SceneKit의 3D 장면을 제어하며, 오디오 위치에 반영될 정보를 추출합니다. SCNSceneRendererDelegate를 채택해 매 프레임마다 위치와 방향을 추적하고 이를 AudioEngine3DConductor에 전달합니다.  주요 구성 요소    theScene: 로딩된 .scn 파일로 구성된 3D 장면   cameraNode: 카메라의 위치를 3D 공간 내에서 설정   updateAudioSourceNodeDelegate: 위치 정보 전달용 delegate (보통 AudioEngine3DConductor)   렌더링 시 위치 업데이트 renderer(_:updateAtTime:)에서 다음 작업을 수행합니다:    장면에서 pointOfView (카메라 위치)와 \"soundSource\" 노드의 위치를 가져옴   updateAudioSourceNodeDelegate를 통해 이 정보를 AudioEngine3DConductor에 전달     🧩 기타 구성 요소 (간단 요약)  AudioKit3DViewModel    @Observable 클래스   AudioEngine3DConductor와 SceneCoordinator를 생성 및 연결   AudioKit3DView    SwiftUI 뷰   뷰 모델을 통해 오디오 및 SceneView 구성   .onAppear / .onDisappear에서 오디오 재생/중지 제어     정리                 역할       담당 클래스       주요 기능                       오디오 처리 및 3D 반영       AudioEngine3DConductor       플레이어, 3D 믹서, 위치 반영                 3D 장면 제어 및 추적       SceneCoordinator       카메라 및 음원 위치 추적 후 오디오 엔진에 전달                 데이터 조율       AudioKit3DViewModel       두 객체 연결                 UI 렌더링       AudioKit3DView       SceneKit 뷰 표시 및 조작           이 시스템은 SceneKit의 위치 정보를 기반으로 AudioKit의 3D 오디오를 실시간 반영하는 구조입니다. 따라서 사용자의 시점이 변하면 오디오도 그에 맞춰 동적으로 바뀝니다.    sourceBuffer의 역할  sourceBuffer는 3D 공간에서 재생할 오디오 데이터의 원본 역할을 합니다. 구체적으로는, 오디오 파일 \"Samples/beat.aiff\"를 앱 번들에서 불러와 AVAudioPCMBuffer 형식으로 메모리에 로드하고, 이후 AudioPlayer가 이 버퍼를 기반으로 사운드를 재생하게 됩니다.    🔍 핵심 역할 요약                 항목       설명                       🎵 버퍼의 정체       AVAudioPCMBuffer: 오디오 프레임들을 담고 있는 PCM 형식의 버퍼                 📂 데이터 출처       번들에 포함된 \"Samples/beat.aiff\"                 🎧 사용 위치       AudioEngine3DConductor의 player.buffer = buffer에서 할당되어 재생                 🔁 특성       player.isLooping = true로 설정되어 반복 재생됨             🧠 왜 버퍼를 쓰는가?     AVAudioPlayer나 AVAudioEngine에서 짧은 오디오 클립을 빠르게 재생하거나 반복 재생할 때, 파일 스트리밍보다 버퍼 방식이 효율적입니다.   AVAudioPCMBuffer는 RAM에 오디오 데이터를 미리 올려놓는 방식이므로 지연(Latency) 없이 즉시 재생이 가능합니다.   공간 오디오 처리에서는 오디오 위치가 실시간으로 변경될 수 있기 때문에, 버퍼 기반의 반복 재생이 적합합니다.     즉, sourceBuffer는 앱이 사용할 사운드를 메모리에 로드된 상태로 유지하며, 3D 위치 기반 재생을 가능하게 해주는 핵심 데이터 소스입니다.    Observable 동작원리    문서  "
  },
  
  {
    "title": "AudioKit의 Arpeggiator(아르페지에이터)는 무엇인가?",
    "url": "/posts/Arpeggiator/",
    "categories": "StudyLog, AudioKit",
    "tags": "AudioKit, 음향이론",
    "date": "2025-04-28 16:09:40 +0900",
    "content": "Arpeggiator  이 코드는 ArpeggiatorConductor라는 클래스를 정의하고 있으며, AudioEngine과 AppleSampler를 사용해 아르페지오 (Arpeggio) 기능을 구현하는 구조입니다. 또한 MIDI 신호를 받아서 음악을 재생하는 역할을 합니다.  클래스의 동작 원리:  주요 속성    engine: AudioEngine 인스턴스로, 음악과 오디오 처리를 담당하는 오디오 엔진.   instrument: AppleSampler 인스턴스로, 샘플러 악기를 사용하여 MIDI 신호를 받아 음악을 연주합니다.   sequencer: SequencerTrack 객체로, 음표의 순서를 제어하는 시퀀서입니다.   midiCallback: MIDI 신호를 처리하는 CallbackInstrument 객체입니다.   heldNotes: 현재 눌린 음표들을 저장하는 배열입니다.   arpUp: 아르페지오가 위로 (UP) 가는지 아래로 (DOWN) 가는지를 판단하는 변수입니다.   currentNote: 현재 연주 중인 음표 번호를 저장합니다.   sequencerNoteLength: 시퀀서에서 각 음표의 길이를 나타내는 변수입니다.   tempo: 템포 (BPM)를 나타내며, 템포가 변경될 때 시퀀서의 템포도 업데이트됩니다.   noteLength: 음표 길이를 나타내며, 음표의 길이가 변경되면 시퀀서에 음표를 추가하거나 업데이트합니다.   주요 메서드    noteOn(pitch:point:):            pitch (음높이)를 받아서 heldNotes 배열에 추가합니다.       음표가 눌리면 해당 음표가 heldNotes에 추가되고, 이는 아르페지오 로직에서 사용됩니다.           noteOff(pitch:):            pitch (음높이)를 받아서 heldNotes 배열에서 해당 음표를 제거합니다.       음표가 떼어지면 heldNotes 배열에서 삭제되고, 아르페지오 로직에서 해당 음표를 고려하지 않습니다.           fireTimer():            heldNotes 배열에 따라 아르페지오 기능을 실행합니다.       arpUp이 false일 때 (아르페지오가 아래로 내려가고 있을 때) heldNotes 중 currentNote보다 큰 음표 중 가장 작은 음표를 currentNote로 설정합니다.       arpUp이 true일 때 (아르페지오가 위로 올라가고 있을 때) heldNotes 중 currentNote보다 작은 음표 중 가장 큰 음표를 currentNote로 설정합니다.       instrument.play()를 사용하여 현재 음표를 재생합니다.       arpUp이 true에서 false로 바뀔 때나 그 반대일 때, 아르페지오는 반대 방향으로 전환됩니다.           초기화 (init):            midiCallback을 설정하여 MIDI 신호를 받을 때마다 fireTimer()를 호출합니다.       engine.output은 PeakLimiter로 설정되어 믹싱 후 신호가 왜곡되지 않도록 합니다.       instrument.loadInstrument()를 통해 샘플러 악기(sawPiano1.exs)를 로드하여 instrument에 설정합니다.       sequencer를 설정하여 기본적인 시퀀서를 만들어 주고, 초기 위치에서 음표를 재생하도록 설정합니다.           요약:    MIDI 입력 처리: MIDI 신호가 들어오면 fireTimer()를 호출하여 현재 눌려진 음표에 맞는 아르페지오를 연주합니다.   아르페지오: heldNotes 배열에 저장된 음표를 바탕으로 arpUp 값에 따라 음표를 순차적으로 재생합니다. 아르페지오는 위로 또는 아래로 진행될 수 있습니다.   악기와 시퀀서: AppleSampler와 SequencerTrack을 이용하여 음악을 연주하고, 시퀀서가 반복적으로 음표를 재생합니다.   템포 및 음표 길이 설정: 템포와 음표 길이가 변경되면, sequencer에 해당 정보를 반영하여 연주 스타일을 조정합니다.   이 클래스는 ArpeggiatorConductor를 통해 아르페지오 효과를 다루며, MIDI 신호에 반응하여 실시간으로 음을 처리하고 재생하는 구조입니다. "
  }
  
]

